[
  {
    "id": "os",
    "title": "Operating System",
    "desc": "A comprehensive roadmap for mastering Operating Systems, from core principles to advanced topics.",
    "description": "This roadmap provides a structured learning path for understanding Operating Systems. It starts with the fundamental concepts, history, and types of OS, then progressively dives into system architecture, process and memory management, storage, security, and advanced topics like virtualization. Each chapter is designed to build upon the previous one, offering detailed explanations, practical code examples, and a clear week-by-week schedule to guide learners from novice to proficient in OS concepts. This journey covers the theoretical underpinnings and practical applications, preparing you for system programming, software engineering, and system administration roles.",
    "category": "Computer Science",
    "categories": ["Operating System", "Intermediate", "System Programming"],
    "difficulty": "Intermediate",
    "image": "/images/os.png",
    "icon": "FaMicrochip",
    "chapters": [
      {
        "id": "c1-introduction",
        "title": "Introduction to Operating Systems",
        "desc": "Learn the basics, history, functions, and types of Operating Systems.",
        "notes": "Chapter 1 serves as the foundational entry point into the world of Operating Systems. It begins by demystifying what an OS is, establishing it as the essential intermediary software between computer hardware and the end-user. We explore its core purpose: to manage hardware resources like the CPU, memory, and storage devices, and to provide a consistent and usable environment for applications to run. The historical context is crucial for understanding how we arrived at today's complex systems. We trace the evolution from early, non-existent OS environments and simple batch systems, where jobs ran sequentially without user interaction, to the advent of multiprogramming and time-sharing systems that allowed for interactivity and simultaneous users. This evolution highlights the driving forces behind OS development, such as the need for efficiency, user convenience, and resource optimization. Finally, the chapter categorizes the vast landscape of operating systems—from personal computers (Windows, macOS, Linux) and mobile devices (Android, iOS) to specialized systems like real-time OS (RTOS) used in critical applications and embedded systems found in everyday electronics. This foundational knowledge is paramount for appreciating the design choices and complexities discussed in subsequent chapters.",
        "code": "",
        "duration": "Week 1",
        "topics": [
          {
            "id": "t1-definition",
            "title": "Definition of Operating System",
            "desc": "Understand what an OS is and why it is fundamentally important for computing.",
            "note": "An Operating System (OS) is the most critical piece of system software in a computer system. It acts as a master controller and an intermediary layer, bridging the gap between the complex underlying hardware and the software applications a user interacts with. Its primary goal is twofold: to provide a convenient, abstract environment for the user and to manage the computer's hardware resources efficiently and fairly. As a resource manager, the OS is responsible for allocating processor time, memory space, file storage, and I/O devices among the various programs and users. It keeps track of who is using which resource, grants resource requests, and mediates conflicting requests from different programs. Without an OS, every application developer would need to write code to directly control the hardware, a task that is incredibly complex and device-specific. For example, to print a document, an application would need to know the specific control signals for every possible printer model. The OS abstracts this complexity away by providing a generic interface, or Application Programming Interface (API), through system calls. The application simply makes a 'print' request to the OS, and the OS, through its device drivers, handles the specific hardware communication. This abstraction simplifies application development, enhances portability, and ensures the system remains stable and secure.",
            "code": "// Example 1: A simple C program demonstrating a system call to write to the console.\n#include <unistd.h>\n\nint main() {\n    const char *message = \"Hello, OS! This is a write system call.\\n\";\n    write(1, message, 39); // 1 is the file descriptor for stdout\n    return 0;\n}\n\n// Example 2: A Python script showing how the OS manages file resources.\nimport os\n\nfile_path = 'my_document.txt'\n\n# The OS handles the file creation and writing process.\nwith open(file_path, 'w') as f:\n    f.write('The Operating System provides file management services.')\n\n# The OS reads the file and provides its content to the program.\nwith open(file_path, 'r') as f:\n    print(f.read())\n\n# The OS handles file deletion.\nos.remove(file_path)\nprint(f\"File '{file_path}' removed successfully.\")"
          },
          {
            "id": "t2-history",
            "title": "History of Operating Systems",
            "desc": "Trace the evolution of Operating Systems from early batch systems to modern, sophisticated OS.",
            "note": "The history of Operating Systems is a fascinating journey that mirrors the evolution of computing itself. In the very first generation of computers (1940s-1950s), there was no concept of an OS. Programmers interacted directly with the hardware using plugboards and switches. The second generation saw the introduction of Batch Systems. Here, jobs with similar needs were bundled together and run as a group, or 'batch,' to improve efficiency. A human operator would sort jobs into batches, and a rudimentary monitor program would load and run one job after another, but there was no direct user interaction. The third generation was revolutionary, introducing Multiprogramming. This allowed multiple jobs to be kept in memory at once. When one job had to wait for an I/O operation to complete, the CPU could switch to another job, significantly increasing CPU utilization. This led to Time-Sharing (or Multitasking) systems, which were a logical extension of multiprogramming. In these systems, the CPU switches between jobs so frequently that each user can interact with their program while it is running, creating the illusion of a dedicated machine. The fourth generation (mid-1970s onwards) witnessed the rise of Personal Computers (PCs). This demanded the creation of user-friendly operating systems like MS-DOS, Apple's Macintosh OS, and later, Microsoft Windows and Linux, which brought graphical user interfaces (GUIs) to the masses. The current era is defined by distributed and mobile operating systems. Distributed systems connect multiple computers to work together, while mobile OS like Android and iOS are highly optimized for power efficiency and touch-based interfaces on portable devices.",
            "code": "// Example 1: Pseudocode representing a simple batch system monitor.\nvoid BatchMonitor() {\n    while (true) {\n        Job nextJob = getNextJobFromQueue();\n        if (nextJob == null) break; // No more jobs\n        \n        loadProgram(nextJob.program);\n        executeProgram();\n        unloadProgram();\n    }\n}\n\n// Example 2: Python demonstrating a simple time-sharing concept using threading.\nimport threading\nimport time\n\ndef task(name, delay):\n    print(f\"Task {name}: Starting\")\n    time.sleep(delay)\n    print(f\"Task {name}: Finishing\")\n\n# The OS scheduler would switch between these threads.\nt1 = threading.Thread(target=task, args=(\"A\", 2))\nt2 = threading.Thread(target=task, args=(\"B\", 2))\n\nt1.start()\nt2.start()\n\nt1.join()\nt2.join()\nprint(\"All tasks finished.\")"
          },
          {
            "id": "t3-functions",
            "title": "Core Functions of an OS",
            "desc": "Explore the primary responsibilities of an Operating System.",
            "note": "The Operating System performs several essential functions that are fundamental to the operation of a computer. These can be broadly categorized. First, Process Management is a key function where the OS handles the creation, deletion, suspension, and resumption of processes. It also provides mechanisms for processes to communicate and synchronize with each other. Second, Memory Management involves overseeing the computer's primary memory (RAM). The OS keeps track of which parts of memory are currently being used and by whom. It allocates memory to processes when they need it and deallocates it when they are done. This ensures that multiple processes can coexist without interfering with each other's memory space. Third, File System Management provides a consistent way to store and retrieve information. The OS organizes files into a hierarchical directory structure and manages access permissions to control who can read, write, or execute files. Fourth, I/O Device Management abstracts the complexity of hardware devices. It manages communication with devices like keyboards, mice, printers, and disk drives through device drivers. It handles all I/O requests from processes, making them device-independent. Finally, the OS provides a layer of Security and Protection, controlling access to system resources. It authenticates users, prevents unauthorized access, and protects processes from interfering with one another, ensuring the overall integrity and stability of the system.",
            "code": "// Example 1: Java demonstrating process creation, a core OS function.\npublic class ProcessCreation {\n    public static void main(String[] args) {\n        try {\n            // The OS is asked to create a new process (e.g., run the 'ls' command on Linux)\n            Process process = new ProcessBuilder(\"ls\", \"-l\").start();\n            System.out.println(\"New process created by the OS.\");\n            process.waitFor(); // Wait for the process to complete\n            System.out.println(\"Process finished.\");\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n\n// Example 2: Python script illustrating OS-level file permission management.\nimport os\nimport stat\n\nfile_name = \"protected_file.txt\"\nwith open(file_name, \"w\") as f:\n    f.write(\"This is a test file.\")\n\n# Use OS call to change file permissions to read-only for the owner\n# The OS enforces these permissions.\nos.chmod(file_name, stat.S_IRUSR)\nprint(f\"Permissions for {file_name} set to read-only for owner.\")\n\ntry:\n    # This will fail because the OS denies write access.\n    with open(file_name, \"w\") as f:\n        f.write(\"Trying to write again.\")\nexcept PermissionError as e:\n    print(f\"Caught expected error: {e}\")\n\nos.remove(file_name)"
          },
          {
            "id": "t4-types",
            "title": "Types of Operating Systems",
            "desc": "Differentiate between various types of OS like Batch, Real-Time, Distributed, and Mobile OS.",
            "note": "Operating systems are designed with different goals and for different environments, leading to several distinct types. Batch Operating Systems, one of the earliest forms, were designed for efficiency, executing jobs in batches without user interaction. They are suitable for tasks like payroll processing or large-scale data analysis where execution time is not critical. Time-Sharing/Multitasking Operating Systems allow multiple users to share the computer simultaneously by rapidly switching the CPU between various tasks. This is the foundation of modern desktop OS like Windows, macOS, and Linux. Distributed Operating Systems manage a group of independent computers and make them appear to be a single computer. The main benefit is resource sharing, allowing users to access resources (like files or printers) on any machine in the network as if they were local. Network Operating Systems (NOS) are similar but less integrated; they run on a server and provide network functions to clients, like file sharing, but each machine is aware of the others. Real-Time Operating Systems (RTOS) are crucial for time-critical applications where tasks must be completed within a strict deadline. They are used in industrial control systems, robotics, and medical imaging devices. An RTOS is valued for its predictability and reliability over raw speed. Lastly, Mobile Operating Systems like Android and iOS are designed for smartphones and tablets. They are optimized for touch-based interfaces, power management, and connectivity features like Wi-Fi and cellular data.",
            "code": "// Example 1: Pseudocode for a Real-Time Operating System (RTOS) task.\n// The OS must guarantee this task runs every 20ms.\nvoid temperatureControlTask() {\n    while (true) {\n        int temp = readSensor();\n        if (temp > THRESHOLD) {\n            activateCoolingSystem();\n        }\n        sleepUntilNextPeriod(20_ms); // OS ensures precise timing\n    }\n}\n\n// Example 2: Python code simulating a task for a distributed system.\n// This might run on one node to request data from another.\nimport requests\n\ndef get_weather_from_node(node_ip):\n    try:\n        # The network/distributed OS handles the underlying communication.\n        response = requests.get(f\"http://{node_ip}:8000/weather\")\n        if response.status_code == 200:\n            print(f\"Weather data from node {node_ip}: {response.json()}\")\n        else:\n            print(f\"Failed to get data from node {node_ip}.\")\n    except requests.exceptions.ConnectionError:\n        print(f\"Could not connect to node {node_ip}.\")\n\n# In a real distributed system, the OS might manage node discovery.\nget_weather_from_node(\"192.168.1.101\")"
          }
        ]
      },
      {
        "id": "c2-system-architecture",
        "title": "System Architecture & Components",
        "desc": "Understand the core structure of an OS, including kernel, user space, and system calls.",
        "notes": "Chapter 2 delves into the fundamental architecture of a modern operating system, dissecting its key components and how they interact. The central concept is the division between kernel space and user space, a crucial protection mechanism. Kernel space is a privileged, protected area where the core of the OS—the kernel—resides and executes. The kernel has unrestricted access to all hardware and memory in the system. It is responsible for the most critical tasks: managing processes, handling memory, and interfacing with hardware. In contrast, user space is a restricted environment where user applications and general system software run. Programs in user space have limited access to hardware and cannot directly interact with it. This separation is vital for system stability; a crashing application in user space will not bring down the entire operating system. The bridge between these two spaces is the system call interface. When a user application needs to perform a privileged operation, such as reading a file or opening a network connection, it must request this service from the kernel by making a system call. This acts as a controlled entry point into the kernel, allowing the OS to validate the request and perform the action on the application's behalf before returning the result. Understanding this dual-mode operation (kernel mode vs. user mode) and the system call mechanism is fundamental to grasping how an OS maintains control and provides services securely.",
        "code": "",
        "duration": "Week 2",
        "topics": [
          {
            "id": "t5-kernel",
            "title": "The Kernel",
            "desc": "Explore the core of the OS, its modes (kernel vs. user), and types (monolithic, microkernel).",
            "note": "The kernel is the heart of the operating system, the first program loaded on startup, and it remains in memory for the entire duration the computer is running. It has complete control over everything in the system. To ensure this control is not compromised, modern CPUs support at least two modes of operation: kernel mode and user mode. When the system is running in kernel mode, the CPU can execute any instruction and access any part of memory. This is the mode in which the kernel itself runs. All other software, such as application programs, runs in user mode, which restricts access to a subset of instructions and memory. This dual-mode operation is the fundamental mechanism for protecting the OS from user programs. If a user program needs to perform a privileged action, it must use a system call to ask the kernel to do it. Kernel architectures vary. A Monolithic Kernel contains most of the OS functionality—CPU scheduling, memory management, file systems, and device drivers—within one large block of code running in a single address space. This design is efficient because communication between components is fast. Linux is a famous example. Conversely, a Microkernel is structured to have only the most basic services in the kernel, such as process management and inter-process communication. Other services like file systems and device drivers run as separate processes in user space. This makes the system more modular and potentially more secure, as a failure in a user-space driver won't crash the kernel. QNX and Hurd are examples of microkernel-based systems.",
            "code": "// Example 1: C code that triggers a system call, causing a switch from user to kernel mode.\n#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    // The printf function will eventually call the write() system call.\n    printf(\"This print statement will trigger a context switch to kernel mode.\\n\");\n    \n    // The getpid() system call asks the kernel for the current process ID.\n    pid_t process_id = getpid();\n    printf(\"The kernel reports my Process ID is: %d\\n\", process_id);\n    \n    return 0; // The exit() system call terminates the process.\n}\n\n// Example 2: Python code implicitly using system calls.\nimport os\n\n# The os.getcwd() function makes a system call to get the current working directory.\n# The application itself cannot determine this without the kernel's help.\ncurrent_dir = os.getcwd()\nprint(f\"Kernel says current directory is: {current_dir}\")\n\n# os.uname() queries the kernel for system information.\n# This is a classic example of user space asking kernel for data.\nkernel_info = os.uname()\nprint(f\"Kernel version: {kernel_info.release}\")"
          },
          {
            "id": "t6-system-calls",
            "title": "System Calls",
            "desc": "Learn how user programs request services from the kernel.",
            "note": "System calls are the programmatic interface through which a user-level process requests a service from the kernel of the operating system. Since user applications run in a restricted mode (user mode) and cannot directly access hardware or perform privileged operations, they must rely on the kernel, which runs in the privileged kernel mode. A system call is the mechanism that facilitates this transition. When a program executes a system call, it's not a typical function call. Instead, it involves a special instruction that causes a software interrupt, or 'trap.' This trap instruction switches the CPU from user mode to kernel mode and transfers control to a predefined location in the kernel's code—the system call handler. The handler then uses a unique number, passed as part of the system call, to identify which service is being requested (e.g., read a file, create a new process, allocate memory). The kernel validates the parameters of the request, performs the operation, and then switches the CPU back to user mode, returning control to the application along with any results or error codes. This entire process is typically hidden from the application developer by a library or API (like the C standard library or the Windows API). For example, a programmer calls `fopen()` to open a file, and the library function handles the low-level details of setting up and executing the actual `open()` system call. This controlled entry into the kernel is essential for maintaining system security and stability.",
            "code": "// Example 1: C code using the 'open' and 'read' system calls directly via unistd.h\n#include <stdio.h>\n#include <unistd.h>\n#include <fcntl.h>\n\nint main() {\n    char buffer[128];\n    // Make a system call to open a file (e.g., /etc/hostname).\n    int fd = open(\"/etc/hostname\", O_RDONLY);\n    if (fd == -1) {\n        perror(\"open\");\n        return 1;\n    }\n    \n    // Make a system call to read from the file into our buffer.\n    ssize_t bytes_read = read(fd, buffer, sizeof(buffer) - 1);\n    buffer[bytes_read] = '\\0';\n    \n    printf(\"Hostname (read via system call): %s\", buffer);\n    \n    // Make a system call to close the file descriptor.\n    close(fd);\n    return 0;\n}\n\n// Example 2: Python's 'os' module provides a direct wrapper for many system calls.\nimport os\n\ntry:\n    # Create a directory - this is a system call.\n    os.mkdir(\"temp_dir\")\n    print(\"'temp_dir' created.\")\n\n    # Change into the new directory - another system call.\n    os.chdir(\"temp_dir\")\n    print(f\"Current dir: {os.getcwd()}\")\n\n    # Change back.\n    os.chdir(\"..\")\n\n    # Remove the directory - a final system call.\n    os.rmdir(\"temp_dir\")\n    print(\"'temp_dir' removed.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")"
          }
        ]
      },
      {
        "id": "c3-processes-threads",
        "title": "Processes & Threads",
        "desc": "Understand processes, threads, context switching, and scheduling basics.",
        "notes": "Chapter 3 introduces the fundamental concepts of execution in an operating system: processes and threads. A process is essentially a program in execution. It is an active entity that requires resources like CPU time, memory, files, and I/O devices to complete its task. The operating system manages all processes through a data structure called the Process Control Block (PCB), which stores vital information about each process, including its current state, CPU register values, memory management information, and a list of open files. A critical operation in a multitasking OS is the context switch, where the OS saves the state of the currently running process (its context) into its PCB and loads the state of another process to resume its execution. This mechanism allows a single CPU to handle multiple processes concurrently. We will also explore the different states a process can be in, such as new, ready, running, waiting, and terminated. The second half of the chapter focuses on threads, which are lightweight units of execution within a process. A single process can contain multiple threads, all of which share the same memory space, code, and resources. This makes communication between threads much faster than between separate processes. Threads are essential for creating responsive applications, as a long-running task in one thread won't block the entire application (e.g., the user interface can remain active while a file downloads in a background thread).",
        "code": "",
        "duration": "Week 3",
        "topics": [
          {
            "id": "t7-processes",
            "title": "Processes and PCB",
            "desc": "Define a process and its representation in the OS via the Process Control Block (PCB).",
            "note": "A process is more than just program code; it is an active instance of a program being executed. While a program is a passive set of instructions stored on a disk (an executable file), a process is a dynamic entity with a program counter specifying the next instruction to execute and a set of associated resources. To manage and keep track of all the running processes, the operating system maintains a data structure for each one called the Process Control Block (PCB), also known as a process descriptor. The PCB is the central repository for all information the OS needs about a process. It contains a wealth of data, including the Process State, which indicates its current status (e.g., running, waiting, ready). It stores the Program Counter, which points to the address of the next instruction to be executed for this process. It holds the contents of the CPU Registers, which must be saved when the process is interrupted so they can be restored later to continue execution correctly. The PCB also includes CPU Scheduling Information, such as the process's priority and pointers to scheduling queues. Memory Management Information, like page tables or segment tables that define the process's address space, is stored here. Finally, it contains Accounting Information (e.g., CPU time used) and I/O Status Information (e.g., a list of I/O devices allocated to the process and a list of open files). When the OS performs a context switch, it is essentially saving the current process's context into its PCB and loading another process's context from its PCB.",
            "code": "// Example 1: C++/Linux code to create a new process using fork().\n// The OS creates a new process with its own PCB, a copy of the parent's.\n#include <iostream>\n#include <unistd.h>\n\nint main() {\n    pid_t pid = fork(); // Creates a new process\n\n    if (pid == 0) {\n        // This is the child process\n        std::cout << \"I am the child process. My PID is \" << getpid() << std::endl;\n        std::cout << \"My parent's PID is \" << getppid() << std::endl;\n    } else if (pid > 0) {\n        // This is the parent process\n        std::cout << \"I am the parent process. My PID is \" << getpid() << std::endl;\n        std::cout << \"I created a child with PID \" << pid << std::endl;\n    } else {\n        std::cerr << \"Fork failed!\" << std::endl;\n        return 1;\n    }\n    return 0;\n}\n\n// Example 2: Python's multiprocessing module to spawn a new process.\n// The OS manages a separate PCB for the new process.\nimport multiprocessing\nimport os\n\ndef worker():\n    \"\"\"Function to be executed in the new process.\"\"\"\n    print(f\"Worker process ID: {os.getpid()}\")\n    print(f\"Parent process ID: {os.getppid()}\")\n\nif __name__ == \"__main__\":\n    print(f\"Main process ID: {os.getpid()}\")\n    p = multiprocessing.Process(target=worker)\n    p.start()\n    p.join()\n    print(\"Worker process finished.\")"
          },
          {
            "id": "t8-threads",
            "title": "Threads",
            "desc": "Understand threads as lightweight processes and their advantages.",
            "note": "A thread is the smallest unit of execution that an operating system can schedule. It is often described as a 'lightweight process' because it exists within the context of a process. A single process can host multiple threads, each executing a different part of the program concurrently. Unlike separate processes, all threads within the same process share the same memory address space, which includes the code section, data section, and operating system resources like open files and signals. However, each thread has its own independent program counter, register set, and stack space. This shared memory model is the key advantage of threads. It allows for very fast communication and data sharing between threads, as they can simply read and write to the same memory locations, avoiding the slower inter-process communication (IPC) mechanisms required for separate processes. This makes threads highly efficient for tasks that need to cooperate closely. The benefits are numerous. For applications with a graphical user interface (GUI), one thread can manage the UI and remain responsive to user input (like mouse clicks), while another thread performs a long-running task in the background, such as a complex calculation or a network download. On multi-core processors, threads provide a natural way to achieve true parallelism, where different threads from the same process can run simultaneously on different CPU cores, dramatically improving performance for CPU-bound tasks.",
            "code": "// Example 1: Java code to create and run multiple threads.\n// All threads share the same process memory.\nclass MyRunnable implements Runnable {\n    private String name;\n    public MyRunnable(String name) { this.name = name; }\n\n    public void run() {\n        for (int i = 0; i < 3; i++) {\n            System.out.println(name + \": running iteration \" + i);\n            try { Thread.sleep(100); } catch (InterruptedException e) {}\n        }\n    }\n}\n\npublic class ThreadExample {\n    public static void main(String[] args) {\n        Thread t1 = new Thread(new MyRunnable(\"Thread-A\"));\n        Thread t2 = new Thread(new MyRunnable(\"Thread-B\"));\n        t1.start(); // OS schedules t1 to run\n        t2.start(); // OS schedules t2 to run\n    }\n}\n\n// Example 2: Python's threading module.\nimport threading\nimport time\n\nshared_data = []\n\ndef writer():\n    \"\"\"This thread writes to the shared data list.\"\"\"\n    for i in range(5):\n        print(f\"Writer adding {i}\")\n        shared_data.append(i)\n        time.sleep(0.5)\n\ndef reader():\n    \"\"\"This thread reads from the shared data list.\"\"\"\n    while len(shared_data) < 5:\n        time.sleep(0.6)\n        print(f\"Reader sees: {shared_data}\")\n\nt1 = threading.Thread(target=writer)\nt2 = threading.Thread(target=reader)\n\nt1.start()\nt2.start()\nt1.join()\nt2.join()"
          }
        ]
      },
      {
        "id": "c4-cpu-scheduling",
        "title": "CPU Scheduling",
        "desc": "Learn various algorithms used by the OS to decide which process to run next.",
        "notes": "Chapter 4 focuses on CPU scheduling, a fundamental function of an operating system that is crucial for multitasking and system performance. The primary goal of CPU scheduling is to maximize CPU utilization by ensuring that the CPU is always busy executing a process. In a multiprogramming system, multiple processes are kept in the 'ready' queue, waiting for their turn on the CPU. The CPU scheduler is the component of the OS that selects one of these processes and allocates the CPU to it. This decision-making process is governed by scheduling algorithms. The choice of algorithm can have a significant impact on system performance metrics such as throughput (the number of processes completed per unit time), turnaround time (the total time taken from submission to completion), waiting time (the time a process spends in the ready queue), and response time (the time from submission until the first response is produced). This chapter will explore a variety of classical scheduling algorithms, starting with the simplest, First-Come, First-Served (FCFS). We will then analyze more sophisticated algorithms like Shortest-Job-First (SJF), which is provably optimal but difficult to implement in practice, and Priority Scheduling, where each process is assigned a priority. We will also cover Round Robin (RR), an algorithm designed for time-sharing systems, and conclude with advanced concepts like Multilevel Queue Scheduling, which classifies processes into different groups for more tailored scheduling.",
        "code": "",
        "duration": "Week 4",
        "topics": [
          {
            "id": "t9-fcfs-sjf",
            "title": "FCFS and SJF Scheduling",
            "desc": "Learn the First-Come, First-Served and Shortest-Job-First scheduling algorithms.",
            "note": "First-Come, First-Served (FCFS) is the simplest CPU scheduling algorithm. As the name implies, the process that requests the CPU first is allocated the CPU first. The implementation is straightforward, managed with a simple FIFO (First-In, First-Out) queue. When a process enters the ready queue, its PCB is linked onto the tail of the queue. When the CPU becomes free, it is allocated to the process at the head of the queue. While FCFS is easy to understand and implement, its performance is often poor. The average waiting time can be quite long, particularly if a short process gets stuck behind a very long one. This phenomenon is known as the 'convoy effect.' FCFS is a non-preemptive algorithm, meaning once a process has the CPU, it keeps it until it either terminates or performs an I/O request. Shortest-Job-First (SJF), on the other hand, prioritizes processes based on the length of their next CPU burst. The scheduler selects the process with the smallest estimated execution time. SJF is provably optimal, as it gives the minimum average waiting time for a given set of processes. However, its major challenge is predicting the length of the next CPU burst. For short-term scheduling, this is typically done using an exponential average of the process's previous CPU bursts. SJF can be either preemptive or non-preemptive. The preemptive version, known as Shortest-Remaining-Time-First (SRTF), will interrupt a running process if a new process with a shorter remaining time arrives.",
            "code": "// Example 1: Python simulation of FCFS Scheduling.\ndef fcfs_scheduling(processes):\n    \"\"\"Calculates waiting time for FCFS.\"\"\"\n    wait_time = [0] * len(processes)\n    completion_time = 0\n    for i, (pid, burst) in enumerate(processes):\n        if i == 0:\n            completion_time = burst\n        else:\n            wait_time[i] = completion_time\n            completion_time += burst\n        print(f\"Process {pid} runs. Wait time: {wait_time[i]}\")\n    print(f\"Average Wait Time: {sum(wait_time)/len(processes)}\")\n\n# Processes are (ID, Burst Time)\nproc_list = [('P1', 24), ('P2', 3), ('P3', 3)]\nfcfs_scheduling(proc_list)\n\n// Example 2: Python simulation of non-preemptive SJF Scheduling.\ndef sjf_scheduling(processes):\n    \"\"\"Calculates waiting time for SJF.\"\"\"\n    # Sort processes by burst time\n    processes.sort(key=lambda x: x[1])\n    print(\"SJF Order:\", [p[0] for p in processes])\n    fcfs_scheduling(processes) # SJF is FCFS on a sorted list\n\nproc_list_sjf = [('P1', 6), ('P2', 8), ('P3', 7), ('P4', 3)]\nsjf_scheduling(proc_list_sjf)"
          },
          {
            "id": "t10-priority-rr",
            "title": "Priority and Round Robin Scheduling",
            "desc": "Explore Priority scheduling and the time-sharing based Round Robin algorithm.",
            "note": "Priority Scheduling is an algorithm where each process is assigned a priority value. The CPU is allocated to the process with the highest priority. In cases of equal priority, FCFS is typically used to break ties. Priorities can be defined either internally, based on criteria like memory requirements or CPU burst time, or externally, based on importance factors set by the system administrator. Priority scheduling can be either preemptive or non-preemptive. In a preemptive scheme, if a new process arrives with a higher priority than the currently running process, the CPU is taken away from the current process and given to the new one. A major problem with priority scheduling is indefinite blocking, or starvation, where low-priority processes may never execute. A common solution to this is 'aging,' a technique where the priority of a process is gradually increased the longer it waits in the system. Round Robin (RR) scheduling is designed specifically for time-sharing systems. It is similar to FCFS but adds preemption to allow the system to switch between processes. A small unit of time, called a time quantum or time slice (typically 10-100 milliseconds), is defined. The ready queue is treated as a circular queue. The CPU scheduler goes around the ready queue, allocating the CPU to each process for a time interval of up to one time quantum. If the process's CPU burst is longer than the quantum, it is preempted and put at the end of the ready queue. If it finishes its burst in less than a quantum, it releases the CPU voluntarily. The performance of RR depends heavily on the size of the time quantum. A very large quantum makes RR behave like FCFS, while a very small quantum leads to excessive context switching overhead.",
            "code": "// Example 1: Python simulation of Round Robin Scheduling.\nfrom collections import deque\n\ndef round_robin(processes, quantum):\n    queue = deque(processes.copy())\n    time = 0\n    while queue:\n        pid, burst = queue.popleft()\n        print(f\"Time {time}: Running {pid}\")\n        if burst > quantum:\n            time += quantum\n            burst -= quantum\n            queue.append((pid, burst))\n            print(f\"Time {time}: {pid} preempted, {burst} remaining.\")\n        else:\n            time += burst\n            print(f\"Time {time}: {pid} finished.\")\n\nproc_list = [('P1', 10), ('P2', 5), ('P3', 8)]\nround_robin(proc_list, 4)\n\n// Example 2: Pseudocode for Priority Scheduling logic.\nstruct Process { int id; int priority; };\nProcess ready_queue[];\n\nProcess get_next_process() {\n    if (is_empty(ready_queue)) return NULL;\n    \n    // Find the process with the highest priority\n    Process highest_priority_proc = ready_queue[0];\n    for (int i = 1; i < queue_size; i++) {\n        // Lower number means higher priority\n        if (ready_queue[i].priority < highest_priority_proc.priority) {\n            highest_priority_proc = ready_queue[i];\n        }\n    }\n    return highest_priority_proc;\n}"
          }
        ]
      },
      {
        "id": "c5-process-synchronization",
        "title": "Process Synchronization",
        "desc": "Grasp the challenges of concurrent processing and solutions like semaphores and monitors.",
        "notes": "Chapter 5 tackles the complex issue of process synchronization. When multiple processes or threads run concurrently and share data, their execution order must be controlled to ensure data consistency. The core of the problem lies in the 'critical section,' a segment of code where a shared resource is accessed. If multiple processes execute their critical sections simultaneously, a 'race condition' can occur, where the final state of the shared data depends on the unpredictable order in which the processes execute. This can lead to corrupted data and incorrect program behavior. To prevent this, we need synchronization mechanisms that enforce 'mutual exclusion,' ensuring that only one process can be in its critical section at any given time. This chapter introduces several classical solutions to the critical-section problem. We will start with software-based solutions and then move to more robust hardware support. The main focus will be on higher-level synchronization tools provided by the operating system. We will explore semaphores, which are simple integer variables used to control access to shared resources through two atomic operations: `wait()` and `signal()`. We will also cover monitors, which are a higher-level abstraction that encapsulates shared data and the operations on it, providing a more structured and less error-prone way to achieve mutual exclusion. Finally, the chapter will provide a basic introduction to deadlocks, a problematic situation where two or more processes are stuck waiting for each other indefinitely, which will be covered in detail in a later chapter.",
        "code": "",
        "duration": "Week 5",
        "topics": [
          {
            "id": "t11-critical-section",
            "title": "The Critical-Section Problem",
            "desc": "Understand race conditions and the requirements for solving the critical-section problem.",
            "note": "The critical-section problem is a fundamental challenge in concurrent programming. It arises whenever multiple processes or threads need to access and manipulate shared data. The part of the program where this shared data is accessed is called the critical section. A 'race condition' is a situation where the system's behavior depends on the sequence or timing of uncontrollable events—specifically, the order in which multiple threads execute. If two threads try to modify the same shared variable at the same time, the result can be unpredictable and incorrect. For example, consider two threads trying to increment a shared counter. This operation, which seems atomic (indivisible) in a high-level language, is actually composed of three machine instructions: load the value from memory into a register, increment the register, and store the new value back to memory. If the OS switches from one thread to the other after the first thread has loaded the value but before it has stored it back, the second thread will load the same original value. Both threads will then store their incremented value, but because they started from the same initial value, one of the increments will be lost. A valid solution to the critical-section problem must satisfy three requirements: 1) Mutual Exclusion: If one process is executing in its critical section, no other processes can be executing in their critical sections. 2) Progress: If no process is in its critical section and some processes wish to enter, then only those processes that are not in their remainder sections can participate in the decision of which will enter its critical section next, and this selection cannot be postponed indefinitely. 3) Bounded Waiting: There must be a limit on the number of times that other processes are allowed to enter their critical sections after a process has made a request to enter its critical section and before that request is granted.",
            "code": "// Example 1: Python demonstrating a race condition.\nimport threading\n\ncounter = 0\n\ndef increment():\n    global counter\n    for _ in range(1000000):\n        counter += 1\n\nt1 = threading.Thread(target=increment)\nt2 = threading.Thread(target=increment)\nt1.start()\nt2.start()\nt1.join()\nt2.join()\n\n# The expected result is 2,000,000, but it will likely be less due to the race condition.\nprint(f\"Final counter (with race condition): {counter}\")\n\n// Example 2: Python solving the race condition with a Lock (a mutual exclusion mechanism).\nimport threading\n\ncounter_safe = 0\nlock = threading.Lock()\n\ndef increment_safe():\n    global counter_safe\n    for _ in range(1000000):\n        lock.acquire() # Enter critical section\n        counter_safe += 1\n        lock.release() # Exit critical section\n\nt1_safe = threading.Thread(target=increment_safe)\nt2_safe = threading.Thread(target=increment_safe)\nt1_safe.start()\nt2_safe.start()\nt1_safe.join()\nt2_safe.join()\n\nprint(f\"Final counter (with lock): {counter_safe}\")"
          },
          {
            "id": "t12-semaphores",
            "title": "Semaphores",
            "desc": "Learn how semaphores work as a synchronization tool.",
            "note": "A semaphore is a versatile synchronization tool provided by the operating system to solve complex critical-section problems. It is essentially an integer variable that, apart from initialization, is accessed only through two standard, atomic (indivisible) operations: `wait()` and `signal()`. The `wait()` operation, originally called P (from the Dutch *proberen*, 'to test'), decrements the semaphore's value. If the value becomes negative, the process executing the `wait()` is blocked and placed into a waiting queue associated with the semaphore. The `signal()` operation, originally called V (from *verhogen*, 'to increment'), increments the semaphore's value. If there are any processes waiting on the semaphore, one of them is unblocked and moved to the ready queue. There are two main types of semaphores. A 'counting semaphore' can have an unrestricted integer value and is used to control access to a resource with a finite number of instances. The semaphore is initialized to the number of available resources. Each time a process wishes to use a resource, it performs a `wait()` on the semaphore. When it's done, it performs a `signal()`. If no resources are available, the process blocks until one is freed. A 'binary semaphore,' also known as a mutex lock, can only have the values 0 or 1. It is used to provide mutual exclusion, ensuring only one process at a time can enter a critical section. The semaphore is initialized to 1. The critical section is guarded by a `wait()` call at the start and a `signal()` call at the end.",
            "code": "// Example 1: Python using a Semaphore to limit access to a pool of resources (e.g., database connections).\nimport threading\nimport time\n\n# Only 3 threads can access the resource at once.\nsemaphore = threading.Semaphore(3)\n\ndef access_resource(thread_id):\n    print(f\"Thread {thread_id} is trying to acquire.\")\n    semaphore.acquire() # wait()\n    print(f\"Thread {thread_id} has acquired the resource.\")\n    time.sleep(2)\n    print(f\"Thread {thread_id} is releasing the resource.\")\n    semaphore.release() # signal()\n\nthreads = [threading.Thread(target=access_resource, args=(i,)) for i in range(5)]\nfor t in threads:\n    t.start()\nfor t in threads:\n    t.join()\n\n// Example 2: Java using a Semaphore as a mutex for a critical section.\nimport java.util.concurrent.Semaphore;\n\nclass CriticalSection {\n    private static Semaphore mutex = new Semaphore(1); // Binary semaphore\n\n    static void access(String threadName) {\n        try {\n            mutex.acquire();\n            System.out.println(threadName + \" is in the critical section.\");\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            System.out.println(threadName + \" is leaving the critical section.\");\n            mutex.release();\n        }\n    }\n\n    public static void main(String[] args) {\n        new Thread(() -> access(\"Thread A\")).start();\n        new Thread(() -> access(\"Thread B\")).start();\n    }\n}"
          }
        ]
      },
      {
        "id": "c6-memory-management",
        "title": "Memory Management",
        "desc": "Explore techniques for managing main memory, including paging, segmentation, and virtual memory.",
        "notes": "Chapter 6 covers memory management, one of the most critical responsibilities of the operating system. Main memory (RAM) is a vital but limited resource that must be carefully allocated among processes. This chapter explains the various strategies the OS employs to handle this task. We begin with basic techniques like contiguous memory allocation, where each process is contained in a single, contiguous section of memory. This approach suffers from 'external fragmentation,' where there is enough total free memory to satisfy a request, but it is not contiguous; it's broken into many small pieces. To solve this, we introduce two powerful and widely used non-contiguous allocation techniques: paging and segmentation. Paging divides a process's logical address space into fixed-size blocks called pages and divides physical memory into frames of the same size. The OS maintains a page table for each process to map logical pages to physical frames, allowing a process's memory to be scattered throughout physical RAM. Segmentation, on the other hand, divides the address space into logical units like a main program, subroutines, and data structures. The highlight of the chapter is the concept of virtual memory, a technique that allows the execution of processes that may not be completely in memory. It creates the illusion of a much larger main memory than is physically available. This is typically implemented using demand paging, where pages are loaded from the disk into memory only when they are needed, enabling us to run larger programs and increase the degree of multiprogramming.",
        "code": "",
        "duration": "Week 6",
        "topics": [
          {
            "id": "t13-paging",
            "title": "Paging",
            "desc": "Learn how paging allows for non-contiguous memory allocation and avoids external fragmentation.",
            "note": "Paging is a sophisticated memory management scheme that eliminates the need for a process's physical address space to be contiguous. It is the predominant memory allocation method in modern operating systems. The core idea is to divide both logical memory (the address space as seen by the process) and physical memory (the actual RAM) into fixed-size blocks. The blocks of logical memory are called 'pages,' and the blocks of physical memory are called 'frames.' Page and frame sizes are always the same, typically a power of 2, such as 4KB. When a process is to be executed, its pages are loaded into any available frames from the physical memory. To keep track of this mapping, the operating system maintains a separate 'page table' for each process. The page table contains one entry for each page in the process's logical address space, and each entry stores the frame number in physical memory where the corresponding page is located. The CPU generates logical addresses, which consist of a page number and an offset within that page. The memory management unit (MMU), a hardware component, uses the page number as an index into the process's page table. It retrieves the corresponding frame number from the table and combines it with the offset to form the final physical address, which is then sent to the memory unit. The primary advantage of paging is that it completely avoids external fragmentation. Any free frame can be allocated to a process that needs it. However, it can introduce 'internal fragmentation,' where a process may not need the entire space of its last page, leaving that part of the frame unused.",
            "code": "// Example 1: C++ code to simulate logical to physical address translation in a paging system.\n#include <iostream>\n#include <vector>\n\nvoid translate_address(int logical_addr, const std::vector<int>& page_table, int page_size) {\n    int page_num = logical_addr / page_size;\n    int offset = logical_addr % page_size;\n    \n    if (page_num >= page_table.size()) {\n        std::cout << \"Invalid page number.\" << std::endl;\n        return;\n    }\n    \n    int frame_num = page_table[page_num];\n    int physical_addr = (frame_num * page_size) + offset;\n    \n    std::cout << \"Logical Address: \" << logical_addr\n              << \" -> Page: \" << page_num << \", Offset: \" << offset\n              << \" -> Frame: \" << frame_num \n              << \" -> Physical Address: \" << physical_addr << std::endl;\n}\n\nint main() {\n    // Page table: page 0->frame 5, page 1->frame 9, page 2->frame 14\n    std::vector<int> page_table = {5, 9, 14};\n    int page_size = 4096; // 4KB pages\n    translate_address(7000, page_table, page_size);\n    return 0;\n}\n\n// Example 2: Python simulation of the same address translation.\ndef translate_address_py(logical_addr, page_table, page_size):\n    page_num = logical_addr // page_size\n    offset = logical_addr % page_size\n\n    if page_num >= len(page_table):\n        print(\"Invalid page number.\")\n        return\n\n    frame_num = page_table[page_num]\n    physical_addr = (frame_num * page_size) + offset\n\n    print(f\"Logical: {logical_addr} -> Physical: {physical_addr}\")\n\npage_table_py = {0: 5, 1: 9, 2: 14} # Using a dictionary for clarity\npage_size_py = 4096\ntranslate_address_py(10000, [page_table_py.get(i) for i in range(max(page_table_py)+1)], page_size_py)"
          },
          {
            "id": "t14-virtual-memory",
            "title": "Virtual Memory",
            "desc": "Understand how virtual memory allows a process to be larger than physical memory.",
            "note": "Virtual memory is a revolutionary memory management technique that allows the execution of processes that are not completely loaded into physical memory. It creates the illusion that each process has its own private and vast contiguous address space (the virtual address space), which can be much larger than the actual physical RAM available. This provides several significant benefits. It allows programmers to write programs without being constrained by the limits of physical memory. It enables a higher degree of multiprogramming because more processes can be kept in memory, as only the necessary parts of each process need to be loaded. It also reduces the I/O needed for loading or swapping processes, leading to faster startup times. The most common implementation of virtual memory is 'demand paging.' This works similarly to a regular paging system, but with a key difference: when a process starts, the OS loads none of its pages into memory initially. Instead, it waits until the CPU tries to access a page. When a reference is made to a page that is not in memory, the MMU hardware generates a 'page fault' trap to the operating system. The OS then finds the required page on the disk, locates a free frame in physical memory (or swaps out an existing page if no frames are free), loads the required page into that frame, updates the page table to reflect the change, and finally, resumes the process as if the memory access had been successful all along. This 'lazy loading' approach ensures that only the parts of a program that are actually used are brought into memory.",
            "code": "// Example 1: Pseudocode illustrating the OS handling a page fault.\nvoid page_fault_handler(virtual_address) {\n    1. Check if the address is valid for the process.\n       If not, terminate the process (segmentation fault).\n\n    2. Find a free frame in physical memory.\n       If no frame is free, select a victim frame using a page replacement algorithm (e.g., LRU).\n\n    3. If a victim frame was selected, write its contents back to disk if it has been modified.\n\n    4. Load the required page from the disk into the now-free frame.\n\n    5. Update the process's page table to map the virtual page to the new physical frame.\n       Set the 'valid' bit for this page table entry to 1.\n\n    6. Restart the instruction that caused the fault.\n}\n\n// Example 2: Python simulation of page replacement (FIFO algorithm).\nfrom collections import deque\n\ndef fifo_page_replacement(page_references, frame_size):\n    frames = deque(maxlen=frame_size)\n    page_faults = 0\n    for page in page_references:\n        if page not in frames:\n            page_faults += 1\n            # If frames are full, the oldest (leftmost) is replaced.\n            frames.append(page)\n            print(f\"Page {page} caused a fault. Frames: {list(frames)}\")\n        else:\n            print(f\"Page {page} was a hit. Frames: {list(frames)}\")\n    print(f\"Total Page Faults: {page_faults}\")\n\npage_stream = [1, 3, 0, 3, 5, 6, 3]\nfifo_page_replacement(page_stream, 3)"
          }
        ]
      },
      {
        "id": "c7-storage-files",
        "title": "Storage & File Systems",
        "desc": "Learn about file system structures, allocation methods, and popular file systems like FAT, NTFS, and ext4.",
        "notes": "Chapter 7 shifts our focus from memory to secondary storage, specifically how the operating system manages files and disks. A file is a logical unit of information, a collection of related data that is given a name and stored on a secondary storage device like a hard disk or SSD. The operating system provides a uniform logical view of information storage through the file system. The file system is responsible for organizing files in a structured way (typically a directory hierarchy), managing the mapping of logical file blocks to physical blocks on the storage device, and controlling access to files. This chapter will explore the fundamental components of a file system, including file attributes (name, type, size, permissions), file operations (create, read, write, delete), and directory structures. A major part of the discussion will be on disk space allocation methods. We will examine how the OS decides where to place file data on the disk, covering techniques like Contiguous Allocation, Linked Allocation, and Indexed Allocation, each with its own trade-offs regarding speed, flexibility, and fragmentation. Finally, we will look at real-world examples of file systems. We will discuss the classic File Allocation Table (FAT) system used in early PCs, the more advanced New Technology File System (NTFS) used in modern Windows, and the ext4 file system, which is the standard for many Linux distributions. Understanding these systems will provide insight into how features like journaling, permissions, and large file support are implemented.",
        "code": "",
        "duration": "Week 7",
        "topics": [
          {
            "id": "t15-filesystems",
            "title": "File System Structure",
            "desc": "Understand the logical structure of a file system, including directories and file access methods.",
            "note": "A file system imposes a structure on the vast, raw space of a storage device, allowing data to be stored, organized, and retrieved efficiently. The most fundamental concept is the 'file,' which is an abstraction provided by the OS to store information. From the user's perspective, a file is the smallest logical unit of storage. To manage these files, the OS uses 'directories' (or folders). A directory is itself a special type of file that contains information about other files and directories. This organization is almost always hierarchical, forming a tree structure. At the top of the hierarchy is the root directory. This structure allows for logical grouping of files and avoids naming conflicts. To navigate this structure, we use paths. An 'absolute path' specifies a file's location starting from the root directory (e.g., `/home/user/document.txt`), while a 'relative path' specifies the location relative to the current working directory. The OS also defines various 'file access methods.' The simplest is Sequential Access, where information in the file is processed in order, one record after another. This is based on the model of a tape drive and is common for text files. Direct Access (or Relative Access) allows a program to read or write records rapidly in no particular order. The file is viewed as a numbered sequence of blocks or records, and any block can be accessed directly by its number. This is essential for database applications. Other, more complex access methods can be built on top of direct access, such as indexed access, which uses an index to look up record locations based on a key value.",
            "code": "// Example 1: Java code to interact with the file system directory structure.\nimport java.io.File;\n\npublic class FileSystemDemo {\n    public static void main(String[] args) {\n        // The OS provides an abstraction for directories.\n        File currentDir = new File(\".\"); // Get current directory\n\n        System.out.println(\"Absolute path: \" + currentDir.getAbsolutePath());\n        System.out.println(\"\\nFiles in current directory:\");\n        \n        // The OS provides a way to list directory contents.\n        String[] files = currentDir.list();\n        if (files != null) {\n            for (String file : files) {\n                System.out.println(file);\n            }\n        }\n    }\n}\n\n// Example 2: Python script demonstrating sequential vs. direct (seek) access.\nfile_name = \"access_demo.txt\"\n\n# Sequential Write\nwith open(file_name, 'w') as f:\n    f.write(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n\nwith open(file_name, 'r') as f:\n    # Sequential Read (first 5 bytes)\n    print(\"Sequential read: \", f.read(5))\n\n    # Direct Access: move the cursor to the 10th byte (index 9)\n    f.seek(9)\n    print(\"Direct access read from index 9: \", f.read(5))\n\nimport os\nos.remove(file_name)"
          },
          {
            "id": "t16-allocation-methods",
            "title": "Allocation Methods",
            "desc": "Explore how file systems allocate disk space: Contiguous, Linked, and Indexed.",
            "note": "Allocation methods deal with how disk blocks are allocated for files. There are three primary strategies. The first is Contiguous Allocation, where each file occupies a set of contiguous blocks on the disk. This method is simple and offers excellent performance for sequential reading because the disk head doesn't have to move much to read the entire file. However, it suffers from significant problems. It requires knowing the file's size at the time of creation, which isn't always possible. More importantly, it suffers from external fragmentation, making it difficult to find contiguous chunks of space for new files as the disk fills up. The second method is Linked Allocation. Here, each file is a linked list of disk blocks, which can be scattered anywhere on the disk. The directory contains a pointer to the first and last blocks of the file. Each block, in turn, contains a pointer to the next block in the sequence. This solves the external fragmentation problem, and there's no need to declare a file's size upfront. However, it's inefficient for direct access, as locating a specific block requires traversing the list from the beginning. It also has poor reliability; if one pointer is lost or damaged, the rest of the file becomes inaccessible. The third method, Indexed Allocation, addresses the shortcomings of the others. It brings all the pointers for a file together into one location: an 'index block.' Each file has its own index block, which is an array of disk block addresses. The directory entry for the file points to this index block. To find the Nth block of the file, we simply look at the Nth entry in the index block. This supports direct access efficiently and avoids external fragmentation. Its main disadvantage is the overhead of the index block itself.",
            "code": "// Example 1: Pseudocode for reading a file with Linked Allocation.\nBlock read_linked_file(FileEntry file, int block_num) {\n    // Start at the first block of the file.\n    Block current_block = read_disk(file.start_block_addr);\n    \n    // Traverse the linked list.\n    for (int i = 0; i < block_num; i++) {\n        if (current_block.next_block_addr == NULL) {\n            return ERROR; // Block number is out of bounds\n        }\n        current_block = read_disk(current_block.next_block_addr);\n    }\n    return current_block;\n}\n\n// Example 2: Pseudocode for reading a file with Indexed Allocation.\nBlock read_indexed_file(FileEntry file, int block_num) {\n    // First, read the index block for the file.\n    IndexBlock index_block = read_disk(file.index_block_addr);\n\n    if (block_num >= index_block.size) {\n        return ERROR; // Block number out of bounds\n    }\n    \n    // Directly find the address of the desired data block.\n    address data_block_addr = index_block.pointers[block_num];\n    \n    // Read and return the data block.\n    return read_disk(data_block_addr);\n}"
          }
        ]
      },
      {
        "id": "c8-io-systems",
        "title": "I/O Systems & Device Management",
        "desc": "Learn how the OS manages I/O hardware, drivers, and operations like buffering.",
        "notes": "Chapter 8 explores the intricate world of I/O (Input/Output) systems, a critical part of the operating system that manages the computer's interaction with a wide array of peripheral devices. The primary goal of the I/O subsystem is to provide a simple, standard, and abstract interface for applications to interact with devices, while also managing these devices efficiently. We'll start by looking at I/O hardware, including ports, buses, and device controllers. The core of OS interaction with hardware is the 'device driver.' Each device controller has a corresponding device driver, which is a piece of software that understands the specific device and presents a uniform interface to the I/O subsystem. A key concept in I/O is the 'interrupt.' Instead of the CPU constantly checking a device's status (a process called polling), devices can send an interrupt signal to the CPU when they are ready for service. This is a much more efficient way to handle I/O. We will also cover techniques the OS uses to improve performance and manage data flow, such as 'buffering' (using a memory area to temporarily store data while it's being transferred between devices or between a device and an application), 'caching' (storing a copy of data in a faster memory for future use), and 'spooling' (holding data for a device, like a printer, in a buffer on disk until the device is ready).",
        "code": "",
        "duration": "Week 8",
        "topics": [
          {
            "id": "t17-interrupts",
            "title": "Interrupts",
            "desc": "Understand the role of interrupts in I/O management and how the OS handles them.",
            "note": "Interrupts are the cornerstone of modern operating system I/O management. An interrupt is a signal sent to the CPU by a hardware device, indicating that an event has occurred that needs immediate attention. This mechanism allows the OS to handle I/O asynchronously, which is far more efficient than the alternative, known as 'polling.' In a polling system, the CPU would have to repeatedly check the status of each I/O device to see if it has completed its task (e.g., 'Has the disk finished reading the data yet?'). This is incredibly wasteful of CPU cycles. With an interrupt-driven system, the CPU can start an I/O operation (e.g., tell the disk controller to read a block of data) and then switch to executing another process. It doesn't need to worry about the I/O operation anymore. When the disk controller has finished reading the data and has it ready in its buffer, it sends an interrupt signal to the CPU. The CPU then suspends what it was doing, saves its current state, and transfers control to a specific piece of code in the OS called the 'interrupt service routine' (ISR) or interrupt handler. This handler determines the cause of the interrupt, performs the necessary processing (e.g., moves the data from the disk controller's buffer into main memory), and then restores the state of the interrupted process, allowing it to continue as if nothing happened. This mechanism ensures the CPU is not idle while waiting for slow I/O devices, dramatically improving overall system throughput and responsiveness.",
            "code": "// Example 1: Pseudocode for an Interrupt Service Routine (ISR) for a keyboard.\nvoid keyboard_interrupt_handler() {\n    // 1. Acknowledge the interrupt to the interrupt controller.\n    acknowledge_interrupt();\n\n    // 2. Read the scancode from the keyboard controller's data port.\n    char scancode = inb(KEYBOARD_DATA_PORT);\n\n    // 3. Translate the scancode to an ASCII character.\n    char character = translate_scancode(scancode);\n\n    // 4. Place the character into the keyboard buffer for a waiting process to read.\n    add_to_keyboard_buffer(character);\n    \n    // 5. Signal any process that was waiting for keyboard input.\n    wakeup(process_waiting_on_keyboard);\n    \n    // 6. Return from interrupt, restoring the previously running process.\n    iret();\n}\n\n// Example 2: Python using an 'event' to simulate interrupt-driven I/O.\n// A worker thread simulates the hardware, and the main thread waits on an event.\nimport threading\nimport time\n\n# This event simulates the interrupt signal.\nio_complete_event = threading.Event()\n\ndef simulate_io_device():\n    print(\"Device: Starting long I/O operation...\")\n    time.sleep(3)\n    print(\"Device: I/O complete! Sending interrupt.\")\n    io_complete_event.set() # Fire the 'interrupt'\n\nprint(\"Main: Starting I/O operation.\")\nthreading.Thread(target=simulate_io_device).start()\n\nprint(\"Main: I/O started. Waiting for interrupt...\")\nio_complete_event.wait() # The 'CPU' blocks until the 'interrupt' is received.\n\nprint(\"Main: Interrupt received! Processing data.\")"
          },
          {
            "id": "t18-drivers",
            "title": "Device Drivers",
            "desc": "Learn the function of device drivers as the interface between the OS and hardware.",
            "note": "A device driver is a specialized type of software program that acts as a translator between the operating system and a specific hardware device. Every piece of hardware, from a simple mouse to a complex graphics card, has a unique set of commands and registers that it uses to function. The operating system's I/O subsystem cannot possibly know the intricate details of every device ever made. Instead, it defines a standard, abstract interface for different classes of devices (e.g., a standard way to interact with all 'block storage devices' or all 'network interfaces'). The device driver's job is to implement this standard interface while handling the specific, low-level details of its particular hardware. When the OS wants to perform an action, such as writing data to a disk, it calls a generic function in the corresponding device driver (e.g., `disk_write()`). The driver then translates this high-level request into the precise sequence of register writes and commands that the specific disk controller hardware understands. This abstraction is incredibly powerful. It allows hardware manufacturers to create new devices without needing to modify the operating system itself; they just need to provide a driver that conforms to the OS's standards. It also allows application programmers to interact with devices using simple, high-level commands (like `write()`) without needing to know anything about the underlying hardware. The driver is responsible for device initialization, registering itself with the OS, managing data transfer, handling power management, and processing interrupts from the device.",
            "code": "// Example 1: Pseudocode for a simplified character device driver structure in a Linux-like kernel.\nstruct file_operations my_device_ops = {\n    .owner = THIS_MODULE,\n    .open = my_device_open,     // Called when a user opens the device file\n    .release = my_device_release, // Called when the file is closed\n    .read = my_device_read,       // Called on a read() system call\n    .write = my_device_write      // Called on a write() system call\n};\n\n// Function to handle reading from the device.\nssize_t my_device_read(struct file *filp, char *buffer, size_t len, loff_t *off) {\n    // 1. Copy data from our device's internal buffer to the user-space buffer.\n    // 2. Return the number of bytes successfully copied.\n    return 0; // Placeholder\n}\n\n// Example 2: Python using the 'pySerial' library, which acts as a driver for serial ports.\n// The library abstracts the low-level OS calls and hardware control.\nimport serial\nimport time\n\ntry:\n    # The 'serial.Serial' object is like a handle to the device driver.\n    # It finds the correct driver ('COM3' on Windows, '/dev/ttyUSB0' on Linux)\n    # and initializes the hardware.\n    ser = serial.Serial('COM3', 9600, timeout=1)\n    time.sleep(2) // Wait for the device to initialize\n\n    # The library translates this high-level write into low-level operations.\n    ser.write(b'Hello Device\\n')\n    print(\"Sent 'Hello Device'\")\n\n    # The driver handles waiting for and reading data from the hardware.\n    response = ser.readline()\n    print(f\"Received: {response.decode()}\")\n\n    ser.close()\nexcept serial.SerialException as e:\n    print(f\"Could not open serial port: {e}\")"
          }
        ]
      },
      {
        "id": "c9-deadlocks",
        "title": "Deadlocks",
        "desc": "Gain a deep understanding of deadlocks, including their conditions, prevention, and avoidance strategies.",
        "notes": "Chapter 9 is dedicated to a serious problem in concurrent systems known as deadlock. A deadlock is a state in which a set of two or more processes are blocked forever, each waiting for a resource that is held by another process in the same set. This creates a circular dependency that can never be resolved without outside intervention, effectively grinding a part of the system to a halt. The chapter begins by identifying the four necessary conditions that must hold simultaneously for a deadlock to occur: Mutual Exclusion (a resource can only be used by one process at a time), Hold and Wait (a process holds at least one resource while waiting for another), No Preemption (a resource can only be released voluntarily by the process holding it), and Circular Wait (a set of processes {P0, P1, ... Pn} exists where P0 is waiting for a resource held by P1, P1 is waiting for a resource held by P2, and so on, with Pn waiting for a resource held by P0). Once these conditions are understood, we can explore various strategies for handling deadlocks. These strategies include Deadlock Prevention, which involves ensuring that at least one of the four necessary conditions can never hold. Another approach is Deadlock Avoidance, where the OS uses information about the maximum resource needs of each process to make decisions that guarantee the system will never enter a deadlocked state. We will also discuss Deadlock Detection and Recovery, a strategy that allows deadlocks to occur, detects them, and then takes action to break the deadlock, for example, by terminating one or more of the deadlocked processes.",
        "code": "",
        "duration": "Week 9",
        "topics": [
          {
            "id": "t19-deadlock-conditions",
            "title": "Conditions for Deadlock",
            "desc": "Learn the four necessary conditions for a deadlock to occur.",
            "note": "For a deadlock to arise in a system, four specific conditions must be met simultaneously. If any one of these conditions is not present, a deadlock cannot occur. Understanding them is the first step toward preventing or handling deadlocks. The first condition is Mutual Exclusion. At least one resource must be held in a non-sharable mode; that is, only one process at a time can use the resource. If another process requests that resource, the requesting process must be delayed until the resource has been released. This is a fundamental requirement for resources like printers or files being written to. The second condition is Hold and Wait. A process must be holding at least one resource and waiting to acquire additional resources that are currently being held by other processes. This creates a situation where processes are partially allocated resources, preventing others from making progress. The third condition is No Preemption. Resources cannot be preempted; that is, a resource can be released only voluntarily by the process holding it, after that process has completed its task. The system cannot forcibly take a resource away from a process. The fourth and final condition is Circular Wait. There must exist a set of waiting processes {P0, P1, ..., Pn} such that P0 is waiting for a resource held by P1, P1 is waiting for a resource held by P2, ..., Pn-1 is waiting for a resource held by Pn, and Pn is waiting for a resource held by P0. This creates a cycle of dependencies where no process can proceed.",
            "code": "// Example 1: Python code demonstrating a deadlock scenario with two threads and two locks.\nimport threading\nimport time\n\nlock_a = threading.Lock()\nlock_b = threading.Lock()\n\ndef thread_1():\n    print(\"Thread 1: Acquiring lock A...\")\n    lock_a.acquire()\n    print(\"Thread 1: Acquired lock A. Waiting for lock B...\")\n    time.sleep(1)\n    lock_b.acquire() # Will block here\n    print(\"Thread 1: Acquired both locks.\")\n    lock_b.release()\n    lock_a.release()\n\ndef thread_2():\n    print(\"Thread 2: Acquiring lock B...\")\n    lock_b.acquire()\n    print(\"Thread 2: Acquired lock B. Waiting for lock A...\")\n    time.sleep(1)\n    lock_a.acquire() # Will block here\n    print(\"Thread 2: Acquired both locks.\")\n    lock_a.release()\n    lock_b.release()\n\nt1 = threading.Thread(target=thread_1)\nt2 = threading.Thread(target=thread_2)\nt1.start()\nt2.start()\nt1.join()\nt2.join()\nprint(\"This line will never be reached.\")\n\n// Example 2: Pseudocode for a Resource Allocation Graph to detect cycles.\n// If a cycle exists in this graph, a deadlock may exist.\nGraph g;\nfor each process P:\n    for each resource R held by P:\n        add_edge(R -> P) // Resource R is assigned to Process P\n    for each resource S that P is requesting:\n        add_edge(P -> S) // Process P is waiting for Resource S\n\nif (has_cycle(g)) {\n    print(\"Potential deadlock detected!\");\n} else {\n    print(\"No deadlock detected.\");\n}"
          },
          {
            "id": "t20-deadlock-prevention-avoidance",
            "title": "Deadlock Prevention and Avoidance",
            "desc": "Study strategies to prevent deadlocks from occurring or avoid entering an unsafe state.",
            "note": "Deadlock Prevention and Avoidance are proactive strategies for dealing with deadlocks. Deadlock Prevention works by ensuring that at least one of the four necessary conditions for deadlock cannot hold. To negate Mutual Exclusion, one could make resources sharable, but this isn't always possible (e.g., a printer). To negate Hold and Wait, the system can require a process to request all its resources before it begins execution, or to release all its current resources before requesting new ones. This can lead to low resource utilization and potential starvation. To negate No Preemption, if a process holding some resources requests another resource that cannot be immediately allocated, it must release all its current resources. To negate Circular Wait, the system can impose a total ordering of all resource types and require that each process requests resources in an increasing order of enumeration. Deadlock Avoidance, on the other hand, requires the operating system to have additional information in advance about which resources a process will request. The OS can then use this information to decide whether a process's request should be granted or delayed. The system must ensure it never enters an 'unsafe state'—a state from which a deadlock might occur. The most famous avoidance algorithm is the Banker's Algorithm. When a process requests a resource, the algorithm checks if granting the request would leave the system in a safe state. A state is safe if there is some sequence of process executions that allows all processes to finish. If granting the request leads to an unsafe state, the process must wait, even if the resource is currently available.",
            "code": "// Example 1: Python code demonstrating deadlock prevention by enforcing a lock order.\nimport threading\n\nlock_a = threading.Lock() # Resource 1\nlock_b = threading.Lock() # Resource 2\n\n# By ensuring both threads acquire locks in the same order (A then B),\n# the circular wait condition is broken.\ndef safe_thread_1():\n    print(\"Safe 1: Acquiring lock A...\")\n    lock_a.acquire()\n    print(\"Safe 1: Acquiring lock B...\")\n    lock_b.acquire()\n    print(\"Safe 1: Acquired both.\")\n    lock_b.release()\n    lock_a.release()\n\ndef safe_thread_2():\n    print(\"Safe 2: Acquiring lock A...\")\n    lock_a.acquire()\n    print(\"Safe 2: Acquiring lock B...\")\n    lock_b.acquire()\n    print(\"Safe 2: Acquired both.\")\n    lock_b.release()\n    lock_a.release()\n\nt1 = threading.Thread(target=safe_thread_1)\nt2 = threading.Thread(target=safe_thread_2)\nt1.start()\nt2.start()\nt1.join()\nt2.join()\nprint(\"Finished safely.\")\n\n// Example 2: Pseudocode for the Banker's Algorithm safety check.\nbool is_safe_state(processes, available_resources) {\n    Work = available_resources;\n    Finish = [false] * num_processes;\n    \n    while (true) {\n        found_process = false;\n        for (i = 0; i < num_processes; i++) {\n            if (Finish[i] == false && processes[i].Needs <= Work) {\n                Work += processes[i].Allocation;\n                Finish[i] = true;\n                found_process = true;\n                break; // Restart search\n            }\n        }\n        if (!found_process) break; // No process can run\n    }\n\n    // If all processes could finish, the state is safe.\n    return all(Finish);\n}"
          }
        ]
      },
      {
        "id": "c10-security-protection",
        "title": "Security & Protection",
        "desc": "Learn how the OS protects system resources using access control, authentication, and other mechanisms.",
        "notes": "Chapter 10 addresses the critical aspects of security and protection within an operating system. Protection refers to the mechanisms controlled by the OS that safeguard system resources (like files, memory sections, and CPU time) from unauthorized or improper access by users or processes. Security, a broader concept, involves defending the system against both internal and external attacks. The chapter begins by establishing the principle of least privilege, which dictates that programs, users, and systems should be given just enough privileges to perform their tasks and no more. A key protection mechanism is the access control list (ACL) or matrix, which specifies what operations a user or process is allowed to perform on a particular object. We will explore how these permissions (e.g., read, write, execute) are implemented in file systems like NTFS and ext4. Authentication is the first line of defense, verifying the identity of a user before granting them access. We'll discuss various authentication methods, from simple passwords to more complex techniques. The chapter also provides a basic introduction to encryption as a tool to protect data confidentiality, both for data at rest (on a disk) and data in transit (over a network). By understanding these fundamental concepts, we can appreciate how an OS works to create a secure and stable multi-user environment, ensuring that one user cannot interfere with another's work or compromise the integrity of the system itself.",
        "code": "",
        "duration": "Week 10",
        "topics": [
          {
            "id": "t21-access-control",
            "title": "Access Control",
            "desc": "Understand how Access Control Lists (ACLs) and capabilities are used to control access to resources.",
            "note": "Access control is the core of OS protection, determining which users or processes are allowed to access which resources and what they are allowed to do with them. A conceptual framework for this is the 'access matrix.' In this model, the rows represent subjects (users or processes), and the columns represent objects (files, devices, memory segments). Each entry `Access[i, j]` in the matrix defines the set of operations that subject `i` can invoke on object `j`. While the matrix is a useful abstraction, it's often too large and sparse to be implemented directly. Therefore, two common implementations are used in practice: Access Control Lists (ACLs) and Capability Lists. An Access Control List is a column-based approach. Each object (e.g., a file) has an associated list, the ACL, which specifies all the subjects that have access to it and their corresponding permissions. For example, a file's ACL might state: `(Alice: read, write), (Bob: read), (Group_Admins: read, write, execute)`. When a subject requests access, the OS checks the object's ACL to see if the request is valid. This is the model used by most modern file systems. A Capability List is a row-based approach. Each subject has a list of capabilities, where each capability is a ticket or token for a specific object that grants certain access rights. To access an object, the subject presents the appropriate capability. Capabilities are managed by the OS to prevent forgery. While less common in general-purpose OS, they are used in certain high-security or distributed systems.",
            "code": "// Example 1: Linux/macOS command-line to view and modify file permissions (a simple form of ACL).\n// The command 'ls -l' shows the permissions.\n// $ ls -l my_file.txt\n// -rw-r--r-- 1 user group 12 Sep 21 10:00 my_file.txt\n// 'rw-' for user, 'r--' for group, 'r--' for others\n\n// The 'chmod' command changes permissions.\n// Give the user (u) execute (x) permission.\n// $ chmod u+x my_file.txt\n// Now permissions are -rwxr--r--\n\n\n// Example 2: Python code to check file access permissions using OS functions.\nimport os\n\nfile_path = \"test_permissions.txt\"\n\n# Create a file\nwith open(file_path, \"w\") as f:\n    f.write(\"OS Security Demo\")\n\n# The OS checks if the current user has read access.\nif os.access(file_path, os.R_OK):\n    print(f\"Read access to {file_path} is granted.\")\nelse:\n    print(f\"Read access to {file_path} is denied.\")\n\n# The OS checks for write access.\nif os.access(file_path, os.W_OK):\n    print(f\"Write access to {file_path} is granted.\")\nelse:\n    print(f\"Write access to {file_path} is denied.\")\n\nos.remove(file_path)"
          }
        ]
      },
      {
        "id": "c11-virtualization",
        "title": "Virtualization & Cloud OS",
        "desc": "Explore modern concepts like Virtual Machines (VMs), hypervisors, and containers.",
        "notes": "Chapter 11 moves into the advanced and highly relevant topic of virtualization. Virtualization is a technology that allows a single physical computer to run multiple 'guest' operating systems simultaneously, each behaving as if it has exclusive control over the hardware. This is achieved by a piece of software called a 'hypervisor' or 'virtual machine monitor' (VMM). The hypervisor sits between the physical hardware and the virtual machines (VMs), abstracting the hardware and providing a virtualized platform for each guest OS. We will differentiate between Type 1 (bare-metal) hypervisors, which run directly on the host's hardware, and Type 2 (hosted) hypervisors, which run as an application on top of a conventional host operating system. Virtualization offers tremendous benefits, including server consolidation (reducing the number of physical servers), efficient resource utilization, and providing isolated environments for testing and development. The second part of the chapter introduces a related but distinct technology: containerization. Unlike VMs, which virtualize the entire hardware stack, containers virtualize the operating system itself. Multiple containers can run on a single OS kernel, sharing it but each having their own isolated user space, file system, and network interfaces. This makes containers, like those managed by Docker, extremely lightweight and fast to start. Finally, we'll touch upon how these technologies form the bedrock of modern cloud computing, enabling services like Infrastructure as a Service (IaaS), where users can provision virtual machines on demand.",
        "code": "",
        "duration": "Week 11",
        "topics": [
          {
            "id": "t22-virtual-machines",
            "title": "Virtual Machines and Hypervisors",
            "desc": "Understand the concept of virtual machines and the role of the hypervisor.",
            "note": "A Virtual Machine (VM) is a software-based emulation of a physical computer. It has a virtual CPU, memory, network interface, and storage, but these resources are mapped to the real physical hardware of the host machine. A single host machine can run multiple VMs, each with its own independent guest operating system (e.g., one VM running Linux, another running Windows). The software that creates and manages these VMs is called a hypervisor or Virtual Machine Monitor (VMM). The hypervisor is responsible for creating a virtual platform and managing the allocation of physical resources to the VMs. When a guest OS tries to execute a privileged instruction (like an I/O operation), the hypervisor intercepts this instruction. It then translates the instruction so that it can be safely executed on the host's physical hardware without interfering with the host OS or other VMs. This process is what allows multiple guest operating systems to share the same hardware without being aware of each other. There are two main types of hypervisors. Type 1, or 'bare-metal' hypervisors, run directly on the host's hardware to control the hardware and manage guest operating systems. Examples include VMware ESXi and Microsoft Hyper-V. They are very efficient. Type 2, or 'hosted' hypervisors, run as a software layer on top of a host operating system, just like a regular application. The guest OS then runs as a process on the host. Examples include Oracle VirtualBox and VMware Workstation. They are easier to set up but have slightly more overhead than Type 1 hypervisors.",
            "code": "// Example 1: Command-line interaction with Docker (a containerization tool, conceptually related).\n// Docker commands abstract interactions with the OS kernel's container features.\n\n// Pull a lightweight Linux image (Alpine Linux)\n// $ docker pull alpine\n\n// Run a command inside a new, isolated container.\n// The OS provides an isolated environment for this 'echo' command.\n// $ docker run alpine echo \"Hello from an isolated container!\"\n\n// Start an interactive shell inside a container.\n// The user gets a command prompt that is isolated from the host system.\n// $ docker run -it alpine /bin/sh\n\n\n// Example 2: Pseudocode for how a hypervisor might handle a privileged instruction from a Guest OS.\nvoid guest_os_execution_loop() {\n    while (true) {\n        Instruction instr = fetch_guest_instruction();\n\n        if (is_privileged(instr)) {\n            // Trap to the hypervisor.\n            hypervisor_handle_instruction(instr);\n        } else {\n            // Execute the instruction directly on the physical CPU.\n            execute_on_cpu(instr);\n        }\n    }\n}\n\nvoid hypervisor_handle_instruction(Instruction instr) {\n    // 1. Emulate the behavior of the privileged instruction in software.\n    // 2. Safely interact with the physical hardware on behalf of the guest OS.\n    // 3. Update the virtual state of the guest's 'hardware'.\n    // 4. Return control to the guest OS.\n}"
          }
        ]
      },
      {
        "id": "c12-case-studies",
        "title": "Case Studies & Advanced Topics",
        "desc": "Analyze the architecture of real-world operating systems like Linux, Windows, and Android.",
        "notes": "The final chapter, Chapter 12, brings together all the concepts we've learned by examining them in the context of real-world, popular operating systems. This provides a practical perspective on how the theoretical principles of OS design are implemented and adapted to meet different goals. We will conduct a case study of the Linux kernel. We'll explore its monolithic-yet-modular architecture, its process and memory management strategies, the design of its highly successful ext4 file system, and its overall philosophy of using small, specialized tools that work together. Understanding Linux internals is invaluable for anyone working in open-source software, server administration, or embedded systems. Next, we will analyze the architecture of Microsoft Windows. We will look at its hybrid kernel design, the structure of the Windows API, its object-based security model, and the architecture of the NTFS file system. This will provide a contrasting view to Linux, highlighting different design trade-offs made to prioritize user-friendliness, backward compatibility, and a rich graphical environment. Finally, we will provide an overview of a mobile operating system, Android. We will see how it is built upon the Linux kernel but adds its own application framework, a specialized runtime (the Android Runtime or ART), and a component-based application model. This case study will emphasize the unique challenges of mobile environments, such as power management, security sandboxing for apps, and managing a different set of I/O devices.",
        "code": "",
        "duration": "Week 12",
        "topics": [
          {
            "id": "t23-linux-internals",
            "title": "Linux Internals",
            "desc": "A high-level look at the Linux kernel's architecture, process management, and file system.",
            "note": "The Linux kernel is a premier example of a monolithic kernel design, though it achieves flexibility through dynamically loadable kernel modules. At its core, the kernel is responsible for managing the system's resources. Process management in Linux is built around the `task_struct` data structure, which is Linux's version of a Process Control Block. It's a massive structure containing all possible information about a process, including its state, scheduling information, memory management details, and open files. Linux uses a sophisticated scheduler called the Completely Fair Scheduler (CFS), which aims to give each process a fair share of the processor's time, moving away from fixed time slices and instead using a weighted allocation model. For memory management, Linux heavily relies on paging and virtual memory. It uses a multi-level page table structure and employs a 'buddy system' for allocating physical memory frames and a 'slab allocator' for managing kernel data structures efficiently. The standard file system, ext4, is an evolution of previous designs and provides features like journaling (for faster recovery after a crash), support for very large file systems and files, and efficient block allocation. A key design philosophy in the Linux/UNIX world is that 'everything is a file.' Processes, devices, and even network connections can be accessed through the file system interface via system calls like `open()`, `read()`, and `write()`, providing a consistent and powerful abstraction.",
            "code": "// Example 1: Using the '/proc' virtual file system in Linux to inspect a process.\n// The kernel presents process information as if they were files.\n// This command reads the 'status' file for process with ID 1.\n// This file is generated on-the-fly by the kernel.\n\n// $ cat /proc/1/status\n// Name:   systemd\n// Umask:  0022\n// State:  S (sleeping)\n// Tgid:   1\n// ... and so on\n\n\n// Example 2: C code to get scheduler policy for the current process on Linux.\n#include <stdio.h>\n#include <sched.h>\n#include <unistd.h>\n\nint main() {\n    pid_t pid = getpid();\n    int policy = sched_getscheduler(pid);\n\n    printf(\"PID %d uses scheduling policy: \", pid);\n    switch (policy) {\n        case SCHED_FIFO:    printf(\"SCHED_FIFO\\n\"); break;\n        case SCHED_RR:      printf(\"SCHED_RR\\n\"); break;\n        case SCHED_OTHER:   printf(\"SCHED_OTHER (CFS)\\n\"); break;\n        default:            printf(\"Unknown\\n\"); break;\n    }\n    return 0;\n}"
          },
          {
            "id": "t24-windows-architecture",
            "title": "Windows Architecture",
            "desc": "An overview of the Windows NT architecture, including its hybrid kernel and object manager.",
            "note": "The architecture of modern Windows versions (based on the Windows NT kernel) is fundamentally different from Linux. It employs a 'hybrid kernel' or 'microkernel-like' architecture. This means that while there is a core kernel (ntoskrnl.exe) that runs in kernel mode and handles critical functions like thread scheduling and interrupt dispatching, many traditional OS services run as separate, protected 'subsystems' in user mode. These include subsystems that provide APIs for different application types, like the Win32 subsystem which is the primary API for most Windows applications. The core of the NT Executive, which runs in kernel mode, is composed of several key components. The Object Manager is central; it manages all system resources (like files, processes, and threads) as 'objects.' Each object has a type, attributes, and a set of methods that can be performed on it. Access to objects is controlled by the Security Reference Monitor, which enforces access control lists. The Process Manager handles the creation and management of processes and threads. The Virtual Memory Manager implements the virtual memory system, using a paging mechanism. The I/O Manager is responsible for dispatching requests to the appropriate device drivers. This highly structured, object-oriented design allows for greater modularity and security compared to a purely monolithic system. The native interface to these services is the Native API, though most developers interact with it indirectly through higher-level APIs like Win32.",
            "code": "// Example 1: C++ code using the Windows API to create a new process.\n// This is a high-level abstraction over the underlying kernel mechanisms.\n#include <windows.h>\n#include <stdio.h>\n\nint main() {\n    STARTUPINFO si;\n    PROCESS_INFORMATION pi;\n    ZeroMemory(&si, sizeof(si));\n    si.cb = sizeof(si);\n    ZeroMemory(&pi, sizeof(pi));\n\n    // The CreateProcess function is part of the Win32 subsystem.\n    // It asks the Windows kernel to create a new process object.\n    if (!CreateProcess(TEXT(\"C:\\\\Windows\\\\System32\\\\notepad.exe\"), NULL, NULL, NULL,\n        FALSE, 0, NULL, NULL, &si, &pi)) {\n        printf(\"CreateProcess failed (%d).\\n\", GetLastError());\n        return 1;\n    }\n    printf(\"Started notepad.exe with process ID: %d\\n\", pi.dwProcessId);\n\n    // Close process and thread handles.\n    CloseHandle(pi.hProcess);\n    CloseHandle(pi.hThread);\n    return 0;\n}\n\n// Example 2: PowerShell command to view kernel-managed objects.\n// The 'Get-Process' cmdlet queries the Windows Process Manager.\n// $ Get-Process\n// \n// Handles  NPM(K)    PM(K)      WS(K)     CPU(s)     Id  SI ProcessName\n// -------  ------    -----      -----     ------     --  -- -----------\n//     146      11     3060       9744       0.05   4620   1 cmd\n//    1789      76   210100     244580      26.55   9512   1 Code\n//     952      48    89996     111244      11.16  11532   1 explorer"
          }
        ]
      }
    ]
  }
]
