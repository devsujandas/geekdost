[
  {
    "id": "os",
    "title": "Operating System",
    "desc": "Comprehensive guide to operating system concepts, design, and implementation",
    "description": "A complete roadmap covering fundamental to advanced operating system concepts including process management, memory allocation, file systems, security, and modern virtualization technologies with practical code examples.",
    "category": "Computer Science",
    "categories": ["Operating System", "Intermediate", "System Programming"],
    "difficulty": "Intermediate",
    "image": "/images/os.png",
    "icon": "FaMicrochip",
    "chapters": [
      {
        "id": "c1-introduction",
        "title": "Introduction to Operating Systems",
        "desc": "Learn the basics, history, and functions of OS",
        "notes": "An operating system (OS) is system software that manages computer hardware, software resources, and provides common services for computer programs. The OS acts as an intermediary between users and the computer hardware, enabling efficient execution of applications and simplifying system interaction. Key functions include process management, memory allocation, file system management, device control, and user interface provision. Operating systems have evolved significantly from early batch processing systems in the 1950s to modern graphical user interface-based systems. Major OS types include single-user single-tasking (e.g., early MS-DOS), single-user multi-tasking (e.g., Windows, macOS), multi-user systems (e.g., UNIX, Linux), real-time operating systems (e.g., VxWorks), and embedded systems (e.g., Android, iOS). Understanding OS fundamentals is crucial for system programmers, application developers, and computer scientists as it provides insights into how software interacts with hardware resources efficiently.",
        "code": "",
        "duration": "Week 1",
        "topics": [
          {
            "id": "t1-definition",
            "title": "Definition of Operating System",
            "desc": "What is an OS and why it is important",
            "note": "An operating system is a complex software system that manages computer hardware resources and provides services for application programs. It serves as an interface between users and computer hardware, enabling efficient execution of applications while abstracting hardware complexities. The OS controls and coordinates the use of hardware among various application programs and users. Key responsibilities include process management, memory management, file system management, device management, security, and command interpretation. Without an operating system, each program would need to include its own code for low-level hardware interactions, leading to massive redundancy and potential conflicts. Modern operating systems provide virtualization of resources, allowing multiple applications to run concurrently while sharing CPU, memory, and I/O devices. They also implement protection mechanisms to prevent processes from interfering with each other and ensure system stability. The importance of operating systems extends to performance optimization, resource allocation, error detection, and user convenience across diverse computing environments from personal devices to enterprise servers.",
            "code": "// Example 1 - Basic system information\n#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    printf(\"Operating System: \");\n    #ifdef _WIN32\n    printf(\"Windows\\n\");\n    #elif __linux__\n    printf(\"Linux\\n\");\n    #elif __APPLE__\n    printf(\"macOS\\n\");\n    #endif\n    \n    printf(\"Page size: %d bytes\\n\", getpagesize());\n    return 0;\n}\n\n// Example 2 - OS role in hardware abstraction\n#include <stdio.h>\n\nint main() {\n    FILE *file = fopen(\"example.txt\", \"w\");\n    if (file != NULL) {\n        fprintf(file, \"OS handles low-level disk operations\\n\");\n        fclose(file);\n        printf(\"File written successfully - OS managed storage operations\\n\");\n    }\n    return 0;\n}"
          },
          {
            "id": "t2-history",
            "title": "History of Operating Systems",
            "desc": "Evolution from batch to modern OS",
            "note": "The history of operating systems reflects the evolution of computing technology from mechanical calculators to modern distributed systems. In the 1940s-1950s, computers operated without OSes using plugboards and manual programming. The first generation (1950s) introduced batch processing systems where operators grouped similar jobs to reduce setup time. The second generation (1960s) saw the development of multiprogramming systems that could run multiple jobs simultaneously, improving CPU utilization. IBM's OS/360 was a landmark system supporting multiple users and applications. The third generation (1970s-1980s) brought UNIX, which introduced hierarchical file systems, pipes, and a modular design that influenced future systems. The personal computer era (1980s) saw the rise of MS-DOS, Apple's Macintosh System, and eventually Windows, which popularized graphical user interfaces. The 1990s witnessed the emergence of network operating systems and open-source Linux, which became dominant in server environments. Modern era (2000s-present) includes mobile operating systems (iOS, Android), cloud-based systems, containerization technologies, and real-time embedded systems. Each evolutionary stage addressed limitations of previous systems while incorporating new hardware capabilities and user requirements, leading to today's sophisticated, secure, and user-friendly operating environments.",
            "code": "// Example 1 - Comparing old and new approaches\n#include <stdio.h>\n\nint main() {\n    // Old approach: direct hardware access (dangerous)\n    printf(\"Early systems required direct hardware programming\\n\");\n    \n    // Modern approach: OS abstraction\n    printf(\"Modern OS provide safe, standardized interfaces:\\n\");\n    printf(\"- File operations via stdio.h\\n\");\n    printf(\"- Memory management via malloc/free\\n\");\n    printf(\"- Process control via system calls\\n\");\n    \n    return 0;\n}\n\n// Example 2 - Evolution demonstration\n#include <stdio.h>\n#include <time.h>\n\nint main() {\n    time_t now = time(NULL);\n    struct tm *tm_info = localtime(&now);\n    \n    printf(\"Current year: %d\\n\", 1900 + tm_info->tm_year);\n    printf(\"From 1950s batch systems to 2020s cloud OS\\n\");\n    printf(\"Evolution driven by hardware advances and user needs\\n\");\n    \n    return 0;\n}"
          },
          {
            "id": "t3-functions",
            "title": "OS Functions and Services",
            "desc": "Core responsibilities and services provided by operating systems",
            "note": "Operating systems provide essential functions and services that enable efficient computer operation and user productivity. The primary functions include process management (creation, scheduling, termination), memory management (allocation, protection, virtualization), file system management (storage, organization, access control), device management (driver interface, I/O operations), and security (authentication, authorization, protection). Services provided to users and programs include user interface (command-line or graphical), program execution (loading, running, ending programs), I/O operations (abstracting device complexities), file system manipulation (create, delete, read, write files), communications (inter-process and network communication), error detection and handling (hardware errors, software exceptions), and resource allocation (managing contention for limited resources). Modern operating systems also provide additional services such as logging (system activity records), protection (preventing unauthorized access), and system performance optimization. These functions work together to create a stable, efficient, and secure environment where applications can execute without needing to manage low-level hardware details directly. The OS continuously monitors system state, allocates resources fairly, and responds to changing conditions while maintaining overall system integrity and performance.",
            "code": "// Example 1 - Process creation service\n#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    printf(\"OS provides process creation service\\n\");\n    pid_t pid = fork();\n    \n    if (pid == 0) {\n        printf(\"Child process created by OS\\n\");\n    } else {\n        printf(\"Parent process - OS manages both\\n\");\n    }\n    \n    return 0;\n}\n\n// Example 2 - File system service\n#include <stdio.h>\n#include <sys/stat.h>\n\nint main() {\n    const char *filename = \"test_service.txt\";\n    \n    // OS provides file creation service\n    FILE *file = fopen(filename, \"w\");\n    if (file) {\n        fprintf(file, \"OS file service example\\n\");\n        fclose(file);\n        \n        // OS provides file information service\n        struct stat file_info;\n        if (stat(filename, &file_info) == 0) {\n            printf(\"File size: %ld bytes (provided by OS)\\n\", file_info.st_size);\n        }\n    }\n    \n    return 0;\n}"
          },
          {
            "id": "t4-types",
            "title": "Types of Operating Systems",
            "desc": "Classification of operating systems based on capabilities and design",
            "note": "Operating systems can be classified into several types based on their capabilities, design philosophy, and target environments. Batch processing systems were early OSes that processed jobs in batches without user interaction. Time-sharing systems allow multiple users to interact with the system concurrently by rapidly switching between tasks. Distributed operating systems manage a group of independent computers as a single system, providing transparency and resource sharing across networks. Network operating systems are designed primarily to support networking, file sharing, and communication services. Real-time operating systems (RTOS) guarantee response within strict time constraints, essential for embedded systems, industrial control, and medical devices. Embedded operating systems are optimized for specific hardware with limited resources, found in appliances, IoT devices, and automotive systems. Mobile operating systems are designed for smartphones and tablets with touch interfaces, power management, and mobile-specific features. Multi-user systems support multiple simultaneous users with proper isolation and security. Single-user systems are designed for personal use with either single-tasking or multi-tasking capabilities. Each OS type has distinct characteristics tailored to specific requirements such as responsiveness, resource constraints, user interaction patterns, and security needs, reflecting the diverse computing environments in which they operate.",
            "code": "// Example 1 - Detecting OS type characteristics\n#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    printf(\"OS Type Detection:\\n\");\n    \n    #ifdef __unix__\n    printf(\"Unix-like system (time-sharing)\\n\");\n    #endif\n    \n    #ifdef _WIN32\n    printf(\"Windows system (single-user multitasking)\\n\");\n    #endif\n    \n    printf(\"CPU cores: %ld\\n\", sysconf(_SC_NPROCESSORS_ONLN));\n    printf(\"This suggests a %s system\\n\", \n           sysconf(_SC_NPROCESSORS_ONLN) > 1 ? \"multitasking\" : \"single-tasking\");\n    \n    return 0;\n}\n\n// Example 2 - Simulating different OS behavior\n#include <stdio.h>\n#include <time.h>\n\nvoid simulate_rtos() {\n    printf(\"RTOS: Guaranteed response time\\n\");\n    clock_t start = clock();\n    // Critical task\n    clock_t end = clock();\n    printf(\"Task completed in %f seconds\\n\", ((double)(end - start)) / CLOCKS_PER_SEC);\n}\n\nvoid simulate_batch() {\n    printf(\"Batch: Processing jobs without interaction\\n\");\n    for (int i = 0; i < 3; i++) {\n        printf(\"Processing job %d...\\n\", i+1);\n    }\n}\n\nint main() {\n    printf(\"Simulating different OS types:\\n\\n\");\n    simulate_rtos();\n    printf(\"\\n\");\n    simulate_batch();\n    \n    return 0;\n}"
          }
        ]
      },
      {
        "id": "c2-architecture",
        "title": "System Architecture & Components",
        "desc": "Understand OS structure, kernel modes, and system interfaces",
        "notes": "Operating system architecture defines the organizational structure and components of an OS, determining how system resources are managed and how software interacts with hardware. The fundamental division is between kernel space (privileged mode where OS core functions execute) and user space (where applications run with restricted privileges). Major architectural approaches include monolithic kernels (all OS services in kernel space, e.g., Linux), microkernels (minimal kernel with most services as user-level servers, e.g., QNX), hybrid kernels (combine aspects of both, e.g., Windows NT), and exokernels (provide minimal abstraction for maximum flexibility). System components typically include process management, memory management, file systems, device drivers, networking stacks, and security subsystems. System calls provide the interface between user applications and OS services, allowing controlled access to privileged operations. Hardware interaction involves interrupt handling, DMA controllers, memory management units, and I/O port management. Understanding OS architecture is essential for system programmers, as it influences performance, security, reliability, and maintainability of the entire computing system.",
        "code": "",
        "duration": "Week 1",
        "topics": [
          {
            "id": "t5-kernel",
            "title": "Kernel Architecture and Types",
            "desc": "Core OS component designs and implementations",
            "note": "The kernel is the core component of an operating system that manages system resources and facilitates communication between hardware and software. Kernel architectures differ in how they structure OS services and components. Monolithic kernels incorporate all operating system services (process management, memory management, file systems, device drivers) into a single large executable running in kernel space. This design offers high performance due to direct function calls between components but risks system instability if any component fails. Linux and traditional UNIX systems use monolithic kernels. Microkernels minimize kernel functionality to basic essentials (process communication, memory management) while running other services as user-space servers. This improves stability and security since driver failures don't crash the entire system, but incurs performance overhead due to frequent context switching. Examples include QNX and Minix. Hybrid kernels combine aspects of both approaches, keeping some services in kernel space for performance while moving others to user space for stability. Windows NT and macOS X use hybrid architectures. Exokernels provide minimal abstraction, allowing applications to directly manage hardware resources for maximum flexibility and performance. Understanding kernel architecture is crucial for OS developers and system programmers as it determines system performance characteristics, security models, and development approaches.",
            "code": "// Example 1 - Kernel space vs user space demonstration\n#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    printf(\"Current process ID: %d\\n\", getpid());\n    printf(\"This program runs in user space\\n\");\n    \n    // Attempt to access kernel memory (will fail in user space)\n    // int *kernel_mem = (int*)0x80000000; // Hypothetical kernel address\n    // printf(\"This would crash if we tried to access kernel memory\\n\");\n    \n    printf(\"User processes must use system calls to access kernel services\\n\");\n    return 0;\n}\n\n// Example 2 - Simulating kernel service handling\n#include <stdio.h>\n\n// Simulated kernel function (would run in kernel space)\nvoid kernel_service(const char *service_name) {\n    printf(\"[KERNEL] Executing service: %s\\n\", service_name);\n}\n\n// User space function\nvoid user_request(const char *request) {\n    printf(\"[USER] Requesting: %s\\n\", request);\n    // This would be a system call in real OS\n    kernel_service(request);\n}\n\nint main() {\n    printf(\"Simulating kernel/user interaction:\\n\\n\");\n    user_request(\"File read\");\n    user_request(\"Memory allocation\");\n    user_request(\"Process creation\");\n    \n    return 0;\n}"
          },
          {
            "id": "t6-user-space",
            "title": "User Space Environment",
            "desc": "Application execution environment and user-level services",
            "note": "User space refers to the memory area and execution environment where user applications and non-kernel processes run. This environment provides a protected execution context with restricted privileges to ensure system stability and security. Applications in user space cannot directly access hardware or kernel memory and must use system calls to request services from the operating system. The user space environment includes libraries (such as libc for C programs), runtime environments, and system utilities that provide higher-level abstractions over kernel services. User space components include command shells, graphical interfaces, application software, and system daemons that provide various services. The separation between user space and kernel space is enforced by hardware protection mechanisms (memory management units, privilege levels) that prevent user applications from interfering with critical system operations. This architecture allows multiple applications to run concurrently without affecting each other or the operating system's stability. User space development focuses on application logic, user interfaces, and business logic while relying on the OS for resource management, security, and hardware interaction. Understanding the user space environment is essential for application developers to create efficient, secure, and portable software that properly utilizes operating system services.",
            "code": "// Example 1 - User space memory allocation\n#include <stdio.h>\n#include <stdlib.h>\n\nint main() {\n    printf(\"User space memory demonstration:\\n\");\n    \n    // Allocate memory in user space\n    int *user_memory = (int*)malloc(10 * sizeof(int));\n    if (user_memory == NULL) {\n        printf(\"Memory allocation failed\\n\");\n        return 1;\n    }\n    \n    printf(\"Allocated 10 integers in user space at %p\\n\", (void*)user_memory);\n    \n    // Use the memory\n    for (int i = 0; i < 10; i++) {\n        user_memory[i] = i * i;\n    }\n    \n    printf(\"Data stored in user memory:\\n\");\n    for (int i = 0; i < 10; i++) {\n        printf(\"user_memory[%d] = %d\\n\", i, user_memory[i]);\n    }\n    \n    free(user_memory);\n    return 0;\n}\n\n// Example 2 - User space system call demonstration\n#include <stdio.h>\n#include <unistd.h>\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <fcntl.h>\n\nint main() {\n    printf(\"User space system call example:\\n\");\n    \n    // System call to open a file (handled by kernel)\n    int fd = open(\"user_file.txt\", O_WRONLY | O_CREAT, 0644);\n    if (fd == -1) {\n        perror(\"open failed\");\n        return 1;\n    }\n    \n    printf(\"File opened successfully via system call\\n\");\n    \n    // System call to write data\n    const char *data = \"Data written from user space\\n\";\n    ssize_t bytes_written = write(fd, data, strlen(data));\n    printf(\"Wrote %zd bytes via system call\\n\", bytes_written);\n    \n    // System call to close file\n    close(fd);\n    printf(\"File operations completed through kernel services\\n\");\n    \n    return 0;\n}"
          },
          {
            "id": "t7-system-calls",
            "title": "System Calls Interface",
            "desc": "Mechanisms for user programs to request OS services",
            "note": "System calls provide the fundamental interface between user applications and the operating system kernel, allowing programs to request services that require privileged hardware access or kernel functionality. When a user program makes a system call, it transitions from user mode to kernel mode through a carefully controlled mechanism that ensures security and stability. Common system call categories include process control (fork, exec, exit), file management (open, read, write, close), device management (ioctl, read, write), information maintenance (getpid, time, system info), and communication (pipe, shmget, msgget). The system call interface typically uses software interrupts or special processor instructions to trigger the mode switch. Parameters are passed through registers, stack, or memory blocks, and the kernel validates all requests before execution. After processing, results are returned to the user program, which resumes execution in user mode. Modern operating systems provide wrapper functions in standard libraries that hide the assembly-level details of making system calls. Understanding system calls is crucial for system programming, as they represent the boundary between application logic and operating system services, and their efficient use is key to application performance and proper resource management.",
            "code": "// Example 1 - Using system calls for process information\n#include <stdio.h>\n#include <unistd.h>\n#include <sys/types.h>\n\nint main() {\n    printf(\"System call examples for process information:\\n\");\n    \n    // System call to get process ID\n    pid_t pid = getpid();\n    printf(\"Process ID: %d\\n\", pid);\n    \n    // System call to get parent process ID\n    pid_t ppid = getppid();\n    printf(\"Parent Process ID: %d\\n\", ppid);\n    \n    // System call to get user ID\n    uid_t uid = getuid();\n    printf(\"User ID: %d\\n\", uid);\n    \n    // System call to get working directory\n    char cwd[1024];\n    if (getcwd(cwd, sizeof(cwd)) != NULL) {\n        printf(\"Current working directory: %s\\n\", cwd);\n    }\n    \n    return 0;\n}\n\n// Example 2 - File operations via system calls\n#include <stdio.h>\n#include <fcntl.h>\n#include <unistd.h>\n#include <string.h>\n\nint main() {\n    printf(\"File operations using system calls:\\n\");\n    \n    // System call to create/open file\n    int fd = open(\"syscall_example.txt\", O_WRONLY | O_CREAT | O_TRUNC, 0644);\n    if (fd == -1) {\n        perror(\"open failed\");\n        return 1;\n    }\n    \n    // System call to write data\n    const char *text = \"This data written via write() system call\\n\";\n    ssize_t bytes_written = write(fd, text, strlen(text));\n    printf(\"Write system call wrote %zd bytes\\n\", bytes_written);\n    \n    // System call to close file\n    close(fd);\n    printf(\"File closed using close() system call\\n\");\n    \n    // Now read back using system calls\n    fd = open(\"syscall_example.txt\", O_RDONLY);\n    if (fd == -1) {\n        perror(\"open for read failed\");\n        return 1;\n    }\n    \n    char buffer[256];\n    ssize_t bytes_read = read(fd, buffer, sizeof(buffer) - 1);\n    if (bytes_read > 0) {\n        buffer[bytes_read] = '\\0';\n        printf(\"Read via system call: %s\", buffer);\n    }\n    \n    close(fd);\n    return 0;\n}"
          },
          {
            "id": "t8-hardware-interaction",
            "title": "Hardware Interaction Mechanisms",
            "desc": "How OS communicates with and manages hardware devices",
            "note": "Operating systems interact with hardware through various mechanisms that abstract device complexities while providing efficient access to system resources. The primary hardware interaction methods include programmed I/O (CPU directly controls devices through port instructions), interrupt-driven I/O (devices signal completion via interrupts), direct memory access (DMA controllers transfer data directly between devices and memory without CPU involvement), and memory-mapped I/O (device registers appear as memory locations). Device drivers serve as hardware-specific software components that translate OS requests into device-specific operations. The OS manages hardware resources through device controllers, which interface between the system bus and physical devices. Interrupt handling is a critical aspect where the OS responds to hardware events by saving context, servicing the interrupt, and restoring execution. Modern systems also use advanced configuration and power interface (ACPI) for power management and device configuration. Hardware abstraction layers (HAL) provide uniform interfaces to diverse hardware, enhancing portability. Understanding hardware interaction is essential for system developers and driver writers, as it impacts system performance, power efficiency, and compatibility across different hardware platforms.",
            "code": "// Example 1 - Simulating hardware register access\n#include <stdio.h>\n#include <stdint.h>\n\n// Simulated device register (would be memory-mapped in real hardware)\nvolatile uint32_t *simulated_device_register = (uint32_t*)0x1000;\n\nvoid simulate_device_operation() {\n    printf(\"Simulating hardware interaction:\\n\");\n    \n    // Simulate writing to device register\n    printf(\"Writing command to device register at %p\\n\", \n           (void*)simulated_device_register);\n    \n    // Simulate reading status from device\n    printf(\"Reading device status register\\n\");\n    printf(\"Device status: READY\\n\");\n    \n    // Simulate data transfer\n    printf(\"Initiating DMA transfer...\\n\");\n    printf(\"DMA transfer completed successfully\\n\");\n}\n\nint main() {\n    simulate_device_operation();\n    return 0;\n}\n\n// Example 2 - Simulating interrupt handling\n#include <stdio.h>\n#include <signal.h>\n#include <unistd.h>\n\nvolatile sig_atomic_t interrupt_received = 0;\n\n// Simulated interrupt handler\nvoid handle_interrupt(int sig) {\n    interrupt_received = 1;\n    printf(\"\\nInterrupt received! Handling hardware event...\\n\");\n}\n\nint main() {\n    printf(\"Simulating interrupt-driven I/O:\\n\");\n    \n    // Set up signal handler to simulate interrupt\n    signal(SIGINT, handle_interrupt);\n    \n    printf(\"Running main program. Press Ctrl+C to simulate hardware interrupt\\n\");\n    \n    // Simulate main program work\n    for (int i = 0; i < 10 && !interrupt_received; i++) {\n        printf(\"Working... %d\\n\", i);\n        sleep(1);\n    }\n    \n    if (interrupt_received) {\n        printf(\"Interrupt handled, resuming normal operation\\n\");\n    } else {\n        printf(\"Program completed without interrupts\\n\");\n    }\n    \n    return 0;\n}"
          }
        ]
      },
      {
        "id": "c3-processes",
        "title": "Processes & Threads",
        "desc": "Learn about process management, threads, and execution contexts",
        "notes": "Processes and threads are fundamental execution entities that operating systems manage to enable multitasking and parallel execution. A process is an instance of a running program with its own memory space, resources, and execution state. The Process Control Block (PCB) is a kernel data structure that stores all information about a process including state, registers, memory maps, and scheduling information. Processes can be in various states: new, ready, running, waiting, or terminated. Context switching is the mechanism where the OS saves the state of one process and restores another, enabling concurrent execution. Threads are lightweight processes that share the same memory space within a process, allowing more efficient parallel execution. Multithreading enables concurrent execution within the same program while sharing resources. Understanding process and thread management is essential for developing efficient, responsive applications that effectively utilize system resources and enable parallelism on modern multi-core systems.",
        "code": "",
        "duration": "Week 1",
        "topics": [
          {
            "id": "t9-pcb",
            "title": "Process Control Block",
            "desc": "Data structure containing process information and state",
            "note": "The Process Control Block (PCB) is a fundamental kernel data structure that represents a process in an operating system. It contains all the essential information needed to manage and track a process throughout its lifecycle. The PCB typically includes process identification data (process ID, parent process ID, user ID), processor state information (register values, program counter, stack pointer), process control information (scheduling state, priority, scheduling parameters), memory management information (page tables, memory limits, segment information), accounting information (CPU time used, time limits, account numbers), and I/O status information (list of open files, I/O devices allocated). When a process is created, the OS allocates a PCB and initializes it with the appropriate values. During context switching, the current process's state is saved in its PCB before loading the state of the next process to run. The PCB enables the OS to suspend and resume processes, manage process hierarchies, and maintain isolation between processes. Understanding the PCB structure is crucial for system programmers and OS developers as it represents the complete execution context of a process and is central to process management operations.",
            "code": "// Example 1 - Simulating PCB structure\n#include <stdio.h>\n#include <unistd.h>\n\n// Simulated PCB structure\ntypedef struct {\n    int pid;              // Process ID\n    int ppid;             // Parent Process ID\n    int state;            // Process state (0=ready, 1=running, 2=waiting)\n    unsigned long cpu_time; // CPU time used\n    int priority;         // Scheduling priority\n    char name[32];        // Process name\n} pcb_t;\n\nvoid display_pcb(const pcb_t *pcb) {\n    printf(\"PCB Information:\\n\");\n    printf(\"  PID: %d\\n\", pcb->pid);\n    printf(\"  Parent PID: %d\\n\", pcb->ppid);\n    printf(\"  State: %s\\n\", \n           pcb->state == 0 ? \"READY\" : \n           pcb->state == 1 ? \"RUNNING\" : \"WAITING\");\n    printf(\"  CPU Time: %lu units\\n\", pcb->cpu_time);\n    printf(\"  Priority: %d\\n\", pcb->priority);\n    printf(\"  Name: %s\\n\", pcb->name);\n}\n\nint main() {\n    // Create a simulated PCB for current process\n    pcb_t current_process = {\n        .pid = getpid(),\n        .ppid = getppid(),\n        .state = 1,  // RUNNING\n        .cpu_time = 100,\n        .priority = 10,\n        .name = \"example_process\"\n    };\n    \n    display_pcb(&current_process);\n    return 0;\n}\n\n// Example 2 - PCB context switching simulation\n#include <stdio.h>\n\n// Simulated register state\ntypedef struct {\n    int eax, ebx, ecx, edx;\n    int esp, ebp;\n    int eip;\n} cpu_state_t;\n\n// Enhanced PCB with CPU state\ntypedef struct {\n    int pid;\n    int state;\n    cpu_state_t registers;\n} enhanced_pcb_t;\n\nvoid save_context(enhanced_pcb_t *pcb) {\n    printf(\"Saving context for process %d\\n\", pcb->pid);\n    // Simulate saving register values\n    pcb->registers.eax = 1234;\n    pcb->registers.ebx = 5678;\n    pcb->registers.eip = 0x400510;\n    printf(\"Context saved - EIP: 0x%x\\n\", pcb->registers.eip);\n}\n\nvoid restore_context(enhanced_pcb_t *pcb) {\n    printf(\"Restoring context for process %d\\n\", pcb->pid);\n    printf(\"Registers: EAX=%d, EBX=%d, EIP=0x%x\\n\", \n           pcb->registers.eax, pcb->registers.ebx, pcb->registers.eip);\n    printf(\"Process execution resumed\\n\");\n}\n\nint main() {\n    enhanced_pcb_t process1 = {1, 0};\n    enhanced_pcb_t process2 = {2, 0};\n    \n    printf(\"Context switching simulation:\\n\\n\");\n    \n    // Simulate context switch from process1 to process2\n    save_context(&process1);\n    process1.state = 0; // Set to ready\n    \n    process2.state = 1; // Set to running\n    restore_context(&process2);\n    \n    return 0;\n}"
          },
          {
            "id": "t10-context-switching",
            "title": "Context Switching Mechanism",
            "desc": "Process of saving and restoring process execution states",
            "note": "Context switching is the fundamental mechanism that enables multitasking in operating systems by allowing the CPU to switch between different processes. When a context switch occurs, the operating system saves the state of the currently running process (including register values, program counter, stack pointer, and other context information) and loads the saved state of another process to resume its execution. Context switches can be triggered by various events including hardware interrupts, system calls, scheduling timeouts, or when a process voluntarily yields the CPU. The process involves saving the current process's context to its Process Control Block (PCB), updating scheduling information, selecting the next process to run, loading the new process's context from its PCB, and updating memory management structures. Context switching overhead includes the time spent saving and restoring registers, flushing and repopulating CPU caches, and updating various kernel data structures. Modern processors provide hardware support for efficient context switching through features like multiple register sets and specialized instructions. Understanding context switching is crucial for system performance optimization, as excessive context switches can significantly impact system throughput and responsiveness, particularly in systems with many short-running processes or real-time constraints.",
            "code": "// Example 1 - Context switch overhead measurement\n#include <stdio.h>\n#include <time.h>\n#include <sched.h>\n\n#define ITERATIONS 100000\n\nvoid measure_context_switch() {\n    struct timespec start, end;\n    double total_time = 0;\n    \n    clock_gettime(CLOCK_MONOTONIC, &start);\n    \n    for (int i = 0; i < ITERATIONS; i++) {\n        // Force a context switch using sched_yield\n        sched_yield();\n    }\n    \n    clock_gettime(CLOCK_MONOTONIC, &end);\n    \n    total_time = (end.tv_sec - start.tv_sec) + \n                 (end.tv_nsec - start.tv_nsec) / 1e9;\n    \n    double avg_time = (total_time / ITERATIONS) * 1e6; // microseconds\n    \n    printf(\"Context switch measurement:\\n\");\n    printf(\"Iterations: %d\\n\", ITERATIONS);\n    printf(\"Total time: %.6f seconds\\n\", total_time);\n    printf(\"Average context switch time: %.3f microseconds\\n\", avg_time);\n}\n\nint main() {\n    measure_context_switch();\n    return 0;\n}\n\n// Example 2 - Simulating context switch decision process\n#include <stdio.h>\n#include <unistd.h>\n\n// Simulated process states\ntypedef enum {\n    STATE_READY,\n    STATE_RUNNING,\n    STATE_WAITING\n} process_state_t;\n\n// Simulated process\ntypedef struct {\n    int pid;\n    process_state_t state;\n    int time_quantum;\n    int priority;\n} process_t;\n\n// Simulated scheduler decision\nint should_context_switch(process_t *current, process_t *next) {\n    // Check if current process used its time quantum\n    if (current->time_quantum <= 0) {\n        printf(\"Time quantum expired, context switch needed\\n\");\n        return 1;\n    }\n    \n    // Check if higher priority process is ready\n    if (next->state == STATE_READY && next->priority > current->priority) {\n        printf(\"Higher priority process ready, context switch needed\\n\");\n        return 1;\n    }\n    \n    // Check if current process is waiting\n    if (current->state == STATE_WAITING) {\n        printf(\"Current process waiting, context switch needed\\n\");\n        return 1;\n    }\n    \n    return 0;\n}\n\nint main() {\n    process_t current = {1, STATE_RUNNING, 0, 5}; // Time quantum expired\n    process_t next = {2, STATE_READY, 10, 8};     // Higher priority\n    \n    printf(\"Context switch decision simulation:\\n\\n\");\n    \n    if (should_context_switch(&current, &next)) {\n        printf(\"Performing context switch from PID %d to PID %d\\n\", \n               current.pid, next.pid);\n        printf(\"Saving current process state...\\n\");\n        printf(\"Loading next process state...\\n\");\n        printf(\"Context switch completed\\n\");\n    } else {\n        printf(\"No context switch needed\\n\");\n    }\n    \n    return 0;\n}"
          },
          {
            "id": "t11-process-states",
            "title": "Process States and Transitions",
            "desc": "Lifecycle states of processes and conditions for state changes",
            "note": "Processes in an operating system transition through various states throughout their lifecycle, representing different stages of execution and resource availability. The fundamental process states include: New (process being created), Ready (process waiting to be assigned to CPU), Running (instructions being executed on CPU), Waiting (process waiting for some event such as I/O completion), and Terminated (process has finished execution). State transitions occur based on specific events: a new process moves to Ready when initialization completes; a Ready process moves to Running when scheduled by the OS; a Running process moves to Waiting when it requests an operation that requires waiting (like I/O); a Waiting process moves to Ready when the event it was waiting for occurs; a Running process moves to Ready when its time quantum expires or a higher priority process becomes ready; and a Running process moves to Terminated when it completes execution or is explicitly killed. Some systems include additional states like Suspended (process swapped out of memory) or Zombie (process terminated but still has an entry in process table). Understanding process states and transitions is essential for system designers and developers to create efficient scheduling algorithms, debug process-related issues, and optimize system performance by minimizing unnecessary state transitions and associated overhead.",
            "code": "// Example 1 - Process state simulation\n#include <stdio.h>\n\n// Process states\ntypedef enum {\n    STATE_NEW,\n    STATE_READY,\n    STATE_RUNNING,\n    STATE_WAITING,\n    STATE_TERMINATED\n} process_state_t;\n\nconst char *state_names[] = {\n    \"NEW\", \"READY\", \"RUNNING\", \"WAITING\", \"TERMINATED\"\n};\n\n// Process structure\ntypedef struct {\n    int pid;\n    process_state_t state;\n    const char *name;\n} process_t;\n\nvoid change_state(process_t *process, process_state_t new_state) {\n    printf(\"Process %d (%s): %s -> %s\\n\", \n           process->pid, process->name,\n           state_names[process->state],\n           state_names[new_state]);\n    process->state = new_state;\n}\n\nvoid simulate_process_lifecycle() {\n    process_t proc = {1, STATE_NEW, \"example_process\"};\n    \n    printf(\"Process lifecycle simulation:\\n\\n\");\n    \n    // Simulate process creation and execution\n    change_state(&proc, STATE_READY);   // Process initialized\n    change_state(&proc, STATE_RUNNING); // Scheduled\n    change_state(&proc, STATE_WAITING); // Requested I/O\n    change_state(&proc, STATE_READY);   // I/O completed\n    change_state(&proc, STATE_RUNNING); // Scheduled again\n    change_state(&proc, STATE_TERMINATED); // Finished\n}\n\nint main() {\n    simulate_process_lifecycle();\n    return 0;\n}\n\n// Example 2 - State transition conditions\n#include <stdio.h>\n#include <stdbool.h>\n\n// Events that trigger state transitions\ntypedef enum {\n    EVENT_CREATE,\n    EVENT_SCHEDULE,\n    EVENT_IO_REQUEST,\n    EVENT_IO_COMPLETE,\n    EVENT_TIME_EXPIRE,\n    EVENT_TERMINATE\n} process_event_t;\n\nconst char *event_names[] = {\n    \"CREATE\", \"SCHEDULE\", \"IO_REQUEST\", \"IO_COMPLETE\", \"TIME_EXPIRE\", \"TERMINATE\"\n};\n\nprocess_state_t handle_event(process_state_t current_state, process_event_t event) {\n    printf(\"Event: %s, Current state: %s -> \", \n           event_names[event], state_names[current_state]);\n    \n    switch (current_state) {\n        case STATE_NEW:\n            if (event == EVENT_CREATE) return STATE_READY;\n            break;\n        case STATE_READY:\n            if (event == EVENT_SCHEDULE) return STATE_RUNNING;\n            break;\n        case STATE_RUNNING:\n            if (event == EVENT_IO_REQUEST) return STATE_WAITING;\n            if (event == EVENT_TIME_EXPIRE) return STATE_READY;\n            if (event == EVENT_TERMINATE) return STATE_TERMINATED;\n            break;\n        case STATE_WAITING:\n            if (event == EVENT_IO_COMPLETE) return STATE_READY;\n            break;\n        default:\n            break;\n    }\n    \n    return current_state; // No state change for invalid transition\n}\n\nint main() {\n    printf(\"Process state transition rules:\\n\\n\");\n    \n    // Test various transitions\n    process_state_t state = STATE_NEW;\n    state = handle_event(state, EVENT_CREATE);\n    printf(\"%s\\n\", state_names[state]);\n    \n    state = handle_event(state, EVENT_SCHEDULE);\n    printf(\"%s\\n\", state_names[state]);\n    \n    state = handle_event(state, EVENT_IO_REQUEST);\n    printf(\"%s\\n\", state_names[state]);\n    \n    state = handle_event(state, EVENT_IO_COMPLETE);\n    printf(\"%s\\n\", state_names[state]);\n    \n    state = handle_event(state, EVENT_SCHEDULE);\n    printf(\"%s\\n\", state_names[state]);\n    \n    state = handle_event(state, EVENT_TERMINATE);\n    printf(\"%s\\n\", state_names[state]);\n    \n    return 0;\n}"
          },
          {
            "id": "t12-threads",
            "title": "Threads and Multithreading",
            "desc": "Lightweight processes and concurrent execution within processes",
            "note": "Threads are lightweight execution units within a process that enable concurrent execution while sharing the same memory space and resources. Unlike processes which have separate memory spaces, threads within the same process share code, data, and system resources but have their own stack, registers, and program counter. This makes thread creation, context switching, and communication more efficient than processes. Threads can be implemented at the user level (managed by a user-space library) or kernel level (managed by the operating system). User-level threads are faster to create and manage but cannot leverage multiple processors, while kernel-level threads can run on multiple processors but have higher overhead. Multithreading allows applications to perform multiple tasks concurrently, improving responsiveness and resource utilization. Common threading models include one-to-one (each user thread maps to one kernel thread), many-to-one (many user threads map to one kernel thread), and many-to-many (many user threads map to many kernel threads). Thread synchronization mechanisms like mutexes, semaphores, and condition variables are essential to prevent race conditions when threads access shared resources. Understanding threads and multithreading is crucial for developing responsive, efficient applications that can leverage modern multi-core processors effectively.",
            "code": "// Example 1 - Basic multithreading with pthreads\n#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\n#define NUM_THREADS 3\n\n// Thread function\nvoid *thread_function(void *arg) {\n    int thread_id = *(int*)arg;\n    printf(\"Thread %d started - PID: %d\\n\", thread_id, getpid());\n    \n    // Simulate work\n    for (int i = 0; i < 3; i++) {\n        printf(\"Thread %d working... %d\\n\", thread_id, i);\n        sleep(1);\n    }\n    \n    printf(\"Thread %d finished\\n\", thread_id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int thread_ids[NUM_THREADS];\n    \n    printf(\"Main process PID: %d\\n\", getpid());\n    printf(\"Creating %d threads within same process:\\n\\n\", NUM_THREADS);\n    \n    // Create threads\n    for (int i = 0; i < NUM_THREADS; i++) {\n        thread_ids[i] = i + 1;\n        if (pthread_create(&threads[i], NULL, thread_function, &thread_ids[i]) != 0) {\n            perror(\"pthread_create failed\");\n            return 1;\n        }\n    }\n    \n    // Wait for all threads to complete\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    \n    printf(\"All threads completed - Note they all shared same PID\\n\");\n    return 0;\n}\n\n// Example 2 - Demonstrating shared memory between threads\n#include <stdio.h>\n#include <pthread.h>\n\n// Shared data between threads\nint shared_counter = 0;\n\nvoid *increment_thread(void *arg) {\n    int iterations = *(int*)arg;\n    \n    for (int i = 0; i < iterations; i++) {\n        shared_counter++; // Race condition potential!\n        printf(\"Thread incremented counter to: %d\\n\", shared_counter);\n    }\n    \n    return NULL;\n}\n\nint main() {\n    pthread_t thread1, thread2;\n    int iterations = 5;\n    \n    printf(\"Shared memory demonstration between threads:\\n\\n\");\n    printf(\"Initial shared counter: %d\\n\", shared_counter);\n    \n    // Create two threads that access shared memory\n    pthread_create(&thread1, NULL, increment_thread, &iterations);\n    pthread_create(&thread2, NULL, increment_thread, &iterations);\n    \n    // Wait for threads\n    pthread_join(thread1, NULL);\n    pthread_join(thread2, NULL);\n    \n    printf(\"Final shared counter: %d\\n\", shared_counter);\n    printf(\"Expected: %d, Actual: %d (race condition evident)\\n\", \n           iterations * 2, shared_counter);\n    \n    return 0;\n}"
          }
        ]
      },
      {
        "id": "c4-scheduling",
        "title": "CPU Scheduling",
        "desc": "Algorithms for process scheduling and CPU allocation",
        "notes": "CPU scheduling is a fundamental OS function that determines which process gets access to the CPU and for how long. Scheduling algorithms aim to maximize CPU utilization, throughput, and system responsiveness while minimizing waiting time, response time, and turnaround time. Key scheduling algorithms include First-Come-First-Served (FCFS) which processes jobs in arrival order but can suffer from convoy effect; Shortest-Job-First (SJF) which selects the shortest job next for optimal average waiting time but requires accurate runtime estimates; Priority Scheduling which assigns priorities to processes but can cause starvation; Round Robin (RR) which uses time slicing to provide fair allocation but may have high context switch overhead; and Multilevel Queue Scheduling which categorizes processes into different queues with different scheduling policies. Modern systems often use complex multilevel feedback queues that adapt to process behavior. Understanding CPU scheduling is essential for system designers to create efficient, fair, and responsive operating systems that meet diverse performance requirements across different computing environments.",
        "code": "",
        "duration": "Week 1",
        "topics": [
          {
            "id": "t13-fcfs",
            "title": "First-Come-First-Served Scheduling",
            "desc": "Non-preemptive scheduling based on arrival order",
            "note": "First-Come-First-Served (FCFS) is the simplest CPU scheduling algorithm where processes are executed in the order of their arrival. When a process enters the ready queue, it is placed at the tail, and the CPU is allocated to the process at the head of the queue. FCFS is non-preemptive, meaning once a process starts execution, it runs to completion without being interrupted. The main advantage of FCFS is its simplicity and ease of implementation with a simple FIFO queue. However, it suffers from several disadvantages: the convoy effect where short processes wait behind long processes, leading to poor average waiting time; poor responsiveness for interactive systems as processes may wait indefinitely; and no prioritization of important processes. FCFS can perform reasonably well when process burst times are similar but becomes inefficient with varying CPU burst times. The average waiting time under FCFS can be calculated by summing the waiting times of all processes and dividing by the number of processes. Despite its limitations, FCFS is used in some simple systems and serves as a baseline for comparing more sophisticated scheduling algorithms.",
            "code": "// Example 1 - FCFS scheduling simulation\n#include <stdio.h>\n\n// Process structure for FCFS\ntypedef struct {\n    int pid;\n    int arrival_time;\n    int burst_time;\n    int waiting_time;\n    int turnaround_time;\n} process_t;\n\nvoid fcfs_scheduler(process_t processes[], int n) {\n    int current_time = 0;\n    \n    printf(\"FCFS Scheduling Simulation:\\n\\n\");\n    printf(\"PID\\tArrival\\tBurst\\tStart\\tFinish\\tWaiting\\tTurnaround\\n\");\n    \n    for (int i = 0; i < n; i++) {\n        // Process waits until current time reaches its arrival time\n        if (current_time < processes[i].arrival_time) {\n            current_time = processes[i].arrival_time;\n        }\n        \n        int start_time = current_time;\n        int finish_time = current_time + processes[i].burst_time;\n        \n        processes[i].waiting_time = start_time - processes[i].arrival_time;\n        processes[i].turnaround_time = finish_time - processes[i].arrival_time;\n        \n        printf(\"%d\\t%d\\t%d\\t%d\\t%d\\t%d\\t%d\\n\",\n               processes[i].pid,\n               processes[i].arrival_time,\n               processes[i].burst_time,\n               start_time,\n               finish_time,\n               processes[i].waiting_time,\n               processes[i].turnaround_time);\n        \n        current_time = finish_time;\n    }\n    \n    // Calculate averages\n    double avg_waiting = 0, avg_turnaround = 0;\n    for (int i = 0; i < n; i++) {\n        avg_waiting += processes[i].waiting_time;\n        avg_turnaround += processes[i].turnaround_time;\n    }\n    avg_waiting /= n;\n    avg_turnaround /= n;\n    \n    printf(\"\\nAverage Waiting Time: %.2f\\n\", avg_waiting);\n    printf(\"Average Turnaround Time: %.2f\\n\", avg_turnaround);\n}\n\nint main() {\n    // Example processes: PID, Arrival, Burst\n    process_t processes[] = {\n        {1, 0, 10, 0, 0},\n        {2, 1, 5, 0, 0},\n        {3, 2, 8, 0, 0}\n    };\n    \n    int n = sizeof(processes) / sizeof(processes[0]);\n    fcfs_scheduler(processes, n);\n    \n    return 0;\n}\n\n// Example 2 - FCFS with different arrival times\n#include <stdio.h>\n\nvoid fcfs_varying_arrival() {\n    process_t processes[] = {\n        {1, 0, 5, 0, 0},\n        {2, 2, 3, 0, 0},\n        {3, 4, 2, 0, 0},\n        {4, 6, 4, 0, 0}\n    };\n    \n    int n = sizeof(processes) / sizeof(processes[0]);\n    \n    printf(\"FCFS with varying arrival times:\\n\\n\");\n    fcfs_scheduler(processes, n);\n    \n    printf(\"\\nNote how processes with later arrival times\\n\");\n    printf(\"may have to wait even if they have short burst times\\n\");\n}\n\nint main() {\n    fcfs_varying_arrival();\n    return 0;\n}"
          },
          {
            "id": "t14-sjf",
            "title": "Shortest-Job-First Scheduling",
            "desc": "Scheduling based on shortest CPU burst time",
            "note": "Shortest-Job-First (SJF) is a CPU scheduling algorithm that selects the process with the smallest CPU burst time from the ready queue. SJF can be implemented as either non-preemptive (once a process starts, it runs to completion) or preemptive (a new shorter process can interrupt a currently running process, known as Shortest-Remaining-Time-First). SJF is theoretically optimal for minimizing average waiting time, as shorter processes are given priority, reducing the waiting time of subsequent processes. However, SJF has several practical limitations: it requires accurate knowledge of CPU burst times which is often unavailable; it can lead to starvation of longer processes if short processes keep arriving; and it may not be suitable for interactive systems where response time is important. The preemptive version (SRTF) provides better response times but increases context switching overhead. SJF works well in batch systems where job characteristics are known in advance. Implementation typically requires maintaining the ready queue as a priority queue ordered by burst time. Despite its optimality for average waiting time, SJF is rarely used in pure form in modern systems due to its impracticality but influences the design of more adaptive scheduling algorithms.",
            "code": "// Example 1 - Non-preemptive SJF simulation\n#include <stdio.h>\n#include <stdbool.h>\n\nvoid sjf_scheduler(process_t processes[], int n) {\n    int current_time = 0;\n    int completed = 0;\n    bool completed_proc[n];\n    \n    for (int i = 0; i < n; i++) {\n        completed_proc[i] = false;\n    }\n    \n    printf(\"SJF (Non-preemptive) Scheduling:\\n\\n\");\n    printf(\"PID\\tArrival\\tBurst\\tStart\\tFinish\\tWaiting\\tTurnaround\\n\");\n    \n    while (completed < n) {\n        int shortest_index = -1;\n        int shortest_burst = 9999;\n        \n        // Find process with shortest burst time that has arrived\n        for (int i = 0; i < n; i++) {\n            if (!completed_proc[i] && \n                processes[i].arrival_time <= current_time &&\n                processes[i].burst_time < shortest_burst) {\n                shortest_burst = processes[i].burst_time;\n                shortest_index = i;\n            }\n        }\n        \n        if (shortest_index == -1) {\n            current_time++;\n            continue;\n        }\n        \n        int i = shortest_index;\n        int start_time = current_time;\n        int finish_time = current_time + processes[i].burst_time;\n        \n        processes[i].waiting_time = start_time - processes[i].arrival_time;\n        processes[i].turnaround_time = finish_time - processes[i].arrival_time;\n        \n        printf(\"%d\\t%d\\t%d\\t%d\\t%d\\t%d\\t%d\\n\",\n               processes[i].pid,\n               processes[i].arrival_time,\n               processes[i].burst_time,\n               start_time,\n               finish_time,\n               processes[i].waiting_time,\n               processes[i].turnaround_time);\n        \n        current_time = finish_time;\n        completed_proc[i] = true;\n        completed++;\n    }\n    \n    // Calculate averages\n    double avg_waiting = 0, avg_turnaround = 0;\n    for (int i = 0; i < n; i++) {\n        avg_waiting += processes[i].waiting_time;\n        avg_turnaround += processes[i].turnaround_time;\n    }\n    avg_waiting /= n;\n    avg_turnaround /= n;\n    \n    printf(\"\\nAverage Waiting Time: %.2f\\n\", avg_waiting);\n    printf(\"Average Turnaround Time: %.2f\\n\", avg_turnaround);\n}\n\nint main() {\n    process_t processes[] = {\n        {1, 0, 6, 0, 0},\n        {2, 2, 8, 0, 0},\n        {3, 4, 7, 0, 0},\n        {4, 5, 3, 0, 0}\n    };\n    \n    int n = sizeof(processes) / sizeof(processes[0]);\n    sjf_scheduler(processes, n);\n    \n    return 0;\n}\n\n// Example 2 - Preemptive SJF (SRTF) simulation\n#include <stdio.h>\n#include <stdbool.h>\n\nvoid srtf_scheduler(process_t processes[], int n) {\n    int current_time = 0;\n    int completed = 0;\n    int remaining_time[n];\n    \n    for (int i = 0; i < n; i++) {\n        remaining_time[i] = processes[i].burst_time;\n        processes[i].waiting_time = 0;\n        processes[i].turnaround_time = 0;\n    }\n    \n    printf(\"SRTF (Preemptive SJF) Scheduling:\\n\\n\");\n    printf(\"Time\\tPID\\tRemaining\\n\");\n    \n    int prev_pid = -1;\n    \n    while (completed < n) {\n        int shortest_index = -1;\n        int shortest_remaining = 9999;\n        \n        // Find process with shortest remaining time that has arrived\n        for (int i = 0; i < n; i++) {\n            if (processes[i].arrival_time <= current_time && \n                remaining_time[i] > 0 &&\n                remaining_time[i] < shortest_remaining) {\n                shortest_remaining = remaining_time[i];\n                shortest_index = i;\n            }\n        }\n        \n        if (shortest_index == -1) {\n            current_time++;\n            continue;\n        }\n        \n        // Execute the process for 1 time unit\n        remaining_time[shortest_index]--;\n        \n        if (prev_pid != processes[shortest_index].pid) {\n            printf(\"%d\\t%d\\t%d\\n\", current_time, processes[shortest_index].pid, \n                   remaining_time[shortest_index]);\n            prev_pid = processes[shortest_index].pid;\n        }\n        \n        // Update waiting times for other ready processes\n        for (int i = 0; i < n; i++) {\n            if (i != shortest_index && \n                processes[i].arrival_time <= current_time && \n                remaining_time[i] > 0) {\n                processes[i].waiting_time++;\n            }\n        }\n        \n        current_time++;\n        \n        // Check if process completed\n        if (remaining_time[shortest_index] == 0) {\n            completed++;\n            processes[shortest_index].turnaround_time = \n                current_time - processes[shortest_index].arrival_time;\n        }\n    }\n    \n    printf(\"\\nFinal Results:\\n\");\n    printf(\"PID\\tWaiting\\tTurnaround\\n\");\n    \n    double avg_waiting = 0, avg_turnaround = 0;\n    for (int i = 0; i < n; i++) {\n        printf(\"%d\\t%d\\t%d\\n\", processes[i].pid, \n               processes[i].waiting_time, processes[i].turnaround_time);\n        avg_waiting += processes[i].waiting_time;\n        avg_turnaround += processes[i].turnaround_time;\n    }\n    \n    avg_waiting /= n;\n    avg_turnaround /= n;\n    \n    printf(\"\\nAverage Waiting Time: %.2f\\n\", avg_waiting);\n    printf(\"Average Turnaround Time: %.2f\\n\", avg_turnaround);\n}\n\nint main() {\n    process_t processes[] = {\n        {1, 0, 8, 0, 0},\n        {2, 1, 4, 0, 0},\n        {3, 2, 9, 0, 0},\n        {4, 3, 5, 0, 0}\n    };\n    \n    int n = sizeof(processes) / sizeof(processes[0]);\n    srtf_scheduler(processes, n);\n    \n    return 0;\n}"
          },
          {
            "id": "t15-priority",
            "title": "Priority Scheduling",
            "desc": "Scheduling based on process priority levels",
            "note": "Priority scheduling is a CPU scheduling algorithm where each process is assigned a priority, and the process with the highest priority is selected for execution. Priorities can be assigned based on various criteria such as process importance, resource requirements, user class, or other system-defined metrics. Priority scheduling can be either preemptive (higher priority process can interrupt a running lower priority process) or non-preemptive (once a process starts, it runs to completion regardless of priority). Processes with equal priority are typically scheduled using FCFS. The main advantage of priority scheduling is that it allows important processes to receive preferential treatment, which is useful in real-time systems and situations where certain tasks are more critical than others. However, priority scheduling can lead to starvation of low-priority processes if higher priority processes continuously arrive. This issue is often addressed through aging techniques that gradually increase the priority of waiting processes. Implementation requires maintaining the ready queue as a priority queue ordered by process priority. Priority scheduling is widely used in modern operating systems, often in combination with other algorithms in multilevel queue systems.",
            "code": "// Example 1 - Non-preemptive priority scheduling\n#include <stdio.h>\n#include <stdbool.h>\n\n// Enhanced process structure with priority\ntypedef struct {\n    int pid;\n    int arrival_time;\n    int burst_time;\n    int priority;  // Lower number = higher priority\n    int waiting_time;\n    int turnaround_time;\n} priority_process_t;\n\nvoid priority_scheduler(priority_process_t processes[], int n) {\n    int current_time = 0;\n    int completed = 0;\n    bool completed_proc[n];\n    \n    for (int i = 0; i < n; i++) {\n        completed_proc[i] = false;\n    }\n    \n    printf(\"Priority Scheduling (Non-preemptive):\\n\\n\");\n    printf(\"PID\\tArrival\\tBurst\\tPriority\\tStart\\tFinish\\tWaiting\\tTurnaround\\n\");\n    \n    while (completed < n) {\n        int highest_priority_index = -1;\n        int highest_priority = 9999; // Lower number = higher priority\n        \n        // Find process with highest priority that has arrived\n        for (int i = 0; i < n; i++) {\n            if (!completed_proc[i] && \n                processes[i].arrival_time <= current_time &&\n                processes[i].priority < highest_priority) {\n                highest_priority = processes[i].priority;\n                highest_priority_index = i;\n            }\n        }\n        \n        if (highest_priority_index == -1) {\n            current_time++;\n            continue;\n        }\n        \n        int i = highest_priority_index;\n        int start_time = current_time;\n        int finish_time = current_time + processes[i].burst_time;\n        \n        processes[i].waiting_time = start_time - processes[i].arrival_time;\n        processes[i].turnaround_time = finish_time - processes[i].arrival_time;\n        \n        printf(\"%d\\t%d\\t%d\\t%d\\t\\t%d\\t%d\\t%d\\t%d\\n\",\n               processes[i].pid,\n               processes[i].arrival_time,\n               processes[i].burst_time,\n               processes[i].priority,\n               start_time,\n               finish_time,\n               processes[i].waiting_time,\n               processes[i].turnaround_time);\n        \n        current_time = finish_time;\n        completed_proc[i] = true;\n        completed++;\n    }\n    \n    // Calculate averages\n    double avg_waiting = 0, avg_turnaround = 0;\n    for (int i = 0; i < n; i++) {\n        avg_waiting += processes[i].waiting_time;\n        avg_turnaround += processes[i].turnaround_time;\n    }\n    avg_waiting /= n;\n    avg_turnaround /= n;\n    \n    printf(\"\\nAverage Waiting Time: %.2f\\n\", avg_waiting);\n    printf(\"Average Turnaround Time: %.2f\\n\", avg_turnaround);\n}\n\nint main() {\n    priority_process_t processes[] = {\n        {1, 0, 10, 3, 0, 0},\n        {2, 0, 5, 1, 0, 0},  // Highest priority\n        {3, 0, 8, 2, 0, 0},\n        {4, 0, 4, 4, 0, 0}   // Lowest priority\n    };\n    \n    int n = sizeof(processes) / sizeof(processes[0]);\n    priority_scheduler(processes, n);\n    \n    return 0;\n}\n\n// Example 2 - Preemptive priority scheduling with aging\n#include <stdio.h>\n#include <stdbool.h>\n\nvoid preemptive_priority_scheduler(priority_process_t processes[], int n) {\n    int current_time = 0;\n    int completed = 0;\n    int remaining_time[n];\n    int original_priority[n];\n    \n    for (int i = 0; i < n; i++) {\n        remaining_time[i] = processes[i].burst_time;\n        original_priority[i] = processes[i].priority;\n        processes[i].waiting_time = 0;\n        processes[i].turnaround_time = 0;\n    }\n    \n    printf(\"Preemptive Priority Scheduling with Aging:\\n\\n\");\n    printf(\"Time\\tPID\\tPriority\\tRemaining\\n\");\n    \n    while (completed < n) {\n        int highest_priority_index = -1;\n        int highest_priority = 9999;\n        \n        // Apply aging: increase priority of waiting processes\n        for (int i = 0; i < n; i++) {\n            if (processes[i].arrival_time <= current_time && \n                remaining_time[i] > 0) {\n                // Aging: reduce priority number (increase actual priority)\n                // for processes that have been waiting\n                int wait_time = current_time - processes[i].arrival_time;\n                processes[i].priority = original_priority[i] - (wait_time / 5);\n                if (processes[i].priority < 1) processes[i].priority = 1;\n            }\n        }\n        \n        // Find process with highest priority (lowest number)\n        for (int i = 0; i < n; i++) {\n            if (processes[i].arrival_time <= current_time && \n                remaining_time[i] > 0 &&\n                processes[i].priority < highest_priority) {\n                highest_priority = processes[i].priority;\n                highest_priority_index = i;\n            }\n        }\n        \n        if (highest_priority_index == -1) {\n            current_time++;\n            continue;\n        }\n        \n        // Execute the process for 1 time unit\n        int i = highest_priority_index;\n        remaining_time[i]--;\n        \n        printf(\"%d\\t%d\\t%d\\t\\t%d\\n\", current_time, processes[i].pid, \n               processes[i].priority, remaining_time[i]);\n        \n        // Update waiting times for other ready processes\n        for (int j = 0; j < n; j++) {\n            if (j != i && \n                processes[j].arrival_time <= current_time && \n                remaining_time[j] > 0) {\n                processes[j].waiting_time++;\n            }\n        }\n        \n        current_time++;\n        \n        // Check if process completed\n        if (remaining_time[i] == 0) {\n            completed++;\n            processes[i].turnaround_time = \n                current_time - processes[i].arrival_time;\n            // Restore original priority for final statistics\n            processes[i].priority = original_priority[i];\n        }\n    }\n    \n    printf(\"\\nFinal Results:\\n\");\n    printf(\"PID\\tOriginal Priority\\tWaiting\\tTurnaround\\n\");\n    \n    double avg_waiting = 0, avg_turnaround = 0;\n    for (int i = 0; i < n; i++) {\n        printf(\"%d\\t%d\\t\\t\\t%d\\t%d\\n\", processes[i].pid, \n               original_priority[i],\n               processes[i].waiting_time, processes[i].turnaround_time);\n        avg_waiting += processes[i].waiting_time;\n        avg_turnaround += processes[i].turnaround_time;\n    }\n    \n    avg_waiting /= n;\n    avg_turnaround /= n;\n    \n    printf(\"\\nAverage Waiting Time: %.2f\\n\", avg_waiting);\n    printf(\"Average Turnaround Time: %.2f\\n\", avg_turnaround);\n}\n\nint main() {\n    priority_process_t processes[] = {\n        {1, 0, 10, 4, 0, 0},  // Lowest priority\n        {2, 0, 5, 1, 0, 0},   // Highest priority\n        {3, 0, 8, 3, 0, 0},\n        {4, 0, 12, 5, 0, 0}   // Very low priority\n    };\n    \n    int n = sizeof(processes) / sizeof(processes[0]);\n    preemptive_priority_scheduler(processes, n);\n    \n    return 0;\n}"
          },
          {
            "id": "t16-round-robin",
            "title": "Round Robin Scheduling",
            "desc": "Time-sliced scheduling with fixed time quantum",
            "note": "Round Robin (RR) is a preemptive CPU scheduling algorithm designed for time-sharing systems where each process is assigned a fixed time unit called a time quantum or time slice. Processes are kept in a circular queue, and the CPU scheduler goes around this queue, allocating the CPU to each process for the time quantum. If a process's CPU burst time is less than the time quantum, it will release the CPU voluntarily upon completion. If the burst time is longer, the process is preempted after the time quantum expires and placed at the tail of the ready queue. The key advantage of Round Robin is its fairness - each process gets an equal share of CPU time. It provides good response time for interactive systems and prevents starvation. The performance of RR depends heavily on the size of the time quantum: too large a quantum degenerates to FCFS, while too small a quantum increases context switching overhead reducing CPU utilization. RR is particularly effective when process burst times vary widely or when the system needs to provide responsive interactive performance. Modern operating systems often use RR as the default scheduling algorithm for interactive processes, sometimes with dynamic time quantum adjustment based on system load and process priorities.",
            "code": "// Example 1 - Round Robin scheduling simulation\n#include <stdio.h>\n#include <stdbool.h>\n\nvoid round_robin_scheduler(process_t processes[], int n, int time_quantum) {\n    int current_time = 0;\n    int completed = 0;\n    int remaining_time[n];\n    \n    for (int i = 0; i < n; i++) {\n        remaining_time[i] = processes[i].burst_time;\n        processes[i].waiting_time = 0;\n        processes[i].turnaround_time = 0;\n    }\n    \n    printf(\"Round Robin Scheduling (Time Quantum = %d):\\n\\n\", time_quantum);\n    printf(\"Time\\tPID\\tRemaining\\tAction\\n\");\n    \n    while (completed < n) {\n        for (int i = 0; i < n; i++) {\n            if (processes[i].arrival_time <= current_time && remaining_time[i] > 0) {\n                int execution_time = (remaining_time[i] > time_quantum) ? \n                                    time_quantum : remaining_time[i];\n                \n                printf(\"%d\\t%d\\t%d\\t\\t\", current_time, processes[i].pid, remaining_time[i]);\n                \n                // Update waiting times for other processes\n                for (int j = 0; j < n; j++) {\n                    if (j != i && \n                        processes[j].arrival_time <= current_time && \n                        remaining_time[j] > 0) {\n                        processes[j].waiting_time += execution_time;\n                    }\n                }\n                \n                // Execute the process\n                remaining_time[i] -= execution_time;\n                current_time += execution_time;\n                \n                if (remaining_time[i] == 0) {\n                    printf(\"Completed\\n\");\n                    completed++;\n                    processes[i].turnaround_time = current_time - processes[i].arrival_time;\n                } else {\n                    printf(\"Preempted\\n\");\n                }\n            }\n        }\n    }\n    \n    printf(\"\\nFinal Results:\\n\");\n    printf(\"PID\\tWaiting\\tTurnaround\\n\");\n    \n    double avg_waiting = 0, avg_turnaround = 0;\n    for (int i = 0; i < n; i++) {\n        printf(\"%d\\t%d\\t%d\\n\", processes[i].pid, \n               processes[i].waiting_time, processes[i].turnaround_time);\n        avg_waiting += processes[i].waiting_time;\n        avg_turnaround += processes[i].turnaround_time;\n    }\n    \n    avg_waiting /= n;\n    avg_turnaround /= n;\n    \n    printf(\"\\nAverage Waiting Time: %.2f\\n\", avg_waiting);\n    printf(\"Average Turnaround Time: %.2f\\n\", avg_turnaround);\n}\n\nint main() {\n    process_t processes[] = {\n        {1, 0, 10, 0, 0},\n        {2, 0, 5, 0, 0},\n        {3, 0, 8, 0, 0}\n    };\n    \n    int n = sizeof(processes) / sizeof(processes[0]);\n    int time_quantum = 3;\n    \n    round_robin_scheduler(processes, n, time_quantum);\n    \n    return 0;\n}\n\n// Example 2 - Round Robin with different time quanta\n#include <stdio.h>\n\nvoid compare_time_quanta() {\n    process_t processes[] = {\n        {1, 0, 24, 0, 0},\n        {2, 0, 3, 0, 0},\n        {3, 0, 3, 0, 0}\n    };\n    \n    int n = sizeof(processes) / sizeof(processes[0]);\n    \n    printf(\"Comparing different time quanta in Round Robin:\\n\\n\");\n    \n    // Test with large time quantum (similar to FCFS)\n    printf(\"=== Time Quantum = 10 (Large) ===\\n\");\n    round_robin_scheduler(processes, n, 10);\n    \n    printf(\"\\n=== Time Quantum = 3 (Medium) ===\\n\");\n    round_robin_scheduler(processes, n, 3);\n    \n    printf(\"\\n=== Time Quantum = 1 (Small) ===\\n\");\n    round_robin_scheduler(processes, n, 1);\n    \n    printf(\"\\nNote how smaller time quanta improve response time\\n\");\n    printf(\"but increase context switching overhead\\n\");\n}\n\nint main() {\n    compare_time_quanta();\n    return 0;\n}"
          },
         
          {
            "id": "t17-multilevel",
            "title": "Multilevel Queue Scheduling",
            "desc": "Hierarchical scheduling with multiple priority queues",
            "note": "Multilevel queue scheduling is a sophisticated CPU scheduling algorithm that partitions the ready queue into several separate queues, each with its own scheduling algorithm and priority level. Processes are permanently assigned to a queue based on some process characteristic such as process type, priority, memory size, or other criteria. Common queue classifications include system processes (highest priority), interactive processes (medium priority), batch processes (low priority), and student processes (lowest priority). Each queue can have its own scheduling algorithm - typically, higher priority queues use preemptive algorithms like Round Robin for good response time, while lower priority queues use non-preemptive algorithms like FCFS for throughput. Scheduling between queues is usually done with fixed priority preemptive scheduling (no process in a lower queue can run until all higher queues are empty) or with time slicing (each queue gets a certain percentage of CPU time). Multilevel feedback queues extend this concept by allowing processes to move between queues based on their behavior and CPU burst characteristics. This approach provides flexibility to handle different types of processes appropriately and is widely used in modern operating systems like UNIX and Windows where processes have different priorities and scheduling requirements.",
            "code": "// Example 1 - Multilevel queue scheduling simulation\n#include <stdio.h>\n#include <stdbool.h>\n\n// Queue types\ntypedef enum {\n    QUEUE_SYSTEM,    // Highest priority, Round Robin\n    QUEUE_INTERACTIVE, // Medium priority, Round Robin\n    QUEUE_BATCH      // Lowest priority, FCFS\n} queue_type_t;\n\n// Enhanced process structure with queue assignment\ntypedef struct {\n    int pid;\n    int arrival_time;\n    int burst_time;\n    queue_type_t queue;\n    int waiting_time;\n    int turnaround_time;\n    int remaining_time;\n} mlq_process_t;\n\nconst char *queue_names[] = {\n    \"SYSTEM\", \"INTERACTIVE\", \"BATCH\"\n};\n\nvoid multilevel_queue_scheduler(mlq_process_t processes[], int n, \n                               int system_quantum, int interactive_quantum) {\n    int current_time = 0;\n    int completed = 0;\n    \n    // Initialize remaining times\n    for (int i = 0; i < n; i++) {\n        processes[i].remaining_time = processes[i].burst_time;\n        processes[i].waiting_time = 0;\n        processes[i].turnaround_time = 0;\n    }\n    \n    printf(\"Multilevel Queue Scheduling:\\n\\n\");\n    printf(\"Time\\tPID\\tQueue\\t\\tRemaining\\tAction\\n\");\n    \n    while (completed < n) {\n        bool found_process = false;\n        \n        // Check queues in priority order: SYSTEM -> INTERACTIVE -> BATCH\n        for (int queue_level = QUEUE_SYSTEM; queue_level <= QUEUE_BATCH; queue_level++) {\n            for (int i = 0; i < n; i++) {\n                if (processes[i].arrival_time <= current_time && \n                    processes[i].remaining_time > 0 &&\n                    processes[i].queue == queue_level) {\n                    \n                    found_process = true;\n                    int time_quantum;\n                    \n                    // Determine time quantum based on queue\n                    switch (queue_level) {\n                        case QUEUE_SYSTEM:\n                            time_quantum = system_quantum;\n                            break;\n                        case QUEUE_INTERACTIVE:\n                            time_quantum = interactive_quantum;\n                            break;\n                        case QUEUE_BATCH:\n                            time_quantum = processes[i].remaining_time; // FCFS\n                            break;\n                    }\n                    \n                    int execution_time = (processes[i].remaining_time > time_quantum) ? \n                                       time_quantum : processes[i].remaining_time;\n                    \n                    printf(\"%d\\t%d\\t%-12s\\t%d\\t\\t\", current_time, processes[i].pid, \n                           queue_names[queue_level], processes[i].remaining_time);\n                    \n                    // Update waiting times for other processes\n                    for (int j = 0; j < n; j++) {\n                        if (j != i && \n                            processes[j].arrival_time <= current_time && \n                            processes[j].remaining_time > 0) {\n                            processes[j].waiting_time += execution_time;\n                        }\n                    }\n                    \n                    // Execute the process\n                    processes[i].remaining_time -= execution_time;\n                    current_time += execution_time;\n                    \n                    if (processes[i].remaining_time == 0) {\n                        printf(\"Completed\\n\");\n                        completed++;\n                        processes[i].turnaround_time = current_time - processes[i].arrival_time;\n                    } else {\n                        printf(\"Preempted\\n\");\n                    }\n                    \n                    break; // Process one queue level at a time\n                }\n            }\n            if (found_process) break;\n        }\n        \n        if (!found_process) {\n            current_time++; // Idle CPU time\n        }\n    }\n    \n    printf(\"\\nFinal Results:\\n\");\n    printf(\"PID\\tQueue\\t\\tWaiting\\tTurnaround\\n\");\n    \n    double avg_waiting = 0, avg_turnaround = 0;\n    for (int i = 0; i < n; i++) {\n        printf(\"%d\\t%-12s\\t%d\\t%d\\n\", processes[i].pid, \n               queue_names[processes[i].queue],\n               processes[i].waiting_time, processes[i].turnaround_time);\n        avg_waiting += processes[i].waiting_time;\n        avg_turnaround += processes[i].turnaround_time;\n    }\n    \n    avg_waiting /= n;\n    avg_turnaround /= n;\n    \n    printf(\"\\nAverage Waiting Time: %.2f\\n\", avg_waiting);\n    printf(\"Average Turnaround Time: %.2f\\n\", avg_turnaround);\n}\n\nint main() {\n    mlq_process_t processes[] = {\n        {1, 0, 8, QUEUE_SYSTEM, 0, 0, 0},\n        {2, 0, 4, QUEUE_INTERACTIVE, 0, 0, 0},\n        {3, 0, 12, QUEUE_BATCH, 0, 0, 0},\n        {4, 2, 6, QUEUE_INTERACTIVE, 0, 0, 0}\n    };\n    \n    int n = sizeof(processes) / sizeof(processes[0]);\n    int system_quantum = 2;\n    int interactive_quantum = 4;\n    \n    multilevel_queue_scheduler(processes, n, system_quantum, interactive_quantum);\n    \n    return 0;\n}\n\n// Example 2 - Multilevel feedback queue simulation\n#include <stdio.h>\n#include <stdbool.h>\n\nvoid multilevel_feedback_queue(mlq_process_t processes[], int n, \n                              int quantums[], int num_queues) {\n    printf(\"Multilevel Feedback Queue Simulation:\\n\\n\");\n    printf(\"Processes can move between queues based on CPU burst behavior\\n\");\n    \n    // Initialize processes with dynamic queue assignment\n    for (int i = 0; i < n; i++) {\n        processes[i].queue = QUEUE_SYSTEM; // Start in highest priority queue\n        processes[i].remaining_time = processes[i].burst_time;\n        processes[i].waiting_time = 0;\n        processes[i].turnaround_time = 0;\n    }\n    \n    int current_time = 0;\n    int completed = 0;\n    \n    while (completed < n) {\n        bool found_process = false;\n        \n        for (int q = 0; q < num_queues; q++) {\n            for (int i = 0; i < n; i++) {\n                if (processes[i].arrival_time <= current_time && \n                    processes[i].remaining_time > 0 &&\n                    processes[i].queue == q) {\n                    \n                    found_process = true;\n                    int time_quantum = quantums[q];\n                    int execution_time = (processes[i].remaining_time > time_quantum) ? \n                                       time_quantum : processes[i].remaining_time;\n                    \n                    printf(\"Time %d: PID %d in Queue %d (Quantum=%d)\\n\", \n                           current_time, processes[i].pid, q, time_quantum);\n                    \n                    // Update other processes' waiting time\n                    for (int j = 0; j < n; j++) {\n                        if (j != i && processes[j].arrival_time <= current_time && \n                            processes[j].remaining_time > 0) {\n                            processes[j].waiting_time += execution_time;\n                        }\n                    }\n                    \n                    processes[i].remaining_time -= execution_time;\n                    current_time += execution_time;\n                    \n                    if (processes[i].remaining_time == 0) {\n                        printf(\"  PID %d completed\\n\", processes[i].pid);\n                        processes[i].turnaround_time = current_time - processes[i].arrival_time;\n                        completed++;\n                    } else {\n                        // Demote to lower priority queue if not finished\n                        if (q < num_queues - 1) {\n                            processes[i].queue = q + 1;\n                            printf(\"  PID %d demoted to Queue %d\\n\", processes[i].pid, q + 1);\n                        } else {\n                            printf(\"  PID %d remains in lowest queue\\n\", processes[i].pid);\n                        }\n                    }\n                    \n                    break;\n                }\n            }\n            if (found_process) break;\n        }\n        \n        if (!found_process) current_time++;\n    }\n    \n    printf(\"\\nFinal Results:\\n\");\n    double avg_waiting = 0, avg_turnaround = 0;\n    for (int i = 0; i < n; i++) {\n        printf(\"PID %d: Waiting=%d, Turnaround=%d\\n\", \n               processes[i].pid, processes[i].waiting_time, processes[i].turnaround_time);\n        avg_waiting += processes[i].waiting_time;\n        avg_turnaround += processes[i].turnaround_time;\n    }\n    printf(\"Averages: Waiting=%.2f, Turnaround=%.2f\\n\", \n           avg_waiting/n, avg_turnaround/n);\n}\n\nint main() {\n    mlq_process_t processes[] = {\n        {1, 0, 20, 0, 0, 0, 0},\n        {2, 0, 12, 0, 0, 0, 0},\n        {3, 0, 8, 0, 0, 0, 0},\n        {4, 0, 16, 0, 0, 0, 0}\n    };\n    \n    int n = sizeof(processes) / sizeof(processes[0]);\n    int quantums[] = {4, 8, 16}; // Time quantums for 3 queues\n    int num_queues = sizeof(quantums) / sizeof(quantums[0]);\n    \n    multilevel_feedback_queue(processes, n, quantums, num_queues);\n    \n    return 0;\n}"
          }
        ]
      },
      {
        "id": "c5-synchronization",
        "title": "Process Synchronization",
        "desc": "Techniques for coordinating process execution and shared resource access",
        "notes": "Process synchronization is a fundamental aspect of operating systems that deals with coordinating the execution of multiple processes that share resources. When processes access shared data or resources concurrently, there's a risk of race conditions where the final outcome depends on the specific sequence of execution. The critical section problem is at the heart of process synchronization - ensuring that only one process can execute its critical section (code accessing shared resources) at a time. Solutions to this problem must satisfy three conditions: mutual exclusion (only one process in critical section), progress (if no process is in critical section, a waiting process can enter), and bounded waiting (a process should not wait indefinitely to enter its critical section). Operating systems provide various synchronization mechanisms including semaphores (integer variables with atomic wait and signal operations), mutexes (binary semaphores for mutual exclusion), monitors (high-level synchronization constructs that encapsulate shared data and operations), and condition variables. These tools help prevent problems like deadlocks, starvation, and data inconsistencies while allowing efficient use of system resources through controlled concurrent access.",
        "code": "",
        "duration": "Week 1",
        "topics": [
          {
            "id": "t18-critical-section",
            "title": "Critical Section Problem",
            "desc": "Coordinating access to shared resources among concurrent processes",
            "note": "The critical section problem is a fundamental challenge in operating systems where multiple processes need to access shared resources or variables without causing inconsistencies. A critical section is a code segment that accesses shared resources and must be executed atomically - only one process can be in its critical section at any time. The problem requires solutions that satisfy three essential conditions: mutual exclusion (only one process can execute in its critical section at a time), progress (if no process is in its critical section and some processes wish to enter, only those not executing in their remainder sections can participate in the decision, and the selection cannot be postponed indefinitely), and bounded waiting (there exists a bound on the number of times other processes are allowed to enter their critical sections after a process has made a request to enter its critical section and before that request is granted). Solutions to the critical section problem can be classified as software-based (using algorithms like Peterson's solution or Bakery algorithm) or hardware-based (using atomic instructions like test-and-set or compare-and-swap). Modern operating systems typically provide synchronization primitives like mutexes and semaphores that implement solutions to the critical section problem, allowing application developers to focus on higher-level synchronization concerns rather than low-level implementation details.",
            "code": "// Example 1 - Demonstrating the critical section problem\n#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\n// Shared resource\nint shared_counter = 0;\n\n// Function without critical section protection\nvoid *increment_without_protection(void *arg) {\n    int iterations = *(int*)arg;\n    \n    for (int i = 0; i < iterations; i++) {\n        // Critical section (without protection)\n        int temp = shared_counter;\n        temp = temp + 1;\n        // Simulate context switch possibility\n        usleep(100); \n        shared_counter = temp;\n    }\n    \n    return NULL;\n}\n\nvoid demonstrate_race_condition() {\n    pthread_t thread1, thread2;\n    int iterations = 100;\n    \n    printf(\"Demonstrating Critical Section Problem:\\n\");\n    printf(\"Initial shared counter: %d\\n\", shared_counter);\n    \n    // Create two threads that access shared resource without protection\n    pthread_create(&thread1, NULL, increment_without_protection, &iterations);\n    pthread_create(&thread2, NULL, increment_without_protection, &iterations);\n    \n    // Wait for threads to complete\n    pthread_join(thread1, NULL);\n    pthread_join(thread2, NULL);\n    \n    printf(\"Final shared counter: %d\\n\", shared_counter);\n    printf(\"Expected value: %d\\n\", iterations * 2);\n    printf(\"Race condition evident: %d != %d\\n\", shared_counter, iterations * 2);\n}\n\n// Example 2 - Peterson's solution for critical section\nint turn = 0;\nint flag[2] = {0, 0}; // Two processes\n\nvoid enter_critical_section(int process_id) {\n    int other = 1 - process_id;\n    flag[process_id] = 1;\n    turn = process_id;\n    \n    // Wait until other process finishes or it's not their turn\n    while (flag[other] == 1 && turn == process_id) {\n        // Busy wait\n    }\n}\n\nvoid leave_critical_section(int process_id) {\n    flag[process_id] = 0;\n}\n\nvoid *peterson_solution_demo(void *arg) {\n    int process_id = *(int*)arg;\n    int iterations = 50;\n    \n    for (int i = 0; i < iterations; i++) {\n        enter_critical_section(process_id);\n        \n        // Critical section\n        shared_counter++;\n        printf(\"Process %d in critical section, counter: %d\\n\", \n               process_id, shared_counter);\n        \n        leave_critical_section(process_id);\n        \n        // Remainder section\n        usleep(1000);\n    }\n    \n    return NULL;\n}\n\nvoid test_peterson_solution() {\n    printf(\"\\nTesting Peterson's Solution for Critical Section:\\n\");\n    shared_counter = 0;\n    \n    pthread_t thread1, thread2;\n    int id1 = 0, id2 = 1;\n    \n    pthread_create(&thread1, NULL, peterson_solution_demo, &id1);\n    pthread_create(&thread2, NULL, peterson_solution_demo, &id2);\n    \n    pthread_join(thread1, NULL);\n    pthread_join(thread2, NULL);\n    \n    printf(\"Final counter with Peterson's solution: %d\\n\", shared_counter);\n    printf(\"Expected: %d\\n\", 100);\n}\n\nint main() {\n    demonstrate_race_condition();\n    test_peterson_solution();\n    return 0;\n}"
          },
          {
            "id": "t19-semaphores",
            "title": "Semaphores and Synchronization",
            "desc": "Integer variables for controlling access to shared resources",
            "note": "Semaphores are synchronization primitives introduced by Edsger Dijkstra that provide a robust solution to the critical section problem and other synchronization challenges. A semaphore is an integer variable that, apart from initialization, is accessed only through two atomic operations: wait (or P) and signal (or V). The wait operation decrements the semaphore value and if it becomes negative, blocks the process. The signal operation increments the semaphore value and if there are waiting processes, wakes one up. Semaphores can be used for two main purposes: mutual exclusion (using binary semaphores/mutexes with initial value 1) and resource counting (using counting semaphores with initial value N representing available resources). Operating systems implement semaphores using various approaches including busy waiting (spinlocks) or blocking (putting processes to sleep). Modern systems typically use blocking semaphores to avoid wasting CPU cycles. Semaphores are versatile tools that can solve various synchronization problems including producer-consumer, reader-writer, and dining philosophers. However, they require careful usage as incorrect implementation can lead to deadlocks or starvation. Most programming languages and operating systems provide built-in semaphore implementations that handle the low-level details of atomic operations and process blocking, making them accessible to application developers for solving complex synchronization problems.",
            "code": "// Example 1 - Implementing semaphores for mutual exclusion\n#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\n// Shared resource\nint shared_counter = 0;\n\n// Semaphore for mutual exclusion\nsem_t mutex;\n\nvoid *thread_with_semaphore(void *arg) {\n    int iterations = *(int*)arg;\n    \n    for (int i = 0; i < iterations; i++) {\n        // Wait on semaphore (enter critical section)\n        sem_wait(&mutex);\n        \n        // Critical section\n        shared_counter++;\n        printf(\"Thread %ld: counter = %d\\n\", (long)pthread_self(), shared_counter);\n        \n        // Signal semaphore (exit critical section)\n        sem_post(&mutex);\n        \n        // Remainder section\n        usleep(1000);\n    }\n    \n    return NULL;\n}\n\nvoid demonstrate_semaphores() {\n    pthread_t thread1, thread2;\n    int iterations = 50;\n    \n    // Initialize semaphore with value 1 (binary semaphore for mutual exclusion)\n    sem_init(&mutex, 0, 1);\n    \n    printf(\"Demonstrating Semaphores for Mutual Exclusion:\\n\");\n    printf(\"Initial shared counter: %d\\n\", shared_counter);\n    \n    pthread_create(&thread1, NULL, thread_with_semaphore, &iterations);\n    pthread_create(&thread2, NULL, thread_with_semaphore, &iterations);\n    \n    pthread_join(thread1, NULL);\n    pthread_join(thread2, NULL);\n    \n    printf(\"Final shared counter: %d\\n\", shared_counter);\n    printf(\"Expected: %d\\n\", iterations * 2);\n    \n    // Destroy semaphore\n    sem_destroy(&mutex);\n}\n\n// Example 2 - Producer-Consumer problem with semaphores\n#define BUFFER_SIZE 5\n\nint buffer[BUFFER_SIZE];\nint in = 0, out = 0;\n\nsem_t empty; // Counts empty slots\nsem_t full;  // Counts full slots\nsem_t mutex; // For mutual exclusion\n\nvoid *producer(void *arg) {\n    int item = 0;\n    \n    for (int i = 0; i < 10; i++) {\n        item = i + 1;\n        \n        // Wait for empty slot\n        sem_wait(&empty);\n        // Wait for mutex\n        sem_wait(&mutex);\n        \n        // Critical section: add item to buffer\n        buffer[in] = item;\n        printf(\"Produced: %d at position %d\\n\", item, in);\n        in = (in + 1) % BUFFER_SIZE;\n        \n        // Release mutex\n        sem_post(&mutex);\n        // Signal that a slot is now full\n        sem_post(&full);\n        \n        usleep(100000);\n    }\n    \n    return NULL;\n}\n\nvoid *consumer(void *arg) {\n    int item;\n    \n    for (int i = 0; i < 10; i++) {\n        // Wait for full slot\n        sem_wait(&full);\n        // Wait for mutex\n        sem_wait(&mutex);\n        \n        // Critical section: remove item from buffer\n        item = buffer[out];\n        printf(\"Consumed: %d from position %d\\n\", item, out);\n        out = (out + 1) % BUFFER_SIZE;\n        \n        // Release mutex\n        sem_post(&mutex);\n        // Signal that a slot is now empty\n        sem_post(&empty);\n        \n        usleep(150000);\n    }\n    \n    return NULL;\n}\n\nvoid producer_consumer_demo() {\n    printf(\"\\nProducer-Consumer Problem with Semaphores:\\n\");\n    \n    // Initialize semaphores\n    sem_init(&empty, 0, BUFFER_SIZE); // Initially all slots empty\n    sem_init(&full, 0, 0);            // Initially no full slots\n    sem_init(&mutex, 0, 1);           // Binary semaphore for mutual exclusion\n    \n    pthread_t prod_thread, cons_thread;\n    \n    pthread_create(&prod_thread, NULL, producer, NULL);\n    pthread_create(&cons_thread, NULL, consumer, NULL);\n    \n    pthread_join(prod_thread, NULL);\n    pthread_join(cons_thread, NULL);\n    \n    // Destroy semaphores\n    sem_destroy(&empty);\n    sem_destroy(&full);\n    sem_destroy(&mutex);\n}\n\nint main() {\n    demonstrate_semaphores();\n    producer_consumer_demo();\n    return 0;\n}"
          },
          {
            "id": "t20-monitors",
            "title": "Monitors and High-level Synchronization",
            "desc": "Structured approach to synchronization using encapsulated operations",
            "note": "Monitors are high-level synchronization constructs that provide a structured approach to managing concurrent access to shared resources. A monitor is an abstract data type that encapsulates shared data and the procedures that operate on that data, ensuring that only one process can be active within the monitor at any time. Monitors automatically provide mutual exclusion - when a process enters a monitor procedure, it automatically gains exclusive access to the monitor's data. For more complex synchronization needs, monitors use condition variables that allow processes to wait for certain conditions to become true. Condition variables support operations like wait (release monitor lock and block until signaled), signal (wake up one waiting process), and broadcast (wake up all waiting processes). Unlike semaphores, monitors are programming language constructs rather than OS primitives, and they provide better encapsulation and reduced programming errors. Languages like Java (with synchronized methods and wait/notify) and Python (with threading.Condition) provide monitor-like functionality. Monitors help prevent common synchronization errors by enforcing structured access to shared data and making the synchronization logic more explicit and maintainable. They are particularly useful for implementing complex synchronization patterns like readers-writers problems, bounded buffers, and resource allocation systems where multiple conditions need to be managed.",
            "code": "// Example 1 - Monitor-like implementation using mutex and condition variables\n#include <stdio.h>\n#include <pthread.h>\n\n// Shared data structure\ntypedef struct {\n    int value;\n    pthread_mutex_t mutex;\n    pthread_cond_t cond;\n} shared_data_t;\n\n// Monitor-like procedure to increment value\nvoid monitor_increment(shared_data_t *data, int increment_by) {\n    pthread_mutex_lock(&data->mutex);\n    \n    // Critical section - only one thread can execute this at a time\n    printf(\"Thread %ld: incrementing value by %d\\n\", \n           (long)pthread_self(), increment_by);\n    data->value += increment_by;\n    printf(\"New value: %d\\n\", data->value);\n    \n    // Signal any waiting threads that value has changed\n    pthread_cond_broadcast(&data->cond);\n    \n    pthread_mutex_unlock(&data->mutex);\n}\n\n// Monitor-like procedure that waits for a condition\nvoid monitor_wait_for_value(shared_data_t *data, int target_value) {\n    pthread_mutex_lock(&data->mutex);\n    \n    while (data->value < target_value) {\n        printf(\"Thread %ld: waiting for value to reach %d (current: %d)\\n\", \n               (long)pthread_self(), target_value, data->value);\n        pthread_cond_wait(&data->cond, &data->mutex);\n    }\n    \n    printf(\"Thread %ld: condition met, value is now %d\\n\", \n           (long)pthread_self(), data->value);\n    \n    pthread_mutex_unlock(&data->mutex);\n}\n\nvoid *thread_func1(void *arg) {\n    shared_data_t *data = (shared_data_t*)arg;\n    \n    // Wait for value to reach at least 15\n    monitor_wait_for_value(data, 15);\n    \n    // Then increment by 5\n    monitor_increment(data, 5);\n    \n    return NULL;\n}\n\nvoid *thread_func2(void *arg) {\n    shared_data_t *data = (shared_data_t*)arg;\n    \n    // Increment several times\n    for (int i = 0; i < 5; i++) {\n        monitor_increment(data, 3);\n        usleep(100000);\n    }\n    \n    return NULL;\n}\n\nvoid demonstrate_monitor_pattern() {\n    shared_data_t data = {\n        .value = 0,\n        .mutex = PTHREAD_MUTEX_INITIALIZER,\n        .cond = PTHREAD_COND_INITIALIZER\n    };\n    \n    printf(\"Demonstrating Monitor-like Synchronization:\\n\");\n    printf(\"Initial value: %d\\n\", data.value);\n    \n    pthread_t thread1, thread2;\n    \n    pthread_create(&thread1, NULL, thread_func1, &data);\n    pthread_create(&thread2, NULL, thread_func2, &data);\n    \n    pthread_join(thread1, NULL);\n    pthread_join(thread2, NULL);\n    \n    printf(\"Final value: %d\\n\", data.value);\n    \n    // Cleanup\n    pthread_mutex_destroy(&data.mutex);\n    pthread_cond_destroy(&data.cond);\n}\n\n// Example 2 - Bounded buffer using monitor pattern\n#define BUFFER_CAPACITY 3\n\ntypedef struct {\n    int buffer[BUFFER_CAPACITY];\n    int count;\n    int in;\n    int out;\n    pthread_mutex_t mutex;\n    pthread_cond_t not_empty;\n    pthread_cond_t not_full;\n} bounded_buffer_t;\n\nvoid buffer_init(bounded_buffer_t *buf) {\n    buf->count = 0;\n    buf->in = 0;\n    buf->out = 0;\n    pthread_mutex_init(&buf->mutex, NULL);\n    pthread_cond_init(&buf->not_empty, NULL);\n    pthread_cond_init(&buf->not_full, NULL);\n}\n\nvoid buffer_destroy(bounded_buffer_t *buf) {\n    pthread_mutex_destroy(&buf->mutex);\n    pthread_cond_destroy(&buf->not_empty);\n    pthread_cond_destroy(&buf->not_full);\n}\n\nvoid buffer_put(bounded_buffer_t *buf, int item) {\n    pthread_mutex_lock(&buf->mutex);\n    \n    // Wait until buffer is not full\n    while (buf->count == BUFFER_CAPACITY) {\n        printf(\"Producer waiting: buffer full\\n\");\n        pthread_cond_wait(&buf->not_full, &buf->mutex);\n    }\n    \n    // Add item to buffer\n    buf->buffer[buf->in] = item;\n    buf->in = (buf->in + 1) % BUFFER_CAPACITY;\n    buf->count++;\n    \n    printf(\"Produced: %d, count: %d\\n\", item, buf->count);\n    \n    // Signal that buffer is not empty\n    pthread_cond_signal(&buf->not_empty);\n    \n    pthread_mutex_unlock(&buf->mutex);\n}\n\nint buffer_get(bounded_buffer_t *buf) {\n    pthread_mutex_lock(&buf->mutex);\n    \n    // Wait until buffer is not empty\n    while (buf->count == 0) {\n        printf(\"Consumer waiting: buffer empty\\n\");\n        pthread_cond_wait(&buf->not_empty, &buf->mutex);\n    }\n    \n    // Remove item from buffer\n    int item = buf->buffer[buf->out];\n    buf->out = (buf->out + 1) % BUFFER_CAPACITY;\n    buf->count--;\n    \n    printf(\"Consumed: %d, count: %d\\n\", item, buf->count);\n    \n    // Signal that buffer is not full\n    pthread_cond_signal(&buf->not_full);\n    \n    pthread_mutex_unlock(&buf->mutex);\n    \n    return item;\n}\n\nvoid *producer_monitor(void *arg) {\n    bounded_buffer_t *buf = (bounded_buffer_t*)arg;\n    \n    for (int i = 1; i <= 6; i++) {\n        buffer_put(buf, i);\n        usleep(100000);\n    }\n    \n    return NULL;\n}\n\nvoid *consumer_monitor(void *arg) {\n    bounded_buffer_t *buf = (bounded_buffer_t*)arg;\n    \n    for (int i = 0; i < 6; i++) {\n        int item = buffer_get(buf);\n        usleep(150000);\n    }\n    \n    return NULL;\n}\n\nvoid bounded_buffer_demo() {\n    printf(\"\\nBounded Buffer using Monitor Pattern:\\n\");\n    \n    bounded_buffer_t buffer;\n    buffer_init(&buffer);\n    \n    pthread_t producer_thread, consumer_thread;\n    \n    pthread_create(&producer_thread, NULL, producer_monitor, &buffer);\n    pthread_create(&consumer_thread, NULL, consumer_monitor, &buffer);\n    \n    pthread_join(producer_thread, NULL);\n    pthread_join(consumer_thread, NULL);\n    \n    buffer_destroy(&buffer);\n}\n\nint main() {\n    demonstrate_monitor_pattern();\n    bounded_buffer_demo();\n    return 0;\n}"
          },
          {
            "id": "t21-deadlock-basics",
            "title": "Deadlock Fundamentals",
            "desc": "Understanding conditions and basics of deadlock situations",
            "note": "Deadlock is a situation in operating systems where two or more processes are unable to proceed because each is waiting for a resource that is held by another process in the set. This results in a permanent blocking of the processes involved. Deadlock occurs when four necessary conditions hold simultaneously: mutual exclusion (resources cannot be shared, only one process can use a resource at a time), hold and wait (processes hold resources while waiting for additional resources), no preemption (resources cannot be forcibly taken from processes), and circular wait (a circular chain of processes exists where each process waits for a resource held by the next process in the chain). Deadlocks can involve various types of resources including hardware devices, memory pages, files, database records, and other system resources. Systems handle deadlocks through prevention (designing the system to avoid one of the four conditions), avoidance (dynamically checking if resource allocation might lead to deadlock), detection (periodically checking for deadlock existence), and recovery (breaking deadlocks when they occur). Understanding deadlock fundamentals is crucial for system designers and developers to create robust systems that either avoid deadlocks entirely or can recover from them efficiently, ensuring system reliability and availability.",
            "code": "// Example 1 - Demonstrating deadlock conditions\n#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\n// Two resources\npthread_mutex_t resource1 = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t resource2 = PTHREAD_MUTEX_INITIALIZER;\n\nvoid *process1(void *arg) {\n    printf(\"Process 1: Attempting to acquire resource 1\\n\");\n    pthread_mutex_lock(&resource1);\n    printf(\"Process 1: Acquired resource 1\\n\");\n    \n    // Simulate some work\n    usleep(100000);\n    \n    printf(\"Process 1: Attempting to acquire resource 2\\n\");\n    pthread_mutex_lock(&resource2); // This will cause deadlock\n    printf(\"Process 1: Acquired resource 2\\n\");\n    \n    // Critical section\n    printf(\"Process 1: Using both resources\\n\");\n    \n    pthread_mutex_unlock(&resource2);\n    pthread_mutex_unlock(&resource1);\n    \n    return NULL;\n}\n\nvoid *process2(void *arg) {\n    printf(\"Process 2: Attempting to acquire resource 2\\n\");\n    pthread_mutex_lock(&resource2);\n    printf(\"Process 2: Acquired resource 2\\n\");\n    \n    // Simulate some work\n    usleep(100000);\n    \n    printf(\"Process 2: Attempting to acquire resource 1\\n\");\n    pthread_mutex_lock(&resource1); // This will cause deadlock\n    printf(\"Process 2: Acquired resource 1\\n\");\n    \n    // Critical section\n    printf(\"Process 2: Using both resources\\n\");\n    \n    pthread_mutex_unlock(&resource1);\n    pthread_mutex_unlock(&resource2);\n    \n    return NULL;\n}\n\nvoid demonstrate_deadlock() {\n    pthread_t thread1, thread2;\n    \n    printf(\"Demonstrating Deadlock Conditions:\\n\");\n    printf(\"1. Mutual Exclusion: Resources cannot be shared\\n\");\n    printf(\"2. Hold and Wait: Processes hold resources while waiting for others\\n\");\n    printf(\"3. No Preemption: Resources cannot be forcibly taken\\n\");\n    printf(\"4. Circular Wait: Process1 waits for resource2 held by Process2\\n\");\n    printf(\"                  Process2 waits for resource1 held by Process1\\n\\n\");\n    \n    pthread_create(&thread1, NULL, process1, NULL);\n    pthread_create(&thread2, NULL, process2, NULL);\n    \n    // Wait a bit to see if deadlock occurs\n    sleep(3);\n    \n    printf(\"\\nIf you see this message, the threads are deadlocked and won't complete\\n\");\n    printf(\"The program will hang until manually terminated\\n\");\n    \n    pthread_join(thread1, NULL);\n    pthread_join(thread2, NULL);\n}\n\n// Example 2 - Deadlock avoidance by resource ordering\nvoid *process1_safe(void *arg) {\n    printf(\"Process 1 (Safe): Attempting to acquire resource 1\\n\");\n    pthread_mutex_lock(&resource1);\n    printf(\"Process 1 (Safe): Acquired resource 1\\n\");\n    \n    usleep(100000);\n    \n    printf(\"Process 1 (Safe): Attempting to acquire resource 2\\n\");\n    pthread_mutex_lock(&resource2);\n    printf(\"Process 1 (Safe): Acquired resource 2\\n\");\n    \n    printf(\"Process 1 (Safe): Using both resources\\n\");\n    \n    pthread_mutex_unlock(&resource2);\n    pthread_mutex_unlock(&resource1);\n    \n    return NULL;\n}\n\nvoid *process2_safe(void *arg) {\n    // Use same order as process1: resource1 first, then resource2\n    printf(\"Process 2 (Safe): Attempting to acquire resource 1\\n\");\n    pthread_mutex_lock(&resource1);\n    printf(\"Process 2 (Safe): Acquired resource 1\\n\");\n    \n    usleep(100000);\n    \n    printf(\"Process 2 (Safe): Attempting to acquire resource 2\\n\");\n    pthread_mutex_lock(&resource2);\n    printf(\"Process 2 (Safe): Acquired resource 2\\n\");\n    \n    printf(\"Process 2 (Safe): Using both resources\\n\");\n    \n    pthread_mutex_unlock(&resource2);\n    pthread_mutex_unlock(&resource1);\n    \n    return NULL;\n}\n\nvoid demonstrate_deadlock_avoidance() {\n    pthread_t thread1, thread2;\n    \n    printf(\"\\nDemonstrating Deadlock Avoidance by Resource Ordering:\\n\");\n    printf(\"Both processes acquire resources in the same order (1 then 2)\\n\");\n    printf(\"This prevents circular wait condition\\n\\n\");\n    \n    pthread_create(&thread1, NULL, process1_safe, NULL);\n    pthread_create(&thread2, NULL, process2_safe, NULL);\n    \n    pthread_join(thread1, NULL);\n    pthread_join(thread2, NULL);\n    \n    printf(\"Both processes completed successfully - no deadlock\\n\");\n}\n\nint main() {\n    // Warning: The first demonstration will cause a deadlock\n    // You may want to comment out the first call during testing\n    // demonstrate_deadlock();\n    \n    demonstrate_deadlock_avoidance();\n    \n    // Cleanup\n    pthread_mutex_destroy(&resource1);\n    pthread_mutex_destroy(&resource2);\n    \n    return 0;\n}"
          }
        ]
      },
      {
        "id": "c6-memory",
        "title": "Memory Management",
        "desc": "Techniques for managing main memory allocation and virtualization",
        "notes": "Memory management is a critical function of operating systems that involves managing the computer's primary memory (RAM) to optimize performance and ensure proper isolation between processes. The OS is responsible for allocating memory to processes, tracking which parts of memory are in use and by whom, deciding which processes to load into memory when space becomes available, and managing the movement of data between main memory and disk storage. Key memory management techniques include partitioning (dividing memory into fixed or variable-sized sections), paging (dividing memory into fixed-sized pages and processes into same-sized frames), segmentation (dividing memory into logical segments of variable sizes), and virtual memory (using disk storage to extend apparent memory capacity). Memory management must address issues such as fragmentation (external - free memory is scattered, internal - allocated memory is underutilized), protection (preventing processes from accessing each other's memory), and sharing (allowing controlled access to shared memory regions). Modern operating systems use sophisticated memory management techniques combining paging and segmentation with virtual memory to provide each process with its own protected address space while efficiently utilizing physical memory resources.",
        "code": "",
        "duration": "Week 1",
        "topics": [
          {
            "id": "t22-paging",
            "title": "Paging Memory Management",
            "desc": "Dividing memory into fixed-sized pages for efficient allocation",
            "note": "Paging is a memory management scheme that eliminates the problem of external fragmentation by dividing physical memory into fixed-sized blocks called frames and logical memory into blocks of the same size called pages. When a process is to be executed, its pages are loaded into any available memory frames from secondary storage. The hardware support for paging includes a page table for each process that maps logical page numbers to physical frame numbers. The key advantages of paging are that it eliminates external fragmentation (since any page can go into any frame) and simplifies memory allocation (OS only needs to keep track of free frames). However, paging can still suffer from internal fragmentation (the last page of a process may not be completely full). Modern systems use multi-level paging to handle large address spaces efficiently. The translation lookaside buffer (TLB) is used to cache recent page table lookups and speed up address translation. Paging also forms the basis for virtual memory systems where not all pages need to be in memory simultaneously, allowing processes to be larger than physical memory. The page table structure, TLB management, and page replacement algorithms are critical components that determine the performance of paged memory systems.",
            "code": "// Example 1 - Simulating paging address translation\n#include <stdio.h>\n#include <stdint.h>\n\n// Simulated page table\ntypedef struct {\n    int valid;    // 1 if page is in memory, 0 otherwise\n    int frame;    // Physical frame number\n    int referenced; // Used for page replacement algorithms\n    int modified;  // Dirty bit\n} page_table_entry_t;\n\n// Simulated memory\ntypedef struct {\n    uint8_t data[256]; // 256-byte frames\n} memory_frame_t;\n\n// Convert logical address to page number and offset\nvoid logical_to_physical(uint16_t logical_addr, int page_size, \n                        int *page_num, int *offset) {\n    *page_num = logical_addr / page_size;\n    *offset = logical_addr % page_size;\n}\n\nvoid simulate_paging() {\n    const int PAGE_SIZE = 256; // 256-byte pages\n    const int NUM_PAGES = 16;  // 16 pages in logical address space\n    const int NUM_FRAMES = 8;  // 8 frames in physical memory\n    \n    // Initialize page table\n    page_table_entry_t page_table[NUM_PAGES];\n    for (int i = 0; i < NUM_PAGES; i++) {\n        page_table[i].valid = 0;\n        page_table[i].frame = -1;\n        page_table[i].referenced = 0;\n        page_table[i].modified = 0;\n    }\n    \n    // Initialize physical memory\n    memory_frame_t physical_memory[NUM_FRAMES];\n    \n    // Simulate page table entries\n    page_table[0].valid = 1; page_table[0].frame = 3;\n    page_table[1].valid = 1; page_table[1].frame = 1;\n    page_table[2].valid = 1; page_table[2].frame = 7;\n    page_table[3].valid = 0; // Page not in memory\n    \n    printf(\"Paging Simulation:\\n\");\n    printf(\"Page Size: %d bytes\\n\", PAGE_SIZE);\n    printf(\"Number of Pages: %d\\n\", NUM_PAGES);\n    printf(\"Number of Frames: %d\\n\\n\", NUM_FRAMES);\n    \n    // Test address translation\n    uint16_t logical_addresses[] = {0x0123, 0x0256, 0x03FF, 0x0400};\n    \n    for (int i = 0; i < 4; i++) {\n        uint16_t logical_addr = logical_addresses[i];\n        int page_num, offset;\n        \n        logical_to_physical(logical_addr, PAGE_SIZE, &page_num, &offset);\n        \n        printf(\"Logical Address: 0x%04X\\n\", logical_addr);\n        printf(\"  Page Number: %d, Offset: %d\\n\", page_num, offset);\n        \n        if (page_num < NUM_PAGES && page_table[page_num].valid) {\n            int frame_num = page_table[page_num].frame;\n            uint16_t physical_addr = frame_num * PAGE_SIZE + offset;\n            printf(\"  Page is in Frame: %d\\n\", frame_num);\n            printf(\"  Physical Address: 0x%04X\\n\", physical_addr);\n        } else {\n            printf(\"  Page Fault! Page %d not in memory\\n\", page_num);\n        }\n        printf(\"\\n\");\n    }\n}\n\n// Example 2 - Simple page replacement simulation (FIFO)\n#include <stdio.h>\n\n#define NUM_FRAMES 3\n#define NUM_PAGES 10\n\nvoid fifo_page_replacement() {\n    int reference_string[NUM_PAGES] = {7, 0, 1, 2, 0, 3, 0, 4, 2, 3};\n    int frames[NUM_FRAMES] = {-1, -1, -1}; // -1 means empty\n    int page_faults = 0;\n    int next_victim = 0; // For FIFO replacement\n    \n    printf(\"FIFO Page Replacement Simulation:\\n\");\n    printf(\"Reference String: \");\n    for (int i = 0; i < NUM_PAGES; i++) {\n        printf(\"%d \", reference_string[i]);\n    }\n    printf(\"\\n\\n\");\n    \n    for (int i = 0; i < NUM_PAGES; i++) {\n        int page = reference_string[i];\n        int page_found = 0;\n        \n        // Check if page is already in a frame\n        for (int j = 0; j < NUM_FRAMES; j++) {\n            if (frames[j] == page) {\n                page_found = 1;\n                break;\n            }\n        }\n        \n        if (!page_found) {\n            // Page fault - need to replace a page\n            page_faults++;\n            printf(\"Page fault for page %d: \", page);\n            \n            // Replace the victim page\n            int victim = next_victim;\n            printf(\"Replacing frame %d (page %d) with page %d\\n\", \n                   victim, frames[victim], page);\n            \n            frames[victim] = page;\n            next_victim = (next_victim + 1) % NUM_FRAMES;\n        } else {\n            printf(\"Page %d already in memory\\n\", page);\n        }\n        \n        // Display current frames\n        printf(\"Frames: [\");\n        for (int j = 0; j < NUM_FRAMES; j++) {\n            if (frames[j] == -1) {\n                printf(\" - \");\n            } else {\n                printf(\"%2d\", frames[j]);\n            }\n            if (j < NUM_FRAMES - 1) printf(\" | \");\n        }\n        printf(\"]\\n\\n\");\n    }\n    \n    printf(\"Total Page Faults: %d\\n\", page_faults);\n}\n\nint main() {\n    simulate_paging();\n    fifo_page_replacement();\n    return 0;\n}"
          },
          {
            "id": "t23-segmentation",
            "title": "Segmentation Memory Management",
            "desc": "Dividing memory into logical segments of variable sizes",
            "note": "Segmentation is a memory management scheme that supports the user's view of memory as a collection of variable-sized segments, each representing a logical unit such as a code segment, data segment, stack segment, or heap segment. Unlike paging which divides memory into fixed-sized units, segmentation divides memory into logical units that correspond to the program's structure. Each segment has a name and length, and addresses specify both a segment name and an offset within that segment. The hardware support for segmentation includes a segment table for each process that contains the base address and limit (length) for each segment. When a process references memory, the segment number is used to find the base address in the segment table, and the offset is checked against the segment limit to ensure it's within bounds. The key advantages of segmentation are that it reflects the logical structure of programs, supports sharing and protection at the segment level, and allows segments to grow dynamically. However, segmentation suffers from external fragmentation as memory becomes filled with variable-sized segments. Modern systems often combine segmentation with paging to get the benefits of both approaches: segmentation for logical organization and protection, and paging for efficient physical memory management without external fragmentation.",
            "code": "// Example 1 - Segmentation address translation simulation\n#include <stdio.h>\n#include <stdint.h>\n\n// Segment table entry\ntypedef struct {\n    int base_address;\n    int limit;       // Segment length\n    int valid;       // 1 if segment is in memory\n    int protection;  // Read/write/execute permissions\n} segment_table_entry_t;\n\n// Convert logical address to segment number and offset\nvoid logical_to_physical_segmentation(uint32_t logical_addr, \n                                    int *seg_num, int *offset) {\n    // Assume segment number is in high 4 bits, offset in remaining 12 bits\n    *seg_num = (logical_addr >> 12) & 0xF;\n    *offset = logical_addr & 0xFFF;\n}\n\nvoid simulate_segmentation() {\n    // Initialize segment table\n    segment_table_entry_t seg_table[4] = {\n        {0x0000, 0x1000, 1, 5}, // Segment 0: base=0, limit=4KB, valid, RWX\n        {0x2000, 0x0800, 1, 3}, // Segment 1: base=8KB, limit=2KB, valid, RW\n        {0x0000, 0x0000, 0, 0}, // Segment 2: not present\n        {0x3000, 0x0C00, 1, 1}  // Segment 3: base=12KB, limit=3KB, valid, R\n    };\n    \n    printf(\"Segmentation Simulation:\\n\");\n    printf(\"Segment Table:\\n\");\n    printf(\"Seg#\\tBase\\tLimit\\tValid\\tProtection\\n\");\n    for (int i = 0; i < 4; i++) {\n        printf(\"%d\\t0x%04X\\t0x%04X\\t%d\\t%d\\n\", \n               i, seg_table[i].base_address, seg_table[i].limit,\n               seg_table[i].valid, seg_table[i].protection);\n    }\n    printf(\"\\n\");\n    \n    // Test address translation\n    uint32_t logical_addresses[] = {0x00001234, 0x10000800, 0x20000500, 0x30001000};\n    \n    for (int i = 0; i < 4; i++) {\n        uint32_t logical_addr = logical_addresses[i];\n        int seg_num, offset;\n        \n        logical_to_physical_segmentation(logical_addr, &seg_num, &offset);\n        \n        printf(\"Logical Address: 0x%08X\\n\", logical_addr);\n        printf(\"  Segment: %d, Offset: 0x%03X\\n\", seg_num, offset);\n        \n        if (seg_num < 4 && seg_table[seg_num].valid) {\n            if (offset < seg_table[seg_num].limit) {\n                uint32_t physical_addr = seg_table[seg_num].base_address + offset;\n                printf(\"  Physical Address: 0x%08X\\n\", physical_addr);\n                printf(\"  Access granted with protection level %d\\n\", \n                       seg_table[seg_num].protection);\n            } else {\n                printf(\"  Segmentation Fault! Offset 0x%03X exceeds segment limit 0x%03X\\n\",\n                       offset, seg_table[seg_num].limit);\n            }\n        } else {\n            printf(\"  Segmentation Fault! Segment %d not valid\\n\", seg_num);\n        }\n        printf(\"\\n\");\n    }\n}\n\n// Example 2 - Demonstrating segmentation advantages\nvoid demonstrate_segmentation_benefits() {\n    printf(\"Benefits of Segmentation:\\n\");\n    printf(\"1. Logical organization: Memory divided by function\\n\");\n    printf(\"   - Code segment: executable instructions\\n\");\n    printf(\"   - Data segment: global variables\\n\");\n    printf(\"   - Stack segment: local variables, return addresses\\n\");\n    printf(\"   - Heap segment: dynamically allocated memory\\n\\n\");\n    \n    printf(\"2. Protection: Different segments can have different permissions\\n\");\n    printf(\"   - Code segment: Execute only\\n\");\n    printf(\"   - Data segment: Read/Write\\n\");\n    printf(\"   - Stack segment: Read/Write\\n\");\n    printf(\"   - Constants: Read only\\n\\n\");\n    \n    printf(\"3. Sharing: Segments can be shared between processes\\n\");\n    printf(\"   - Shared libraries: Code segments\\n\");\n    printf(\"   - Shared memory: Data segments\\n\\n\");\n    \n    printf(\"4. Dynamic growth: Segments can grow as needed\\n\");\n    printf(\"   - Heap can expand upward\\n\");\n    printf(\"   - Stack can expand downward\\n\\n\");\n    \n    printf(\"Challenge: External fragmentation\\n\");\n    printf(\"   - Variable-sized segments leave holes in memory\\n\");\n    printf(\"   - Solution: Combine with paging (segmented paging)\\n\");\n}\n\nint main() {\n    simulate_segmentation();\n    demonstrate_segmentation_benefits();\n    return 0;\n}"
          },
          {
            "id": "t24-virtual-memory",
            "title": "Virtual Memory Systems",
            "desc": "Extending memory capacity using secondary storage",
            "note": "Virtual memory is a memory management technique that gives applications the illusion of having a very large contiguous memory space, even though the actual physical memory may be much smaller. This is achieved by using secondary storage (typically disk) to extend the available memory. Virtual memory allows processes to execute even if they are only partially resident in physical memory, with the operating system transparently moving pages between disk and RAM as needed. The key components of virtual memory systems are demand paging (pages are loaded into memory only when needed), page replacement algorithms (deciding which pages to remove when memory is full), and working set model (tracking which pages a process is actively using). Virtual memory provides several important benefits: it allows processes to be larger than physical memory, it simplifies memory management for programmers, it enables efficient process creation through copy-on-write techniques, and it provides memory protection between processes. However, virtual memory introduces overhead due to page faults and address translation, and poor implementation can lead to thrashing where the system spends more time paging than executing useful work. Modern operating systems use sophisticated virtual memory implementations with techniques like prepaging, page buffering, and working set tracking to optimize performance.",
            "code": "// Example 1 - Virtual memory simulation with demand paging\n#include <stdio.h>\n#include <stdbool.h>\n\n#define NUM_PAGES 8\n#define NUM_FRAMES 4\n#define MEMORY_SIZE 4096 // 4KB\n\n// Page table entry for virtual memory\ntypedef struct {\n    bool valid;        // Is page in physical memory?\n    bool referenced;   // Has page been accessed?\n    bool modified;     // Has page been modified?\n    int frame;         // Physical frame number\n    int disk_location; // Where page is stored on disk\n} vm_page_table_entry_t;\n\n// Simulate disk storage\nchar disk_storage[NUM_PAGES][256]; // 256-byte pages\n\n// Simulate physical memory\nchar physical_memory[NUM_FRAMES][256];\n\nvoid initialize_virtual_memory() {\n    printf(\"Initializing Virtual Memory System:\\n\");\n    printf(\"  Total virtual pages: %d\\n\", NUM_PAGES);\n    printf(\"  Physical frames: %d\\n\", NUM_FRAMES);\n    printf(\"  Page size: 256 bytes\\n\");\n    printf(\"  Total virtual memory: %d bytes\\n\", NUM_PAGES * 256);\n    printf(\"  Physical memory: %d bytes\\n\\n\", NUM_FRAMES * 256);\n    \n    // Initialize disk content\n    for (int i = 0; i < NUM_PAGES; i++) {\n        sprintf(disk_storage[i], \"This is content of virtual page %d stored on disk\", i);\n    }\n}\n\n// Simulate page fault handling\nint handle_page_fault(vm_page_table_entry_t *page_table, int page_num) {\n    printf(\"Page fault for page %d! Loading from disk...\\n\", page_num);\n    \n    // Find a free frame or choose a victim\n    int frame_num = -1;\n    for (int i = 0; i < NUM_FRAMES; i++) {\n        bool frame_in_use = false;\n        for (int j = 0; j < NUM_PAGES; j++) {\n            if (page_table[j].valid && page_table[j].frame == i) {\n                frame_in_use = true;\n                break;\n            }\n        }\n        if (!frame_in_use) {\n            frame_num = i;\n            break;\n        }\n    }\n    \n    // If no free frame, use FIFO replacement (simplified)\n    if (frame_num == -1) {\n        frame_num = 0; // Simple victim selection\n        printf(\"No free frames, replacing frame %d\\n\", frame_num);\n        \n        // Find and invalidate the page currently in this frame\n        for (int j = 0; j < NUM_PAGES; j++) {\n            if (page_table[j].valid && page_table[j].frame == frame_num) {\n                if (page_table[j].modified) {\n                    printf(\"Writing page %d back to disk (modified)\\n\", j);\n                }\n                page_table[j].valid = false;\n                break;\n            }\n        }\n    }\n    \n    // Load page from disk to physical memory\n    printf(\"Loading page %d into frame %d\\n\", page_num, frame_num);\n    for (int i = 0; i < 256; i++) {\n        physical_memory[frame_num][i] = disk_storage[page_num][i];\n    }\n    \n    // Update page table\n    page_table[page_num].valid = true;\n    page_table[page_num].frame = frame_num;\n    page_table[page_num].referenced = true;\n    page_table[page_num].modified = false;\n    \n    return frame_num;\n}\n\n// Simulate memory access in virtual memory system\nchar access_memory(vm_page_table_entry_t *page_table, int virtual_address) {\n    int page_num = virtual_address / 256;\n    int offset = virtual_address % 256;\n    \n    printf(\"Accessing virtual address %d (Page %d, Offset %d)\\n\", \n           virtual_address, page_num, offset);\n    \n    if (page_num >= NUM_PAGES) {\n        printf(\"Invalid address! Segmentation fault\\n\");\n        return '\\0';\n    }\n    \n    if (!page_table[page_num].valid) {\n        handle_page_fault(page_table, page_num);\n    }\n    \n    // Mark page as referenced\n    page_table[page_num].referenced = true;\n    \n    int frame_num = page_table[page_num].frame;\n    printf(\"Physical address: Frame %d, Offset %d\\n\", frame_num, offset);\n    \n    return physical_memory[frame_num][offset];\n}\n\nvoid virtual_memory_demo() {\n    vm_page_table_entry_t page_table[NUM_PAGES];\n    \n    // Initialize page table\n    for (int i = 0; i < NUM_PAGES; i++) {\n        page_table[i].valid = false;\n        page_table[i].referenced = false;\n        page_table[i].modified = false;\n        page_table[i].frame = -1;\n        page_table[i].disk_location = i;\n    }\n    \n    initialize_virtual_memory();\n    \n    // Simulate memory accesses that will cause page faults\n    printf(\"\\nSimulating Memory Accesses:\\n\");\n    \n    int addresses[] = {500, 100, 800, 200, 1200, 500, 1800, 100};\n    \n    for (int i = 0; i < 8; i++) {\n        printf(\"\\n--- Access %d ---\\n\", i + 1);\n        char data = access_memory(page_table, addresses[i]);\n        printf(\"Data: %c\\n\", data);\n    }\n    \n    printf(\"\\nFinal Page Table State:\\n\");\n    printf(\"Page\\tValid\\tFrame\\tReferenced\\tModified\\n\");\n    for (int i = 0; i < NUM_PAGES; i++) {\n        printf(\"%d\\t%d\\t%d\\t%d\\t\\t%d\\n\", \n               i, page_table[i].valid, page_table[i].frame, \n               page_table[i].referenced, page_table[i].modified);\n    }\n}\n\n// Example 2 - Working set model simulation\nvoid working_set_model() {\n    printf(\"\\nWorking Set Model for Virtual Memory:\\n\");\n    printf(\"The working set is the set of pages a process is actively using\\n\");\n    printf(\"OS tracks working set to make better page replacement decisions\\n\\n\");\n    \n    int reference_string[] = {1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5};\n    int window_size = 4;\n    \n    printf(\"Reference string: \");\n    for (int i = 0; i < 12; i++) {\n        printf(\"%d \", reference_string[i]);\n    }\n    printf(\"\\n\");\n    printf(\"Working set window size: %d\\n\\n\", window_size);\n    \n    for (int i = 0; i < 12; i++) {\n        printf(\"Time %d: Reference page %d\\n\", i, reference_string[i]);\n        \n        // Calculate working set for current window\n        printf(\"Working set (last %d references): {\", window_size);\n        \n        int start = (i - window_size + 1) > 0 ? (i - window_size + 1) : 0;\n        int working_set[5] = {0}; // Track which pages are in working set\n        \n        for (int j = start; j <= i; j++) {\n            if (j >= 0) {\n                working_set[reference_string[j]] = 1;\n            }\n        }\n        \n        // Print working set\n        int first = 1;\n        for (int p = 1; p <= 5; p++) {\n            if (working_set[p]) {\n                if (!first) printf(\", \");\n                printf(\"%d\", p);\n                first = 0;\n            }\n        }\n        printf(\"}\\n\\n\");\n    }\n}\n\nint main() {\n    virtual_memory_demo();\n    working_set_model();\n    return 0;\n}"
          },
          {
            "id": "t25-allocation-methods",
            "title": "Memory Allocation Methods",
            "desc": "Techniques for allocating memory to processes",
            "note": "Memory allocation methods determine how operating systems assign memory to processes and manage free memory space. The main memory allocation techniques include contiguous allocation (each process occupies a single contiguous block of memory), paging (memory divided into fixed-sized pages, processes divided into same-sized frames), segmentation (memory divided into variable-sized segments matching program structure), and combined systems (paged segmentation or segmented paging). Contiguous allocation can use fixed partitioning (memory divided into fixed-sized partitions) or variable partitioning (memory divided into variable-sized partitions as needed). Variable partitioning uses placement algorithms like first-fit (allocate the first hole that's big enough), best-fit (allocate the smallest hole that's big enough), worst-fit (allocate the largest available hole), and next-fit (similar to first-fit but starts searching from last allocation position). Non-contiguous allocation methods like paging and segmentation avoid external fragmentation but require hardware support for address translation. Modern systems typically use paging with virtual memory, often combined with segmentation for protection and sharing. Memory allocation also involves managing free memory through data structures like bitmaps (each bit represents whether a memory unit is free or allocated) or linked lists (maintain list of free memory blocks). The choice of allocation method affects memory utilization, fragmentation, system performance, and implementation complexity.",
            "code": "// Example 1 - Contiguous memory allocation simulation\n#include <stdio.h>\n#include <stdbool.h>\n\n#define MEMORY_SIZE 1000\n\n// Memory block structure\ntypedef struct {\n    int start;\n    int size;\n    bool allocated;\n    int process_id; // -1 if free\n} memory_block_t;\n\n// Initialize memory with free blocks\nvoid initialize_memory(memory_block_t memory[], int *num_blocks) {\n    *num_blocks = 1;\n    memory[0].start = 0;\n    memory[0].size = MEMORY_SIZE;\n    memory[0].allocated = false;\n    memory[0].process_id = -1;\n}\n\n// Display memory layout\nvoid display_memory(memory_block_t memory[], int num_blocks) {\n    printf(\"Memory Layout:\\n\");\n    printf(\"Start\\tSize\\tStatus\\tProcess\\n\");\n    \n    for (int i = 0; i < num_blocks; i++) {\n        printf(\"%d\\t%d\\t%s\\t\", \n               memory[i].start, memory[i].size,\n               memory[i].allocated ? \"Alloc\" : \"Free\");\n        \n        if (memory[i].allocated) {\n            printf(\"%d\", memory[i].process_id);\n        } else {\n            printf(\"-\");\n        }\n        printf(\"\\n\");\n    }\n    printf(\"\\n\");\n}\n\n// First-fit allocation algorithm\nint first_fit(memory_block_t memory[], int *num_blocks, int size, int process_id) {\n    for (int i = 0; i < *num_blocks; i++) {\n        if (!memory[i].allocated && memory[i].size >= size) {\n            // Found a suitable free block\n            if (memory[i].size > size) {\n                // Split the block\n                // Make space for new block\n                for (int j = *num_blocks; j > i + 1; j--) {\n                    memory[j] = memory[j - 1];\n                }\n                \n                // Create new free block for remaining space\n                memory[i + 1].start = memory[i].start + size;\n                memory[i + 1].size = memory[i].size - size;\n                memory[i + 1].allocated = false;\n                memory[i + 1].process_id = -1;\n                \n                (*num_blocks)++;\n            }\n            \n            // Allocate the block\n            memory[i].size = size;\n            memory[i].allocated = true;\n            memory[i].process_id = process_id;\n            \n            return memory[i].start; // Return starting address\n        }\n    }\n    \n    return -1; // Allocation failed\n}\n\n// Deallocate memory\nvoid deallocate(memory_block_t memory[], int *num_blocks, int process_id) {\n    for (int i = 0; i < *num_blocks; i++) {\n        if (memory[i].allocated && memory[i].process_id == process_id) {\n            memory[i].allocated = false;\n            memory[i].process_id = -1;\n            \n            // Merge with adjacent free blocks\n            if (i > 0 && !memory[i - 1].allocated) {\n                // Merge with previous block\n                memory[i - 1].size += memory[i].size;\n                // Remove current block\n                for (int j = i; j < *num_blocks - 1; j++) {\n                    memory[j] = memory[j + 1];\n                }\n                (*num_blocks)--;\n                i--; // Check this block again for further merging\n            }\n            \n            if (i < *num_blocks - 1 && !memory[i + 1].allocated) {\n                // Merge with next block\n                memory[i].size += memory[i + 1].size;\n                // Remove next block\n                for (int j = i + 1; j < *num_blocks - 1; j++) {\n                    memory[j] = memory[j + 1];\n                }\n                (*num_blocks)--;\n            }\n            \n            break;\n        }\n    }\n}\n\nvoid contiguous_allocation_demo() {\n    memory_block_t memory[20]; // Allow up to 20 blocks\n    int num_blocks;\n    \n    initialize_memory(memory, &num_blocks);\n    \n    printf(\"Contiguous Memory Allocation Simulation (First-Fit):\\n\\n\");\n    \n    display_memory(memory, num_blocks);\n    \n    // Allocate memory for processes\n    int processes[][2] = {{100, 1}, {200, 2}, {150, 3}, {300, 4}};\n    \n    for (int i = 0; i < 4; i++) {\n        int size = processes[i][0];\n        int pid = processes[i][1];\n        \n        int address = first_fit(memory, &num_blocks, size, pid);\n        if (address != -1) {\n            printf(\"Allocated %d units to process %d at address %d\\n\", size, pid, address);\n        } else {\n            printf(\"Failed to allocate %d units to process %d\\n\", size, pid);\n        }\n        display_memory(memory, num_blocks);\n    }\n    \n    // Deallocate some processes\n    printf(\"Deallocating process 2\\n\");\n    deallocate(memory, &num_blocks, 2);\n    display_memory(memory, num_blocks);\n    \n    printf(\"Deallocating process 1\\n\");\n    deallocate(memory, &num_blocks, 1);\n    display_memory(memory, num_blocks);\n    \n    // Allocate again to show fragmentation\n    printf(\"Allocating 250 units to process 5\\n\");\n    int address = first_fit(memory, &num_blocks, 250, 5);\n    if (address != -1) {\n        printf(\"Allocated 250 units to process 5 at address %d\\n\", address);\n    } else {\n        printf(\"Failed to allocate 250 units to process 5 (external fragmentation)\\n\");\n    }\n    display_memory(memory, num_blocks);\n}\n\n// Example 2 - Comparison of placement algorithms\nvoid compare_allocation_algorithms() {\n    printf(\"Memory Placement Algorithms Comparison:\\n\\n\");\n    \n    printf(\"1. First-Fit:\\n\");\n    printf(\"   - Allocate the first hole that is large enough\\n\");\n    printf(\"   - Fast but may leave large free blocks fragmented\\n\\n\");\n    \n    printf(\"2. Best-Fit:\\n\");\n    printf(\"   - Allocate the smallest hole that is large enough\\n\");\n    printf(\"   - Minimizes wasted space but leaves small fragments\\n\");\n    printf(\"   - Slower due to searching entire free list\\n\\n\");\n    \n    printf(\"3. Worst-Fit:\\n\");\n    printf(\"   - Allocate the largest available hole\\n\");\n    printf(\"   - Leaves larger fragments for future allocations\\n\");\n    printf(\"   - Also slow and may not work well in practice\\n\\n\");\n    \n    printf(\"4. Next-Fit:\\n\");\n    printf(\"   - Similar to first-fit but starts from last allocation position\\n\");\n    printf(\"   - More even distribution of allocations\\n\");\n    printf(\"   - Performance similar to first-fit\\n\\n\");\n    \n    printf(\"Modern systems typically use paging instead of contiguous allocation\\n\");\n    printf(\"to avoid external fragmentation problems\\n\");\n}\n\nint main() {\n    contiguous_allocation_demo();\n    compare_allocation_algorithms();\n    return 0;\n}"
          }
        ]
      },
      {
        "id": "c7-storage",
        "title": "Storage & File Systems",
        "desc": "Managing secondary storage and file organization",
        "notes": "Storage and file systems are critical components of operating systems that manage secondary storage devices (hard disks, SSDs, etc.) and provide organized access to stored data. File systems abstract the physical storage details and provide users and applications with a logical view of files and directories. Key file system concepts include file organization (how data is structured within files), directory structures (how files are organized and named), allocation methods (how disk space is assigned to files), free space management (tracking available storage), and protection mechanisms (controlling access to files). Modern file systems also provide features like journaling (for crash recovery), compression, encryption, and snapshot capabilities. Different file systems are optimized for different use cases: FAT is simple and widely compatible, NTFS offers advanced features and security, ext4 is robust for Linux systems, and modern file systems like ZFS and Btrfs provide advanced data integrity and management features. Understanding file system design is essential for system administrators, storage engineers, and developers working with persistent data storage.",
        "code": "",
        "duration": "Week 1",
        "topics": [
          {
            "id": "t26-file-system-structure",
            "title": "File System Structure",
            "desc": "Organization and components of file systems",
            "note": "File system structure refers to the organization and components that make up a file system on secondary storage. A typical file system consists of several key components: boot control block (contains information needed to boot the OS from that volume), volume control block (contains volume details like number of blocks, block size, free block count), directory structure (organizes files and contains metadata about files), and file control blocks (contain file-specific information like ownership, permissions, size, and location data). File systems are typically organized in layers: the I/O control layer handles device drivers and interrupt handling, the basic file system layer issues generic commands to device drivers, the file organization module understands files and logical blocks, and the logical file system manages metadata information. Modern file systems often use journaling to maintain consistency by logging changes before committing them to the main file system. File systems also implement various on-disk structures like superblocks (containing file system metadata), inode tables (storing file metadata), and data blocks (storing actual file content). Understanding file system structure is essential for system administrators for troubleshooting, performance tuning, and data recovery, and for developers working with low-level file operations or implementing custom storage solutions.",
            "code": "// Example 1 - Simulating basic file system structures\n#include <stdio.h>\n#include <time.h>\n\n// Simulated superblock structure\ntypedef struct {\n    char magic[4];        // File system identifier\n    int block_size;       // Size of each block in bytes\n    int total_blocks;     // Total number of blocks\n    int free_blocks;      // Number of free blocks\n    int inode_count;      // Total number of inodes\n    int free_inodes;      // Number of free inodes\n    time_t created;       // File system creation time\n} superblock_t;\n\n// Simulated inode structure\ntypedef struct {\n    int mode;             // File type and permissions\n    int owner;            // User ID of owner\n    int group;            // Group ID of owner\n    int size;             // File size in bytes\n    time_t accessed;      // Last access time\n    time_t modified;      // Last modification time\n    time_t created;       // Creation time\n    int blocks[12];       // Direct block pointers\n    int indirect;         // Single indirect block pointer\n    int double_indirect;  // Double indirect block pointer\n} inode_t;\n\n// Simulated directory entry structure\ntypedef struct {\n    char name[256];       // File name\n    int inode_number;     // Corresponding inode number\n    char type;            // File type: 'f' for file, 'd' for directory\n} dir_entry_t;\n\nvoid demonstrate_file_system_structures() {\n    printf(\"File System Structures Demonstration:\\n\\n\");\n    \n    // Create a simulated superblock\n    superblock_t sb = {\n        .magic = \"EXT4\",\n        .block_size = 4096,\n        .total_blocks = 1000000,\n        .free_blocks = 750000,\n        .inode_count = 100000,\n        .free_inodes = 80000,\n        .created = time(NULL)\n    };\n    \n    printf(\"Superblock Information:\\n\");\n    printf(\"  Magic: %s\\n\", sb.magic);\n    printf(\"  Block Size: %d bytes\\n\", sb.block_size);\n    printf(\"  Total Blocks: %d\\n\", sb.total_blocks);\n    printf(\"  Free Blocks: %d\\n\", sb.free_blocks);\n    printf(\"  Inode Count: %d\\n\", sb.inode_count);\n    printf(\"  Free Inodes: %d\\n\", sb.free_inodes);\n    printf(\"  Created: %s\", ctime(&sb.created));\n    \n    // Create a simulated inode\n    inode_t inode = {\n        .mode = 0x81A4, // Regular file with rw-r--r-- permissions\n        .owner = 1000,\n        .group = 1000,\n        .size = 15000,\n        .accessed = time(NULL),\n        .modified = time(NULL),\n        .created = time(NULL) - 86400, // Created 1 day ago\n        .blocks = {1024, 1025, 1026, -1, -1, -1, -1, -1, -1, -1, -1, -1},\n        .indirect = -1,\n        .double_indirect = -1\n    };\n    \n    printf(\"\\nInode Information:\\n\");\n    printf(\"  Mode: 0x%X\\n\", inode.mode);\n    printf(\"  Owner: %d\\n\", inode.owner);\n    printf(\"  Group: %d\\n\", inode.group);\n    printf(\"  Size: %d bytes\\n\", inode.size);\n    printf(\"  Accessed: %s\", ctime(&inode.accessed));\n    printf(\"  Modified: %s\", ctime(&inode.modified));\n    printf(\"  Created: %s\", ctime(&inode.created));\n    printf(\"  Direct Blocks: \");\n    for (int i = 0; i < 12; i++) {\n        if (inode.blocks[i] != -1) {\n            printf(\"%d \", inode.blocks[i]);\n        }\n    }\n    printf(\"\\n\");\n    \n    // Create simulated directory entries\n    dir_entry_t entries[] = {\n        {\"file1.txt\", 123, 'f'},\n        {\"documents\", 456, 'd'},\n        {\"image.png\", 789, 'f'}\n    };\n    \n    printf(\"\\nDirectory Contents:\\n\");\n    printf(\"Name\\t\\tType\\tInode\\n\");\n    for (int i = 0; i < 3; i++) {\n        printf(\"%-12s\\t%c\\t%d\\n\", entries[i].name, entries[i].type, entries[i].inode_number);\n    }\n}\n\n// Example 2 - File system layer simulation\nvoid simulate_file_system_layers() {\n    printf(\"\\nFile System Layers Simulation:\\n\\n\");\n    \n    printf(\"1. Application Layer:\\n\");\n    printf(\"   - User requests: open('file.txt', O_RDONLY)\\n\");\n    printf(\"   - File descriptor returned: 3\\n\\n\");\n    \n    printf(\"2. Logical File System Layer:\\n\");\n    printf(\"   - Parse path: /home/user/file.txt\\n\");\n    printf(\"   - Check permissions: read allowed\\n\");\n    printf(\"   - Find inode for file.txt\\n\");\n    printf(\"   - Create file table entry\\n\\n\");\n    \n    printf(\"3. File Organization Module:\\n\");\n    printf(\"   - Convert logical block numbers to physical blocks\\n\");\n    printf(\"   - Handle indirect blocks if needed\\n\");\n    printf(\"   - Calculate offset within block\\n\\n\");\n    \n    printf(\"4. Basic File System Layer:\\n\");\n    printf(\"   - Issue commands: read block 1024, read block 1025\\n\");\n    printf(\"   - Buffer management\\n\\n\");\n    \n    printf(\"5. I/O Control Layer:\\n\");\n    printf(\"   - Device driver commands\\n\");\n    printf(\"   - Hardware interaction: read sector X, read sector Y\\n\");\n    printf(\"   - Interrupt handling\\n\\n\");\n    \n    printf(\"6. Hardware Layer:\\n\");\n    printf(\"   - Disk controller operations\\n\");\n    printf(\"   - Physical media access\\n\");\n    printf(\"   - Data transfer to memory\\n\\n\");\n}\n\nint main() {\n    demonstrate_file_system_structures();\n    simulate_file_system_layers();\n    return 0;\n}"
          },
          {
            "id": "t27-fat",
            "title": "FAT File System",
            "desc": "File Allocation Table system structure and operation",
            "note": "The File Allocation Table (FAT) file system is one of the oldest and most widely compatible file systems, originally developed for MS-DOS and still used today in removable media like USB drives and memory cards. FAT uses a File Allocation Table that serves as a linked list of clusters (allocation units) on the disk. The FAT contains entries for each cluster, indicating whether the cluster is free, allocated, bad, or the end of a file chain. FAT comes in several variants: FAT12 (uses 12-bit cluster addresses, suitable for small volumes), FAT16 (16-bit addresses, for medium volumes), and FAT32 (32-bit addresses, for larger volumes). The FAT file system structure includes a boot sector, FAT region (primary and backup copies), root directory, and data region. Files are stored as linked lists of clusters, with the directory entry containing the starting cluster number. FAT is simple and robust but has limitations like lack of built-in security features, no journaling, inefficient storage for large numbers of small files, and file size limitations. Despite its limitations, FAT remains popular due to its excellent cross-platform compatibility, making it ideal for removable storage that needs to work across Windows, macOS, Linux, and other systems.",
            "code": "// Example 1 - FAT file system simulation\n#include <stdio.h>\n#include <string.h>\n\n#define TOTAL_CLUSTERS 100\n#define CLUSTER_SIZE 4096\n#define FAT_ENTRIES TOTAL_CLUSTERS\n\n// FAT entry values\n#define FAT_FREE 0\n#define FAT_EOF (-1)\n#define FAT_BAD (-2)\n\n// Directory entry structure for FAT\ntypedef struct {\n    char name[8];       // File name (8.3 format)\n    char ext[3];        // File extension\n    unsigned char attr; // File attributes\n    int first_cluster;  // First cluster number\n    int size;           // File size in bytes\n} fat_dir_entry_t;\n\n// Simulate FAT table\nint fat_table[FAT_ENTRIES];\n\n// Simulate directory entries\nfat_dir_entry_t directory[50];\nint dir_count = 0;\n\n// Simulate disk clusters\nchar disk_data[TOTAL_CLUSTERS][CLUSTER_SIZE];\n\nvoid initialize_fat() {\n    printf(\"Initializing FAT File System Simulation:\\n\");\n    printf(\"Total clusters: %d\\n\", TOTAL_CLUSTERS);\n    printf(\"Cluster size: %d bytes\\n\", CLUSTER_SIZE);\n    printf(\"Total capacity: %d bytes\\n\\n\", TOTAL_CLUSTERS * CLUSTER_SIZE);\n    \n    // Initialize FAT table\n    for (int i = 0; i < FAT_ENTRIES; i++) {\n        fat_table[i] = FAT_FREE;\n    }\n    \n    // Mark some clusters as bad for realism\n    fat_table[5] = FAT_BAD;\n    fat_table[42] = FAT_BAD;\n    \n    printf(\"FAT table initialized with %d free clusters\\n\", TOTAL_CLUSTERS - 2);\n}\n\n// Find free clusters\nint find_free_clusters(int count) {\n    int found = 0;\n    int first_cluster = -1;\n    int prev_cluster = -1;\n    \n    for (int i = 0; i < FAT_ENTRIES && found < count; i++) {\n        if (fat_table[i] == FAT_FREE) {\n            if (first_cluster == -1) {\n                first_cluster = i;\n            }\n            \n            if (prev_cluster != -1) {\n                fat_table[prev_cluster] = i; // Link to next cluster\n            }\n            \n            prev_cluster = i;\n            found++;\n        }\n    }\n    \n    if (found == count && prev_cluster != -1) {\n        fat_table[prev_cluster] = FAT_EOF; // Mark end of chain\n    }\n    \n    return (found == count) ? first_cluster : -1;\n}\n\n// Create a file in FAT system\nint fat_create_file(const char *name, int size) {\n    // Calculate needed clusters\n    int clusters_needed = (size + CLUSTER_SIZE - 1) / CLUSTER_SIZE;\n    \n    if (clusters_needed <= 0) {\n        printf(\"Invalid file size\\n\");\n        return -1;\n    }\n    \n    // Find free clusters\n    int first_cluster = find_free_clusters(clusters_needed);\n    if (first_cluster == -1) {\n        printf(\"Not enough free space for file %s\\n\", name);\n        return -1;\n    }\n    \n    // Create directory entry\n    if (dir_count < 50) {\n        // Parse name and extension (simplified)\n        char base_name[9] = {0};\n        char extension[4] = {0};\n        \n        const char *dot = strchr(name, '.');\n        if (dot) {\n            int name_len = dot - name;\n            if (name_len > 8) name_len = 8;\n            strncpy(base_name, name, name_len);\n            base_name[name_len] = '\\0';\n            \n            int ext_len = strlen(dot + 1);\n            if (ext_len > 3) ext_len = 3;\n            strncpy(extension, dot + 1, ext_len);\n            extension[ext_len] = '\\0';\n        } else {\n            int name_len = strlen(name);\n            if (name_len > 8) name_len = 8;\n            strncpy(base_name, name, name_len);\n            base_name[name_len] = '\\0';\n        }\n        \n        strcpy(directory[dir_count].name, base_name);\n        strcpy(directory[dir_count].ext, extension);\n        directory[dir_count].attr = 0x20; // Archive attribute\n        directory[dir_count].first_cluster = first_cluster;\n        directory[dir_count].size = size;\n        \n        printf(\"Created file %s with %d clusters starting at cluster %d\\n\", \n               name, clusters_needed, first_cluster);\n        \n        return dir_count++;\n    }\n    \n    printf(\"Directory full\\n\");\n    return -1;\n}\n\n// Display FAT table and directory\nvoid display_fat_info() {\n    printf(\"\\nFAT Table (first 20 entries):\\n\");\n    printf(\"Cluster\\tStatus\\n\");\n    for (int i = 0; i < 20; i++) {\n        printf(\"%d\\t\", i);\n        if (fat_table[i] == FAT_FREE) {\n            printf(\"Free\\n\");\n        } else if (fat_table[i] == FAT_EOF) {\n            printf(\"EOF\\n\");\n        } else if (fat_table[i] == FAT_BAD) {\n            printf(\"Bad\\n\");\n        } else {\n            printf(\"Points to %d\\n\", fat_table[i]);\n        }\n    }\n    \n    printf(\"\\nDirectory Contents:\\n\");\n    printf(\"Name\\tExt\\tSize\\tFirst Cluster\\n\");\n    for (int i = 0; i < dir_count; i++) {\n        printf(\"%s\\t%s\\t%d\\t%d\\n\", \n               directory[i].name, directory[i].ext,\n               directory[i].size, directory[i].first_cluster);\n    }\n}\n\n// Example 2 - FAT file system limitations\ndemonstrate_fat_limitations() {\n    printf(\"\\nFAT File System Limitations:\\n\\n\");\n    \n    printf(\"1. File Size Limits:\\n\");\n    printf(\"   - FAT12: Max file size ~32MB\\n\");\n    printf(\"   - FAT16: Max file size ~2GB\\n\");\n    printf(\"   - FAT32: Max file size ~4GB\\n\\n\");\n    \n    printf(\"2. Volume Size Limits:\\n\");\n    printf(\"   - FAT12: Max volume size ~32MB\\n\");\n    printf(\"   - FAT16: Max volume size ~2GB\\n\");\n    printf(\"   - FAT32: Max volume size ~2TB\\n\\n\");\n    \n    printf(\"3. Performance Issues:\\n\");\n    printf(\"   - File fragmentation slows performance\\n\");\n    printf(\"   - FAT must be read frequently\\n\");\n    printf(\"   - No built-in journaling\\n\\n\");\n    \n    printf(\"4. Security Limitations:\\n\");\n    printf(\"   - No built-in file permissions\\n\");\n    printf(\"   - No encryption support\\n\");\n    printf(\"   - No access control lists\\n\\n\");\n    \n    printf(\"5. Reliability Concerns:\\n\");\n    printf(\"   - Corrupted FAT can cause data loss\\n\");\n    printf(\"   - No transaction support\\n\");\n    printf(\"   - Limited error recovery\\n\\n\");\n    \n    printf(\"Despite these limitations, FAT remains popular for:\\n\");\n    printf(\" - USB drives and memory cards\\n\");\n    printf(\" - Cross-platform compatibility\\n\");\n    printf(\" - Simple implementation\\n\");\n    printf(\" - Wide operating system support\\n\");\n}\n\nint main() {\n    initialize_fat();\n    \n    // Create some files\n    fat_create_file(\"DOCUMENT.TXT\", 5000);\n    fat_create_file(\"IMAGE.JPG\", 15000);\n    fat_create_file(\"LARGE_FILE.DAT\", 50000);\n    \n    display_fat_info();\n    demonstrate_fat_limitations();\n    \n    return 0;\n}"
          },
          {
            "id": "t28-ntfs",
            "title": "NTFS File System",
            "desc": "New Technology File System features and structure",
            "note": "NTFS (New Technology File System) is a proprietary file system developed by Microsoft for Windows NT and its successors. It offers significant improvements over FAT, including support for metadata, advanced data structures, improved performance, reliability, and disk space utilization. Key features of NTFS include journaling for consistency, access control lists for security, file compression, encryption (EFS), disk quotas, sparse files, and volume shadow copy service. NTFS uses a master file table (MFT) as its central database, containing records for all files and directories on the volume. Each MFT record typically is 1KB in size and contains file attributes, which can be resident (stored within the MFT record) or non-resident (stored in external clusters). NTFS supports very large files and volumes (theoretical limits of 16 exabytes for files and 256 terabytes for volumes), Unicode filenames, and hard links. The file system uses a B-tree structure for directory organization, enabling efficient file searches. NTFS also includes self-healing capabilities through the USN journal and chkdsk utility. While primarily used in Windows environments, NTFS can be read (and sometimes written) by other operating systems through third-party drivers, though with potential limitations in supporting all NTFS features.",
            "code": "// Example 1 - NTFS MFT simulation\n#include <stdio.h>\n#include <time.h>\n\n// NTFS attribute types\ntypedef enum {\n    ATTRIBUTE_STANDARD_INFORMATION = 0x10,\n    ATTRIBUTE_ATTRIBUTE_LIST = 0x20,\n    ATTRIBUTE_FILE_NAME = 0x30,\n    ATTRIBUTE_OBJECT_ID = 0x40,\n    ATTRIBUTE_SECURITY_DESCRIPTOR = 0x50,\n    ATTRIBUTE_VOLUME_NAME = 0x60,\n    ATTRIBUTE_VOLUME_INFORMATION = 0x70,\n    ATTRIBUTE_DATA = 0x80,\n    ATTRIBUTE_INDEX_ROOT = 0x90,\n    ATTRIBUTE_INDEX_ALLOCATION = 0xA0,\n    ATTRIBUTE_BITMAP = 0xB0\n} ntfs_attribute_type;\n\n// MFT record header\ntypedef struct {\n    char magic[4];        // \"FILE\"\n    int update_sequence_offset;\n    int update_sequence_size;\n    long long logfile_sequence_number;\n    int sequence_number;\n    int hard_link_count;\n    int first_attribute_offset;\n    int flags;            // 0x01 = in use, 0x02 = directory\n    int used_size;\n    int allocated_size;\n    long long base_file_record;\n    int next_attribute_id;\n} mft_record_header_t;\n\n// Attribute header\ntypedef struct {\n    ntfs_attribute_type type;\n    int length;\n    int non_resident;\n    int name_length;\n    int name_offset;\n    int flags;\n    int attribute_id;\n} attribute_header_t;\n\n// Resident attribute\ntypedef struct {\n    attribute_header_t header;\n    int attribute_length;\n    int attribute_offset;\n} resident_attribute_t;\n\n// Non-resident attribute\ntypedef struct {\n    attribute_header_t header;\n    long long starting_vcn;\n    long long last_vcn;\n    int data_run_offset;\n    int compression_unit;\n    long long allocated_size;\n    long long actual_size;\n    long long initialized_size;\n} non_resident_attribute_t;\n\n// File name attribute\ntypedef struct {\n    long long parent_directory;\n    long long creation_time;\n    long long modification_time;\n    long long mft_change_time;\n    long long last_access_time;\n    long long allocated_size;\n    long long actual_size;\n    int flags;\n    int reparse_value;\n    int name_length;\n    int namespace;\n    wchar_t name[255];\n} file_name_attribute_t;\n\nvoid demonstrate_ntfs_features() {\n    printf(\"NTFS File System Features Demonstration:\\n\\n\");\n    \n    // Simulate MFT record\n    mft_record_header_t mft_header = {\n        .magic = \"FILE\",\n        .logfile_sequence_number = 12345,\n        .sequence_number = 1,\n        .hard_link_count = 1,\n        .flags = 0x01, // In use\n        .used_size = 1024,\n        .allocated_size = 1024,\n        .next_attribute_id = 4\n    };\n    \n    printf(\"MFT Record Header:\\n\");\n    printf(\"  Magic: %.4s\\n\", mft_header.magic);\n    printf(\"  LSN: %lld\\n\", mft_header.logfile_sequence_number);\n    printf(\"  Sequence: %d\\n\", mft_header.sequence_number);\n    printf(\"  Hard Links: %d\\n\", mft_header.hard_link_count);\n    printf(\"  Flags: 0x%X\\n\", mft_header.flags);\n    printf(\"  Used Size: %d\\n\", mft_header.used_size);\n    printf(\"  Allocated Size: %d\\n\", mft_header.allocated_size);\n    \n    // Simulate attributes\n    resident_attribute_t std_info_attr = {\n        .header = {ATTRIBUTE_STANDARD_INFORMATION, 72, 0, 0, 0, 0, 1},\n        .attribute_length = 72,\n        .attribute_offset = 56\n    };\n    \n    resident_attribute_t filename_attr = {\n        .header = {ATTRIBUTE_FILE_NAME, 86, 0, 0, 0, 0, 2},\n        .attribute_length = 86,\n        .attribute_offset = 128\n    };\n    \n    non_resident_attribute_t data_attr = {\n        .header = {ATTRIBUTE_DATA, 64, 1, 0, 0, 0, 3},\n        .starting_vcn = 0,\n        .last_vcn = 7,\n        .data_run_offset = 48,\n        .allocated_size = 32768,\n        .actual_size = 25000,\n        .initialized_size = 25000\n    };\n    \n    printf(\"\\nAttributes in MFT Record:\\n\");\n    printf(\"1. Standard Information (0x%X)\\n\", std_info_attr.header.type);\n    printf(\"2. File Name (0x%X)\\n\", filename_attr.header.type);\n    printf(\"3. Data (0x%X) - Non-resident\\n\", data_attr.header.type);\n    printf(\"   Data runs: %d clusters\\n\", (int)(data_attr.last_vcn - data_attr.starting_vcn + 1));\n    printf(\"   Allocated: %lld bytes, Actual: %lld bytes\\n\", \n           data_attr.allocated_size, data_attr.actual_size);\n}\n\n// Example 2 - NTFS advanced features simulation\nvoid demonstrate_advanced_ntfs_features() {\n    printf(\"\\nAdvanced NTFS Features:\\n\\n\");\n    \n    printf(\"1. Journaling (NTFS Log):\\n\");\n    printf(\"   - Records metadata changes before committing\\n\");\n    printf(\"   - Provides consistency after crashes\\n\");\n    printf(\"   - Example: Log sequence number (LSN) tracking\\n\\n\");\n    \n    printf(\"2. Security Descriptors:\\n\");\n    printf(\"   - Access Control Lists (ACLs)\\n\");\n    printf(\"   - File ownership information\\n\");\n    printf(\"   - Permission inheritance\\n\\n\");\n    \n    printf(\"3. Compression:\\n\");\n    printf(\"   - Transparent file compression\\n\");\n    printf(\"   - Cluster-level compression\\n\");\n    printf(\"   - Sparse file support\\n\\n\");\n    \n    printf(\"4. Encryption (EFS):\\n\");\n    printf(\"   - File-level encryption\\n\");\n    printf(\"   - Public key cryptography\\n\");\n    printf(\"   - Transparent to applications\\n\\n\");\n    \n    printf(\"5. Disk Quotas:\\n\");\n    printf(\"   - User-based storage limits\\n\");\n    printf(\"   - Warning thresholds\\n\");\n    printf(\"   - Enforcement policies\\n\\n\");\n    \n    printf(\"6. Volume Shadow Copy:\\n\");\n    printf(\"   - Point-in-time file copies\\n\");\n    printf(\"   - System restore functionality\\n\");\n    printf(\"   - Backup integration\\n\\n\");\n    \n    printf(\"7. Self-healing NTFS:\\n\");\n    printf(\"   - Automatic error correction\\n\");\n    printf(\"   - Online disk checking\\n\");\n    printf(\"   - Reduced need for chkdsk\\n\\n\");\n}\n\nint main() {\n    demonstrate_ntfs_features();\n    demonstrate_advanced_ntfs_features();\n    return 0;\n}"
          },
          {
            "id": "t29-ext4",
            "title": "ext4 File System",
            "desc": "Fourth extended file system for Linux",
            "note": "ext4 (fourth extended file system) is a journaling file system developed for Linux as the successor to ext3. It provides significant improvements in performance, scalability, and reliability. Key features of ext4 include support for very large file systems (up to 1 exabyte) and files (up to 16 terabytes), extents (contiguous block allocation that reduces fragmentation and improves performance), delayed allocation (improves performance by better grouping writes), journal checksumming (improves reliability), and persistent preallocation (guarantees space for files). ext4 maintains backward compatibility with ext2 and ext3, allowing ext4 partitions to be mounted as ext3. The file system uses a balanced tree structure for directory indexing, enabling faster file lookups in large directories. ext4 also supports nanosecond timestamps, larger inodes (256 bytes or more), and unlimited subdirectories. Journaling options include writeback (metadata only), ordered (metadata after data, default), and journal (full data and metadata journaling). ext4 is the default file system for most Linux distributions and is widely used due to its stability, performance, and feature set, though newer file systems like Btrfs and XFS are gaining popularity for specific use cases.",
            "code": "// Example 1 - ext4 data structures simulation\n#include <stdio.h>\n#include <time.h>\n\n// ext4 superblock structure (simplified)\ntypedef struct {\n    unsigned int inode_count;         // Total inodes\n    unsigned int block_count;         // Total blocks\n    unsigned int reserved_blocks;     // Reserved blocks\n    unsigned int free_blocks;         // Free blocks\n    unsigned int free_inodes;         // Free inodes\n    unsigned int first_data_block;    // First data block\n    unsigned int log_block_size;      // Block size = 1024 << this\n    unsigned int blocks_per_group;    // Blocks per group\n    unsigned int inodes_per_group;    // Inodes per group\n    unsigned int magic;               // Magic signature (0xEF53)\n    unsigned int state;               // File system state\n    unsigned int errors;              // Behavior when detecting errors\n    unsigned int minor_rev_level;     // Minor revision level\n    time_t last_check;                // Time of last check\n    time_t max_mount_interval;        // Max time between checks\n    unsigned int creator_os;          // OS that created FS\n    unsigned int rev_level;           // Revision level\n    unsigned int first_inode;         // First non-reserved inode\n    unsigned short inode_size;        // Size of inode structure\n} ext4_superblock_t;\n\n// ext4 inode structure (simplified)\ntypedef struct {\n    unsigned short mode;        // File mode\n    unsigned short uid;         // Owner UID\n    unsigned int size;          // Size in bytes (low 32 bits)\n    unsigned int atime;         // Access time\n    unsigned int ctime;         // Creation time\n    unsigned int mtime;         // Modification time\n    unsigned int dtime;         // Deletion time\n    unsigned short gid;         // Group ID\n    unsigned short links_count; // Hard links count\n    unsigned int blocks;        // Blocks count\n    unsigned int flags;         // File flags\n    unsigned int block[15];     // Pointers to data blocks\n    unsigned int generation;    // File version\n    unsigned int file_acl;      // File ACL\n    unsigned int size_high;     // Size in bytes (high 32 bits)\n    unsigned int obso_faddr;    // Obsolete fragment address\n} ext4_inode_t;\n\n// ext4 extent structure\ntypedef struct {\n    unsigned int ee_block;    // First logical block\n    unsigned short ee_len;    // Number of blocks\n    unsigned short ee_start_hi; // High 16 bits of physical block\n    unsigned int ee_start_lo;   // Low 32 bits of physical block\n} ext4_extent;\n\n// ext4 extent header\ntypedef struct {\n    unsigned short eh_magic;    // Magic number (0xF30A)\n    unsigned short eh_entries;  // Number of valid entries\n    unsigned short eh_max;      // Capacity of the tree\n    unsigned short eh_depth;    // Depth of the tree\n    unsigned int eh_generation; // Generation of the tree\n} ext4_extent_header;\n\nvoid demonstrate_ext4_features() {\n    printf(\"ext4 File System Features Demonstration:\\n\\n\");\n    \n    // Create a simulated superblock\n    ext4_superblock_t sb = {\n        .inode_count = 1000000,\n        .block_count = 4000000,\n        .free_blocks = 3500000,\n        .free_inodes = 800000,\n        .first_data_block = 1,\n        .log_block_size = 2,        // 1024 << 2 = 4096 bytes\n        .blocks_per_group = 32768,\n        .inodes_per_group = 8192,\n        .magic = 0xEF53,\n        .state = 1,                 // Cleanly unmounted\n        .errors = 1,                // Continue on error\n        .last_check = time(NULL),\n        .creator_os = 0,            // Linux\n        .rev_level = 1,             // Dynamic inodes\n        .first_inode = 11,\n        .inode_size = 256\n    };\n    \n    printf(\"Superblock Information:\\n\");\n    printf(\"  Magic: 0x%X\\n\", sb.magic);\n    printf(\"  Inodes: %u, Free: %u\\n\", sb.inode_count, sb.free_inodes);\n    printf(\"  Blocks: %u, Free: %u\\n\", sb.block_count, sb.free_blocks);\n    printf(\"  Block Size: %u bytes\\n\", 1024 << sb.log_block_size);\n    printf(\"  Inode Size: %u bytes\\n\", sb.inode_size);\n    printf(\"  Blocks per Group: %u\\n\", sb.blocks_per_group);\n    printf(\"  State: %s\\n\", sb.state ? \"Clean\" : \"Errors detected\");\n    \n    // Create a simulated inode with extents\n    ext4_inode_t inode = {\n        .mode = 0x81A4,        // Regular file, rw-r--r--\n        .uid = 1000,\n        .size = 5000000,\n        .atime = time(NULL),\n        .mtime = time(NULL) - 3600,\n        .ctime = time(NULL) - 7200,\n        .links_count = 1,\n        .blocks = 1221,        // 5000000 / 4096  1221 blocks\n        .flags = 0x80000,      // Extents flag\n        .size_high = 0         // For files > 4GB\n    };\n    \n    // Simulate extent tree\n    ext4_extent_header eh = {\n        .eh_magic = 0xF30A,\n        .eh_entries = 3,\n        .eh_max = 4,\n        .eh_depth = 0          // Leaf level (extents stored directly)\n    };\n    \n    ext4_extent extents[3] = {\n        {0, 1000, 0, 5000},    // Logical blocks 0-999 -> Physical 5000-5999\n        {1000, 200, 0, 7000},  // Logical blocks 1000-1199 -> Physical 7000-7199\n        {1200, 21, 0, 8000}    // Logical blocks 1200-1220 -> Physical 8000-8020\n    };\n    \n    printf(\"\\nInode Information:\\n\");\n    printf(\"  Size: %u bytes\\n\", inode.size);\n    printf(\"  Blocks: %u\\n\", inode.blocks);\n    printf(\"  UID: %u\\n\", inode.uid);\n    printf(\"  Links: %u\\n\", inode.links_count);\n    printf(\"  Using extents: %s\\n\", (inode.flags & 0x80000) ? \"Yes\" : \"No\");\n    \n    printf(\"\\nExtent Tree:\\n\");\n    printf(\"  Magic: 0x%X\\n\", eh.eh_magic);\n    printf(\"  Entries: %u, Depth: %u\\n\", eh.eh_entries, eh.eh_depth);\n    \n    for (int i = 0; i < 3; i++) {\n        printf(\"  Extent %d: Logical %u-%u -> Physical %u-%u\\n\", \n               i, extents[i].ee_block, \n               extents[i].ee_block + extents[i].ee_len - 1,\n               extents[i].ee_start_lo,\n               extents[i].ee_start_lo + extents[i].ee_len - 1);\n    }\n}\n\n// Example 2 - ext4 advanced features\nvoid demonstrate_ext4_advanced_features() {\n    printf(\"\\next4 Advanced Features:\\n\\n\");\n    \n    printf(\"1. Extents:\\n\");\n    printf(\"   - Replace traditional block pointers\\n\");\n    printf(\"   - Store contiguous block ranges\\n\");\n    printf(\"   - Reduce metadata overhead\\n\");\n    printf(\"   - Improve performance for large files\\n\\n\");\n    \n    printf(\"2. Delayed Allocation:\\n\");\n    printf(\"   - Delay block allocation until write time\\n\");\n    printf(\"   - Better block grouping decisions\\n\");\n    printf(\"   - Reduced fragmentation\\n\");\n    printf(\"   - Improved write performance\\n\\n\");\n    \n    printf(\"3. Journaling Options:\\n\");\n    printf(\"   - writeback: Metadata only, fastest but riskiest\\n\");\n    printf(\"   - ordered: Metadata after data (default)\\n\");\n    printf(\"   - journal: Full data and metadata, safest but slowest\\n\\n\");\n    \n    printf(\"4. Persistent Preallocation:\\n\");\n    printf(\"   - Guarantee space for files\\n\");\n    printf(\"   - Useful for databases and media streaming\\n\");\n    printf(\"   - Prevents out-of-space errors during writes\\n\\n\");\n    \n    printf(\"5. Online Defragmentation:\\n\");\n    printf(\"   - e4defrag tool for file-level defragmentation\\n\");\n    printf(\"   - Improves performance for fragmented files\\n\");\n    printf(\"   - Works on mounted filesystems\\n\\n\");\n    \n    printf(\"6. Barrier-based Journaling:\\n\");\n    printf(\"   - Ensure data consistency with storage write barriers\\n\");\n    printf(\"   - Prevents data loss during power failures\\n\");\n    printf(\"   - Better reliability than traditional journaling\\n\\n\");\n}\n\nint main() {\n    demonstrate_ext4_features();\n    demonstrate_ext4_advanced_features();\n    return 0;\n}"
          },
          {
            "id": "t30-allocation-methods",
            "title": "File Allocation Methods",
            "desc": "Techniques for allocating disk space to files",
            "note": "File allocation methods determine how operating systems assign disk space to files. The main allocation techniques include contiguous allocation (each file occupies a contiguous set of blocks), linked allocation (each file is a linked list of blocks), indexed allocation (a separate index block contains pointers to all file blocks), and combined approaches used in modern file systems. Contiguous allocation offers excellent read performance but suffers from external fragmentation and file growth challenges. Linked allocation eliminates external fragmentation but has poor random access performance and reliability issues. Indexed allocation provides efficient random access but requires overhead for storing index blocks. Modern file systems often use variations like linked indexed allocation (multi-level indexes) or extent-based allocation (storing ranges of contiguous blocks). The choice of allocation method affects disk utilization, access performance, reliability, and support for file operations like appending and truncating. File systems also need efficient methods for managing free space, typically using bitmaps (each bit represents a block's allocation status) or linked lists of free blocks. Understanding allocation methods is crucial for file system designers and storage engineers to optimize performance and reliability for specific workloads.",
            "code": "// Example 1 - File allocation methods simulation\n#include <stdio.h>\n#include <stdbool.h>\n\n#define DISK_BLOCKS 20\n#define BLOCK_SIZE 1024\n\n// Simulated disk blocks\nchar disk[DISK_BLOCKS][BLOCK_SIZE];\nbool allocated[DISK_BLOCKS] = {false};\n\n// Contiguous allocation\nint contiguous_allocate(int blocks_needed) {\n    int start_block = -1;\n    int consecutive_free = 0;\n    \n    for (int i = 0; i < DISK_BLOCKS; i++) {\n        if (!allocated[i]) {\n            consecutive_free++;\n            if (consecutive_free == blocks_needed) {\n                start_block = i - blocks_needed + 1;\n                break;\n            }\n        } else {\n            consecutive_free = 0;\n        }\n    }\n    \n    if (start_block != -1) {\n        for (int i = start_block; i < start_block + blocks_needed; i++) {\n            allocated[i] = true;\n        }\n    }\n    \n    return start_block;\n}\n\n// Linked allocation\nint linked_allocate(int blocks_needed) {\n    int first_block = -1;\n    int prev_block = -1;\n    int allocated_count = 0;\n    \n    for (int i = 0; i < DISK_BLOCKS && allocated_count < blocks_needed; i++) {\n        if (!allocated[i]) {\n            allocated[i] = true;\n            \n            if (first_block == -1) {\n                first_block = i;\n            }\n            \n            if (prev_block != -1) {\n                // Store pointer to next block in previous block\n                sprintf(disk[prev_block], \"Next: %d\", i);\n            }\n            \n            prev_block = i;\n            allocated_count++;\n        }\n    }\n    \n    if (prev_block != -1) {\n        sprintf(disk[prev_block], \"Next: -1\"); // End of chain\n    }\n    \n    return (allocated_count == blocks_needed) ? first_block : -1;\n}\n\n// Indexed allocation\ntypedef struct {\n    int index_block;\n    int pointers[DISK_BLOCKS];\n    int count;\n} indexed_allocation_t;\n\nindexed_allocation_t indexed_allocate(int blocks_needed) {\n    indexed_allocation_t result = {-1, {0}, 0};\n    \n    // First allocate index block\n    for (int i = 0; i < DISK_BLOCKS; i++) {\n        if (!allocated[i]) {\n            result.index_block = i;\n            allocated[i] = true;\n            break;\n        }\n    }\n    \n    if (result.index_block == -1) {\n        return result; // No space for index block\n    }\n    \n    // Allocate data blocks\n    for (int i = 0; i < DISK_BLOCKS && result.count < blocks_needed; i++) {\n        if (!allocated[i]) {\n            allocated[i] = true;\n            result.pointers[result.count] = i;\n            result.count++;\n        }\n    }\n    \n    // Store pointers in index block\n    char index_content[BLOCK_SIZE] = {0};\n    for (int i = 0; i < result.count; i++) {\n        char pointer_str[10];\n        sprintf(pointer_str, \"%d \", result.pointers[i]);\n        strcat(index_content, pointer_str);\n    }\n    strcpy(disk[result.index_block], index_content);\n    \n    return result;\n}\n\nvoid display_disk_allocation() {\n    printf(\"Disk Allocation Map:\\n\");\n    for (int i = 0; i < DISK_BLOCKS; i++) {\n        printf(\"%c\", allocated[i] ? 'X' : '.');\n        if ((i + 1) % 10 == 0) printf(\" \");\n    }\n    printf(\"\\n\");\n}\n\nvoid demonstrate_allocation_methods() {\n    printf(\"File Allocation Methods Demonstration:\\n\\n\");\n    \n    printf(\"Initial Disk State:\\n\");\n    display_disk_allocation();\n    \n    // Test contiguous allocation\n    printf(\"\\n1. Contiguous Allocation (4 blocks):\\n\");\n    int contig_start = contiguous_allocate(4);\n    if (contig_start != -1) {\n        printf(\"Allocated blocks %d to %d\\n\", contig_start, contig_start + 3);\n    } else {\n        printf(\"Contiguous allocation failed\\n\");\n    }\n    display_disk_allocation();\n    \n    // Test linked allocation\n    printf(\"\\n2. Linked Allocation (3 blocks):\\n\");\n    int linked_start = linked_allocate(3);\n    if (linked_start != -1) {\n        printf(\"Allocated blocks starting at %d\\n\", linked_start);\n        printf(\"Block pointers: \");\n        int current = linked_start;\n        while (current != -1) {\n            printf(\"%d -> \", current);\n            int next;\n            sscanf(disk[current], \"Next: %d\", &next);\n            current = next;\n        }\n        printf(\"END\\n\");\n    } else {\n        printf(\"Linked allocation failed\\n\");\n    }\n    display_disk_allocation();\n    \n    // Test indexed allocation\n    printf(\"\\n3. Indexed Allocation (2 blocks):\\n\");\n    indexed_allocation_t indexed = indexed_allocate(2);\n    if (indexed.index_block != -1 && indexed.count == 2) {\n        printf(\"Index block: %d\\n\", indexed.index_block);\n        printf(\"Data blocks: %d, %d\\n\", indexed.pointers[0], indexed.pointers[1]);\n        printf(\"Index content: %s\\n\", disk[indexed.index_block]);\n    } else {\n        printf(\"Indexed allocation failed\\n\");\n    }\n    display_disk_allocation();\n}\n\n// Example 2 - Comparison of allocation methods\nvoid compare_allocation_methods() {\n    printf(\"\\nFile Allocation Methods Comparison:\\n\\n\");\n    \n    printf(\"1. Contiguous Allocation:\\n\");\n    printf(\"   Advantages:\\n\");\n    printf(\"     - Excellent read performance (sequential access)\\n\");\n    printf(\"     - Simple implementation\\n\");\n    printf(\"   Disadvantages:\\n\");\n    printf(\"     - External fragmentation\\n\");\n    printf(\"     - Difficult file growth\\n\");\n    printf(\"     - Requires compaction\\n\\n\");\n    \n    printf(\"2. Linked Allocation:\\n\");\n    printf(\"   Advantages:\\n\");\n    printf(\"     - No external fragmentation\\n\");\n    printf(\"     - Easy file growth\\n\");\n    printf(\"   Disadvantages:\\n\");\n    printf(\"     - Poor random access\\n\");\n    printf(\"     - Reliability issues (broken links)\\n\");\n    printf(\"     - Overhead for pointers\\n\\n\");\n    \n    printf(\"3. Indexed Allocation:\\n\");\n    printf(\"   Advantages:\\n\");\n    printf(\"     - Efficient random access\\n\");\n    printf(\"     - No external fragmentation\\n\");\n    printf(\"     - Easy file growth\\n\");\n    printf(\"   Disadvantages:\\n\");\n    printf(\"     - Overhead for index blocks\\n\");\n    printf(\"     - Potential large index for big files\\n\");\n    printf(\"     - Complexity\\n\\n\");\n    \n    printf(\"Modern file systems use combined approaches:\\n\");\n    printf(\"   - ext4: Extents (contiguous ranges with indexing)\\n\");\n    printf(\"   - NTFS: MFT with variable-length records\\n\");\n    printf(\"   - FAT: Linked allocation with table\\n\");\n}\n\nint main() {\n    demonstrate_allocation_methods();\n    compare_allocation_methods();\n    return 0;\n}"
          }
        ]
      },
      {
        "id": "c8-io",
        "title": "I/O Systems & Device Management",
        "desc": "Managing input/output devices and operations",
        "notes": "I/O systems and device management are critical components of operating systems that handle communication between the computer and its peripheral devices. The I/O subsystem is responsible for managing various devices including storage devices, network interfaces, display adapters, input devices, and other peripherals. Key aspects of I/O systems include device drivers (software that controls specific hardware devices), I/O scheduling (managing the order of I/O requests for optimal performance), buffering (temporary storage to handle speed mismatches between devices and CPU), caching (storing frequently accessed data for faster retrieval), spooling (simultaneous peripheral operations online, particularly for printers), and error handling. Operating systems use various I/O techniques including programmed I/O (CPU directly controls I/O operations), interrupt-driven I/O (devices signal completion via interrupts), and direct memory access (DMA controllers handle data transfers without CPU involvement). Modern I/O systems also provide device-independent interfaces, allowing applications to access devices through standardized system calls regardless of the specific hardware implementation. Understanding I/O systems is essential for system programmers, device driver developers, and performance engineers working on systems where I/O performance is critical.",
        "code": "",
        "duration": "Week 1",
        "topics": [
 
          {
            "id": "t31-io-hardware",
            "title": "I/O Hardware and Interfaces",
            "desc": "Physical devices and communication interfaces",
            "note": "I/O hardware encompasses the physical devices and communication interfaces that allow computers to interact with the external world. Computer systems support a wide variety of I/O devices including storage devices (hard drives, SSDs, optical drives), display devices (monitors, graphics cards), input devices (keyboards, mice, touchscreens), network interfaces (Ethernet cards, Wi-Fi adapters), and specialized devices (sensors, actuators, scientific instruments). These devices connect to the computer system through various interfaces and buses such as PCI Express (high-speed expansion bus), USB (Universal Serial Bus for peripherals), SATA (Serial ATA for storage devices), Thunderbolt (high-speed interface), and legacy interfaces like Parallel ATA and Serial ports. Each device is controlled by a device controller that contains registers for command, status, and data transfer. The operating system communicates with these controllers through device drivers that translate high-level commands into device-specific operations. Understanding I/O hardware is essential for system designers, device driver developers, and hardware engineers to create efficient and compatible systems that can effectively utilize the capabilities of modern peripheral devices.",
            "code": "// Example 1 - Simulating device controller interaction\n#include <stdio.h>\n#include <stdint.h>\n\n// Simulated device controller registers\ntypedef struct {\n    uint32_t control_register;    // Control commands\n    uint32_t status_register;     // Device status\n    uint32_t data_register;       // Data transfer\n    uint32_t error_register;      // Error codes\n} device_controller_t;\n\n// Device status flags\n#define STATUS_READY 0x01\n#define STATUS_BUSY 0x02\n#define STATUS_ERROR 0x04\n#define STATUS_DATA_READY 0x08\n\n// Control commands\n#define CMD_READ 0x01\n#define CMD_WRITE 0x02\n#define CMD_RESET 0x04\n\nvoid simulate_device_operation() {\n    device_controller_t controller = {0};\n    \n    printf(\"Simulating Device Controller Interaction:\\n\\n\");\n    \n    // Simulate device initialization\n    printf(\"1. Device Initialization:\\n\");\n    controller.status_register = STATUS_READY;\n    printf(\"   Status Register: 0x%08X (Device Ready)\\n\", controller.status_register);\n    \n    // Simulate write operation\n    printf(\"\\n2. Write Operation:\\n\");\n    controller.control_register = CMD_WRITE;\n    controller.status_register |= STATUS_BUSY;\n    printf(\"   Control Register: 0x%08X (Write Command)\\n\", controller.control_register);\n    printf(\"   Status Register: 0x%08X (Device Busy)\\n\", controller.status_register);\n    \n    // Transfer data\n    controller.data_register = 0x12345678;\n    printf(\"   Data Register: 0x%08X (Data to write)\\n\", controller.data_register);\n    \n    // Complete operation\n    controller.status_register &= ~STATUS_BUSY;\n    controller.status_register |= STATUS_READY;\n    printf(\"   Status Register: 0x%08X (Operation Complete)\\n\", controller.status_register);\n    \n    // Simulate read operation\n    printf(\"\\n3. Read Operation:\\n\");\n    controller.control_register = CMD_READ;\n    controller.status_register |= STATUS_BUSY;\n    printf(\"   Control Register: 0x%08X (Read Command)\\n\", controller.control_register);\n    printf(\"   Status Register: 0x%08X (Device Busy)\\n\", controller.status_register);\n    \n    // Simulate data ready\n    controller.status_register |= STATUS_DATA_READY;\n    controller.data_register = 0xABCDEF12;\n    printf(\"   Status Register: 0x%08X (Data Ready)\\n\", controller.status_register);\n    printf(\"   Data Register: 0x%08X (Read data)\\n\", controller.data_register);\n    \n    // Complete operation\n    controller.status_register &= ~(STATUS_BUSY | STATUS_DATA_READY);\n    controller.status_register |= STATUS_READY;\n    printf(\"   Status Register: 0x%08X (Operation Complete)\\n\", controller.status_register);\n}\n\n// Example 2 - I/O port access simulation\n#include <stdio.h>\n\n// Simulated I/O ports\nunsigned char io_ports[256];\n\n// Simulate IN instruction (read from port)\nunsigned char inb(unsigned short port) {\n    printf(\"IN from port 0x%04X: value 0x%02X\\n\", port, io_ports[port]);\n    return io_ports[port];\n}\n\n// Simulate OUT instruction (write to port)\nvoid outb(unsigned short port, unsigned char value) {\n    printf(\"OUT to port 0x%04X: value 0x%02X\\n\", port, value);\n    io_ports[port] = value;\n}\n\nvoid simulate_port_io() {\n    printf(\"\\nSimulating I/O Port Access:\\n\\n\");\n    \n    // Initialize some port values\n    io_ports[0x60] = 0x41; // Keyboard data port\n    io_ports[0x64] = 0x55; // Keyboard status/command port\n    \n    // Simulate keyboard status check\n    printf(\"1. Checking keyboard status:\\n\");\n    unsigned char status = inb(0x64);\n    if (status & 0x01) {\n        printf(\"   Keyboard data available\\n\");\n        unsigned char data = inb(0x60);\n        printf(\"   Scancode: 0x%02X\\n\", data);\n    } else {\n        printf(\"   No keyboard data available\\n\");\n    }\n    \n    // Simulate sending command to device\n    printf(\"\\n2. Sending device command:\\n\");\n    outb(0x64, 0xAE); // Enable keyboard\n    printf(\"   Command 0xAE sent: Enable keyboard\\n\");\n    \n    // Check command acknowledgment\n    status = inb(0x64);\n    if (status & 0x02) {\n        printf(\"   Device busy, waiting...\\n\");\n    } else {\n        printf(\"   Command accepted\\n\");\n    }\n}\n\nint main() {\n    simulate_device_operation();\n    simulate_port_io();\n    return 0;\n}"
          },
          {
            "id": "t32-device-drivers",
            "title": "Device Drivers",
            "desc": "Software interfaces between OS and hardware devices",
            "note": "Device drivers are specialized software components that act as translators between the operating system and hardware devices. They provide a standardized interface for the OS to communicate with diverse hardware while handling device-specific details. Device drivers run in kernel mode with privileged access to hardware resources. The main functions of device drivers include device initialization and configuration, translating OS requests into device-specific commands, handling interrupts from devices, managing data transfer between device and memory, error handling and recovery, and power management. Drivers are typically structured with initialization routines, interrupt service routines, and device-specific functions. Modern operating systems use layered driver models with class drivers (handling common functionality for device types) and minidrivers (providing device-specific implementations). Driver development requires careful attention to synchronization, resource management, and security to prevent system instability. Device drivers can be loaded dynamically as needed and are typically implemented as kernel modules in Unix-like systems or as .sys files in Windows. Understanding device driver architecture is crucial for system programmers, embedded developers, and anyone working with custom hardware or performance-critical applications.",
            "code": "// Example 1 - Simulating device driver structure\n#include <stdio.h>\n#include <stdbool.h>\n\n// Device driver operations structure\ntypedef struct {\n    int (*init)(void);\n    int (*open)(void);\n    int (*read)(char *buffer, int size);\n    int (*write)(const char *buffer, int size);\n    int (*ioctl)(unsigned int cmd, unsigned long arg);\n    int (*close)(void);\n    int (*release)(void);\n} device_operations_t;\n\n// Simulated device driver\nint device_init(void) {\n    printf(\"Device initialized\\n\");\n    return 0;\n}\n\nint device_open(void) {\n    printf(\"Device opened\\n\");\n    return 0;\n}\n\nint device_read(char *buffer, int size) {\n    printf(\"Reading %d bytes from device\\n\", size);\n    // Simulate reading data\n    for (int i = 0; i < size && i < 10; i++) {\n        buffer[i] = 'A' + i;\n    }\n    return size;\n}\n\nint device_write(const char *buffer, int size) {\n    printf(\"Writing %d bytes to device: \", size);\n    for (int i = 0; i < size && i < 10; i++) {\n        printf(\"%c\", buffer[i]);\n    }\n    printf(\"\\n\");\n    return size;\n}\n\nint device_ioctl(unsigned int cmd, unsigned long arg) {\n    printf(\"IOCTL command: 0x%08X, argument: 0x%08lX\\n\", cmd, arg);\n    return 0;\n}\n\nint device_close(void) {\n    printf(\"Device closed\\n\");\n    return 0;\n}\n\nint device_release(void) {\n    printf(\"Device released\\n\");\n    return 0;\n}\n\n// Driver operations structure\ndevice_operations_t dev_ops = {\n    .init = device_init,\n    .open = device_open,\n    .read = device_read,\n    .write = device_write,\n    .ioctl = device_ioctl,\n    .close = device_close,\n    .release = device_release\n};\n\nvoid simulate_driver_operations() {\n    printf(\"Simulating Device Driver Operations:\\n\\n\");\n    \n    // Initialize device\n    dev_ops.init();\n    \n    // Open device\n    dev_ops.open();\n    \n    // Write to device\n    char write_data[] = \"Hello Driver!\";\n    dev_ops.write(write_data, sizeof(write_data));\n    \n    // Read from device\n    char read_buffer[20];\n    dev_ops.read(read_buffer, sizeof(read_buffer));\n    printf(\"Read data: %s\\n\", read_buffer);\n    \n    // IOCTL operation\n    dev_ops.ioctl(0x1234, 0x5678);\n    \n    // Close device\n    dev_ops.close();\n    \n    // Release device\n    dev_ops.release();\n}\n\n// Example 2 - Interrupt handling simulation\n#include <stdio.h>\n#include <signal.h>\n#include <unistd.h>\n\nvolatile sig_atomic_t interrupt_occurred = 0;\n\n// Simulated interrupt handler\nvoid interrupt_handler(int sig) {\n    interrupt_occurred = 1;\n    printf(\"INTERRUPT: Device needs attention!\\n\");\n}\n\nvoid simulate_interrupt_driven_io() {\n    printf(\"\\nSimulating Interrupt-Driven I/O:\\n\\n\");\n    \n    // Set up signal handler to simulate interrupt\n    signal(SIGUSR1, interrupt_handler);\n    \n    printf(\"Starting main processing loop...\\n\");\n    printf(\"Send SIGUSR1 to simulate device interrupt (kill -USR1 %d)\\n\", getpid());\n    \n    // Main loop\n    for (int i = 0; i < 10; i++) {\n        printf(\"Working... %d\\n\", i);\n        sleep(1);\n        \n        if (interrupt_occurred) {\n            printf(\"Processing interrupt...\\n\");\n            printf(\"Reading data from device...\\n\");\n            printf(\"Interrupt processing complete.\\n\");\n            interrupt_occurred = 0;\n        }\n    }\n    \n    printf(\"Main processing completed.\\n\");\n}\n\nint main() {\n    simulate_driver_operations();\n    simulate_interrupt_driven_io();\n    return 0;\n}"
          },
          {
            "id": "t33-spooling",
            "title": "Spooling and Buffering",
            "desc": "Managing I/O operations through temporary storage",
            "note": "Spooling (Simultaneous Peripheral Operations Online) and buffering are techniques used by operating systems to manage the speed differences between devices and improve overall system efficiency. Spooling involves storing data in temporary storage (typically on disk) before processing or output, allowing devices to operate at their own pace without keeping the CPU idle. The most common example is print spooling, where print jobs are queued and sent to the printer sequentially. Buffering uses memory areas to temporarily hold data being transferred between devices, smoothing out speed mismatches and reducing the number of I/O operations. Buffers can be single (one buffer for each direction), double (two buffers allowing simultaneous filling and emptying), or circular (multiple buffers in a ring structure). Spooling provides several benefits: device independence (applications don't need to wait for devices), improved CPU utilization (CPU can continue working while I/O proceeds), and better device utilization (devices can be kept busy with queued work). Modern operating systems use sophisticated buffering and caching techniques throughout the I/O subsystem to optimize performance, including read-ahead buffering, write-behind caching, and buffer cache management. Understanding spooling and buffering is essential for system administrators and developers working with I/O-intensive applications.",
            "code": "// Example 1 - Spooling simulation for print jobs\n#include <stdio.h>\n#include <string.h>\n#include <time.h>\n\n#define MAX_JOBS 10\n#define SPOOL_DIR \"/var/spool/print/\"\n\n// Print job structure\ntypedef struct {\n    int job_id;\n    char filename[256];\n    time_t submit_time;\n    int status; // 0=queued, 1=printing, 2=completed, 3=error\n} print_job_t;\n\n// Print spool queue\nprint_job_t spool_queue[MAX_JOBS];\nint job_count = 0;\n\n// Submit a print job\nint submit_print_job(const char *filename) {\n    if (job_count >= MAX_JOBS) {\n        printf(\"Print queue is full!\\n\");\n        return -1;\n    }\n    \n    spool_queue[job_count].job_id = job_count + 1;\n    strncpy(spool_queue[job_count].filename, filename, 255);\n    spool_queue[job_count].submit_time = time(NULL);\n    spool_queue[job_count].status = 0; // Queued\n    \n    printf(\"Submitted print job %d: %s\\n\", \n           spool_queue[job_count].job_id, filename);\n    \n    return job_count++;\n}\n\n// Process print jobs\nvoid process_print_queue() {\n    printf(\"\\nProcessing print queue:\\n\");\n    \n    for (int i = 0; i < job_count; i++) {\n        if (spool_queue[i].status == 0) { // Queued\n            printf(\"Printing job %d: %s\\n\", \n                   spool_queue[i].job_id, spool_queue[i].filename);\n            spool_queue[i].status = 1; // Printing\n            \n            // Simulate printing time\n            sleep(2);\n            \n            spool_queue[i].status = 2; // Completed\n            printf(\"Completed job %d\\n\", spool_queue[i].job_id);\n        }\n    }\n}\n\n// Display spool queue status\nvoid display_spool_queue() {\n    printf(\"\\nPrint Spool Queue Status:\\n\");\n    printf(\"ID\\tFile\\t\\tStatus\\t\\tSubmit Time\\n\");\n    \n    for (int i = 0; i < job_count; i++) {\n        printf(\"%d\\t%-12s\\t\", spool_queue[i].job_id, spool_queue[i].filename);\n        \n        switch (spool_queue[i].status) {\n            case 0: printf(\"Queued\\t\\t\"); break;\n            case 1: printf(\"Printing\\t\"); break;\n            case 2: printf(\"Completed\\t\"); break;\n            case 3: printf(\"Error\\t\\t\"); break;\n        }\n        \n        printf(\"%s\", ctime(&spool_queue[i].submit_time));\n    }\n}\n\nvoid simulate_print_spooling() {\n    printf(\"Print Spooling Simulation:\\n\\n\");\n    \n    // Submit some print jobs\n    submit_print_job(\"document.pdf\");\n    submit_print_job(\"report.doc\");\n    submit_print_job(\"image.png\");\n    submit_print_job(\"spreadsheet.xls\");\n    \n    display_spool_queue();\n    \n    // Process the queue\n    process_print_queue();\n    \n    display_spool_queue();\n}\n\n// Example 2 - Buffering simulation\n#include <stdio.h>\n\n#define BUFFER_SIZE 5\n\n// Circular buffer for I/O\ntypedef struct {\n    char data[BUFFER_SIZE];\n    int head;\n    int tail;\n    int count;\n} circular_buffer_t;\n\nvoid buffer_init(circular_buffer_t *buf) {\n    buf->head = 0;\n    buf->tail = 0;\n    buf->count = 0;\n}\n\nint buffer_is_full(circular_buffer_t *buf) {\n    return buf->count == BUFFER_SIZE;\n}\n\nint buffer_is_empty(circular_buffer_t *buf) {\n    return buf->count == 0;\n}\n\nint buffer_put(circular_buffer_t *buf, char item) {\n    if (buffer_is_full(buf)) {\n        printf(\"Buffer full! Cannot add '%c'\\n\", item);\n        return 0;\n    }\n    \n    buf->data[buf->tail] = item;\n    buf->tail = (buf->tail + 1) % BUFFER_SIZE;\n    buf->count++;\n    \n    return 1;\n}\n\nint buffer_get(circular_buffer_t *buf, char *item) {\n    if (buffer_is_empty(buf)) {\n        printf(\"Buffer empty!\\n\");\n        return 0;\n    }\n    \n    *item = buf->data[buf->head];\n    buf->head = (buf->head + 1) % BUFFER_SIZE;\n    buf->count--;\n    \n    return 1;\n}\n\nvoid display_buffer(circular_buffer_t *buf) {\n    printf(\"Buffer: [\");\n    for (int i = 0; i < BUFFER_SIZE; i++) {\n        if (i < buf->count) {\n            int index = (buf->head + i) % BUFFER_SIZE;\n            printf(\"'%c'\", buf->data[index]);\n        } else {\n            printf(\" - \");\n        }\n        if (i < BUFFER_SIZE - 1) printf(\", \");\n    }\n    printf(\"]\\n\");\n}\n\nvoid simulate_buffering() {\n    printf(\"\\nI/O Buffering Simulation:\\n\\n\");\n    \n    circular_buffer_t buffer;\n    buffer_init(&buffer);\n    \n    // Simulate producer (faster) and consumer (slower)\n    char producer_data[] = \"ABCDEFGHIJKLMNOP\";\n    char consumer_data;\n    \n    printf(\"Producer generating data: %s\\n\", producer_data);\n    printf(\"Consumer reading data slowly...\\n\\n\");\n    \n    int produced = 0, consumed = 0;\n    \n    while (produced < strlen(producer_data) || consumed < strlen(producer_data)) {\n        // Producer tries to add data\n        if (produced < strlen(producer_data)) {\n            if (buffer_put(&buffer, producer_data[produced])) {\n                printf(\"Produced: '%c'\", producer_data[produced]);\n                produced++;\n                display_buffer(&buffer);\n            }\n        }\n        \n        // Consumer tries to read data (slower)\n        if ((consumed < produced) && (rand() % 3 == 0)) {\n            if (buffer_get(&buffer, &consumer_data)) {\n                printf(\"Consumed: '%c'\", consumer_data);\n                consumed++;\n                display_buffer(&buffer);\n            }\n        }\n        \n        printf(\"\\n\");\n    }\n    \n    printf(\"All data processed. Produced: %d, Consumed: %d\\n\", produced, consumed);\n}\n\nint main() {\n    simulate_print_spooling();\n    simulate_buffering();\n    return 0;\n}"
          },
          {
            "id": "t34-interrupts",
            "title": "Interrupt Handling Mechanisms",
            "desc": "Managing hardware and software interrupts",
            "note": "Interrupts are signals sent to the processor by hardware devices or software to indicate that an event needs immediate attention. Interrupt handling is a critical function of operating systems that allows efficient response to external events without constant polling. Hardware interrupts are generated by devices like keyboards, mice, network cards, and storage controllers, while software interrupts (also called traps or exceptions) are generated by the CPU itself in response to software events like system calls, divide-by-zero errors, or page faults. The interrupt handling process involves several steps: the CPU finishes its current instruction, saves the current execution context, identifies the interrupt source, jumps to the appropriate interrupt service routine (ISR), executes the ISR, restores the saved context, and resumes normal execution. Modern systems use interrupt controllers (like APIC in x86 systems) to manage multiple interrupt sources and prioritize them. Interrupts can be categorized as maskable (can be disabled by the CPU) or non-maskable (critical interrupts that cannot be disabled). Operating systems also use interrupt priority levels to ensure that critical interrupts are handled promptly. Understanding interrupt handling is essential for system programmers, driver developers, and real-time system designers to create responsive and efficient systems.",
            "code": "// Example 1 - Interrupt handling simulation\n#include <stdio.h>\n#include <signal.h>\n#include <setjmp.h>\n#include <unistd.h>\n\njmp_buf interrupt_context;\nvolatile sig_atomic_t interrupt_pending = 0;\n\n// Simulated interrupt service routine\nvoid interrupt_service_routine(int sig) {\n    printf(\"\\n=== INTERRUPT HANDLING ===\\n\");\n    printf(\"Interrupt signal %d received!\\n\", sig);\n    printf(\"Saving current context...\\n\");\n    \n    // Set flag to indicate interrupt occurred\n    interrupt_pending = 1;\n    \n    // In real system, we would return using iret, not longjmp\n    printf(\"Returning from interrupt...\\n\");\n    printf(\"=== INTERRUPT COMPLETE ===\\n\\n\");\n}\n\n// Simulated main program\nvoid main_program() {\n    printf(\"Main program running...\\n\");\n    \n    for (int i = 0; i < 10; i++) {\n        printf(\"Executing instruction %d\\n\", i);\n        usleep(500000); // 0.5 seconds\n        \n        // Check for pending interrupts\n        if (interrupt_pending) {\n            printf(\"Processing pending interrupt...\\n\");\n            interrupt_pending = 0;\n            // Process the interrupt\n            printf(\"Interrupt processing complete.\\n\");\n        }\n    }\n    \n    printf(\"Main program completed.\\n\");\n}\n\nvoid simulate_interrupt_handling() {\n    printf(\"Interrupt Handling Simulation:\\n\\n\");\n    \n    // Set up signal handler for simulated interrupts\n    signal(SIGINT, interrupt_service_routine);\n    signal(SIGUSR1, interrupt_service_routine);\n    \n    printf(\"Starting main program. Send interrupts using:\\n\");\n    printf(\"  Ctrl+C for SIGINT\\n\");\n    printf(\"  kill -USR1 %d for SIGUSR1\\n\\n\", getpid());\n    \n    main_program();\n}\n\n// Example 2 - Interrupt priority simulation\n#include <stdio.h>\n#include <signal.h>\n#include <unistd.h>\n\nvolatile sig_atomic_t high_priority_interrupt = 0;\nvolatile sig_atomic_t low_priority_interrupt = 0;\n\n// High priority interrupt handler\nvoid high_priority_isr(int sig) {\n    printf(\"\\n*** HIGH PRIORITY INTERRUPT ***\\n\");\n    printf(\"Immediate processing required!\\n\");\n    \n    // Simulate critical processing\n    for (int i = 0; i < 3; i++) {\n        printf(\"HP ISR working... %d\\n\", i);\n        usleep(200000);\n    }\n    \n    printf(\"*** HIGH PRIORITY COMPLETE ***\\n\\n\");\n    high_priority_interrupt = 0;\n}\n\n// Low priority interrupt handler\nvoid low_priority_isr(int sig) {\n    printf(\"\\n--- Low priority interrupt ---\\n\");\n    printf(\"Can be deferred if needed\\n\");\n    \n    // Set flag for deferred processing\n    low_priority_interrupt = 1;\n    printf(\"--- Interrupt noted ---\\n\\n\");\n}\n\nvoid simulate_interrupt_priority() {\n    printf(\"Interrupt Priority Simulation:\\n\\n\");\n    \n    // Set up signal handlers\n    signal(SIGUSR1, high_priority_isr);  // High priority\n    signal(SIGUSR2, low_priority_isr);   // Low priority\n    \n    printf(\"Send interrupts using:\\n\");\n    printf(\"  kill -USR1 %d (High priority)\\n\", getpid());\n    printf(\"  kill -USR2 %d (Low priority)\\n\\n\", getpid());\n    \n    printf(\"Main program starting...\\n\");\n    \n    for (int i = 0; i < 15; i++) {\n        printf(\"Main program step %d\\n\", i);\n        usleep(300000); // 0.3 seconds\n        \n        // Check for low priority interrupts (deferred processing)\n        if (low_priority_interrupt) {\n            printf(\"Processing deferred low priority interrupt...\\n\");\n            \n            // Simulate low priority processing\n            for (int j = 0; j < 2; j++) {\n                printf(\"LP ISR working... %d\\n\", j);\n                usleep(200000);\n            }\n            \n            printf(\"Low priority processing complete.\\n\");\n            low_priority_interrupt = 0;\n        }\n    }\n    \n    printf(\"Main program completed.\\n\");\n}\n\nint main() {\n    simulate_interrupt_handling();\n    printf(\"\\n\");\n    simulate_interrupt_priority();\n    return 0;\n}"
          }
        ]
      },
      {
        "id": "c9-deadlocks",
        "title": "Deadlocks",
        "desc": "Understanding, preventing, and recovering from deadlocks",
        "notes": "Deadlock is a situation in operating systems where two or more processes are unable to proceed because each is waiting for a resource that is held by another process in the set. This results in a permanent blocking of the processes involved. Deadlock occurs when four necessary conditions hold simultaneously: mutual exclusion (resources cannot be shared), hold and wait (processes hold resources while waiting for others), no preemption (resources cannot be forcibly taken), and circular wait (a circular chain of processes exists). Systems handle deadlocks through prevention (designing the system to avoid one of the four conditions), avoidance (dynamically checking if resource allocation might lead to deadlock), detection (periodically checking for deadlock existence), and recovery (breaking deadlocks when they occur). Understanding deadlocks is crucial for system designers and developers to create robust systems that either avoid deadlocks entirely or can recover from them efficiently.",
        "code": "",
        "duration": "Week 1",
        "topics": [
          {
            "id": "t35-conditions",
            "title": "Deadlock Conditions",
            "desc": "Necessary conditions for deadlock occurrence",
            "note": "Deadlock occurs when four necessary conditions hold simultaneously in a system. These conditions, first described by Coffman, Elphick, and Shoshani in 1971, are: 1) Mutual Exclusion - At least one resource must be held in a non-sharable mode, meaning only one process can use the resource at a time. 2) Hold and Wait - Processes already holding resources may request additional resources without releasing their current resources. 3) No Preemption - Resources cannot be forcibly taken from processes; they must be explicitly released by the process holding them. 4) Circular Wait - A circular chain of processes exists where each process is waiting for a resource held by the next process in the chain. All four conditions must be present for a deadlock to occur. If any one condition is prevented, deadlock cannot occur. Understanding these conditions is fundamental to deadlock analysis, as they provide the basis for deadlock prevention, avoidance, and detection strategies. System designers can choose which condition to target based on system requirements and constraints.",
            "code": "// Example 1 - Demonstrating deadlock conditions\n#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\npthread_mutex_t resource1 = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t resource2 = PTHREAD_MUTEX_INITIALIZER;\n\nvoid *process1(void *arg) {\n    printf(\"Process 1: Requesting resource 1 (Mutual Exclusion)\\n\");\n    pthread_mutex_lock(&resource1);\n    printf(\"Process 1: Acquired resource 1\\n\");\n    \n    usleep(100000); // Simulate work\n    \n    printf(\"Process 1: Requesting resource 2 (Hold and Wait)\\n\");\n    pthread_mutex_lock(&resource2); // This will cause deadlock\n    printf(\"Process 1: Acquired resource 2\\n\");\n    \n    pthread_mutex_unlock(&resource2);\n    pthread_mutex_unlock(&resource1);\n    return NULL;\n}\n\nvoid *process2(void *arg) {\n    printf(\"Process 2: Requesting resource 2 (Mutual Exclusion)\\n\");\n    pthread_mutex_lock(&resource2);\n    printf(\"Process 2: Acquired resource 2\\n\");\n    \n    usleep(100000); // Simulate work\n    \n    printf(\"Process 2: Requesting resource 1 (Hold and Wait)\\n\");\n    pthread_mutex_lock(&resource1); // This will cause deadlock\n    printf(\"Process 2: Acquired resource 1\\n\");\n    \n    pthread_mutex_unlock(&resource1);\n    pthread_mutex_unlock(&resource2);\n    return NULL;\n}\n\nvoid demonstrate_deadlock_conditions() {\n    pthread_t thread1, thread2;\n    \n    printf(\"Demonstrating Deadlock Conditions:\\n\\n\");\n    printf(\"1. Mutual Exclusion: Resources cannot be shared\\n\");\n    printf(\"2. Hold and Wait: Processes hold resources while waiting for others\\n\");\n    printf(\"3. No Preemption: Resources cannot be forcibly taken\\n\");\n    printf(\"4. Circular Wait: Process1 -> Resource2 -> Process2 -> Resource1 -> Process1\\n\\n\");\n    \n    pthread_create(&thread1, NULL, process1, NULL);\n    pthread_create(&thread2, NULL, process2, NULL);\n    \n    // Let threads run for a bit\n    sleep(2);\n    \n    printf(\"\\nSystem is now deadlocked! Both processes are waiting indefinitely.\\n\");\n    printf(\"All four conditions are satisfied, causing deadlock.\\n\");\n}\n\n// Example 2 - Breaking deadlock by preventing one condition\nvoid *process1_safe(void *arg) {\n    printf(\"Process 1 (Safe): Requesting both resources at once\\n\");\n    \n    // Request both resources together to avoid hold and wait\n    pthread_mutex_lock(&resource1);\n    pthread_mutex_lock(&resource2);\n    \n    printf(\"Process 1 (Safe): Acquired both resources\\n\");\n    \n    // Do work\n    usleep(200000);\n    \n    pthread_mutex_unlock(&resource2);\n    pthread_mutex_unlock(&resource1);\n    \n    printf(\"Process 1 (Safe): Released both resources\\n\");\n    return NULL;\n}\n\nvoid *process2_safe(void *arg) {\n    printf(\"Process 2 (Safe): Requesting both resources at once\\n\");\n    \n    // Request both resources together to avoid hold and wait\n    pthread_mutex_lock(&resource1);\n    pthread_mutex_lock(&resource2);\n    \n    printf(\"Process 2 (Safe): Acquired both resources\\n\");\n    \n    // Do work\n    usleep(200000);\n    \n    pthread_mutex_unlock(&resource2);\n    pthread_mutex_unlock(&resource1);\n    \n    printf(\"Process 2 (Safe): Released both resources\\n\");\n    return NULL;\n}\n\nvoid demonstrate_deadlock_prevention() {\n    pthread_t thread1, thread2;\n    \n    printf(\"\\nDemonstrating Deadlock Prevention:\\n\");\n    printf(\"Preventing 'Hold and Wait' condition by requesting all resources at once\\n\\n\");\n    \n    pthread_create(&thread1, NULL, process1_safe, NULL);\n    pthread_create(&thread2, NULL, process2_safe, NULL);\n    \n    pthread_join(thread1, NULL);\n    pthread_join(thread2, NULL);\n    \n    printf(\"\\nBoth processes completed successfully - no deadlock!\\n\");\n    printf(\"By preventing one condition (Hold and Wait), deadlock was avoided.\\n\");\n}\n\nint main() {\n    demonstrate_deadlock_conditions();\n    demonstrate_deadlock_prevention();\n    \n    // Cleanup\n    pthread_mutex_destroy(&resource1);\n    pthread_mutex_destroy(&resource2);\n    \n    return 0;\n}"
          },
          {
            "id": "t36-prevention",
            "title": "Deadlock Prevention",
            "desc": "Designing systems to avoid deadlock conditions",
            "note": "Deadlock prevention involves designing a system in such a way that at least one of the four necessary conditions for deadlock cannot hold. This approach ensures that deadlocks are impossible by system design. The strategies include: 1) Preventing Mutual Exclusion - Make all resources sharable (not always possible, e.g., printers cannot be truly shared). 2) Preventing Hold and Wait - Require processes to request all resources before execution or release all resources before requesting new ones. 3) Preventing No Preemption - Allow the system to forcibly take resources from processes (complicated and may cause issues). 4) Preventing Circular Wait - Impose a total ordering of resource types and require processes to request resources in increasing order. Each prevention strategy has trade-offs: preventing mutual exclusion is often impractical for physical devices; preventing hold and wait can lead to poor resource utilization; preemption may be difficult to implement safely; and enforcing resource ordering adds complexity. Deadlock prevention is often used in real-time and embedded systems where predictability is more important than optimal resource utilization. The choice of prevention strategy depends on system requirements, resource types, and performance considerations.",
            "code": "// Example 1 - Deadlock prevention by resource ordering\n#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\n// Define resource ordering: resource1 < resource2\npthread_mutex_t resource1 = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t resource2 = PTHREAD_MUTEX_INITIALIZER;\n\nvoid *process_with_ordering(void *arg) {\n    int process_id = *(int*)arg;\n    \n    printf(\"Process %d: Requesting resources in order (resource1 then resource2)\\n\", process_id);\n    \n    // Always acquire resources in increasing order to prevent circular wait\n    pthread_mutex_lock(&resource1);\n    printf(\"Process %d: Acquired resource1\\n\", process_id);\n    \n    usleep(100000); // Simulate work\n    \n    pthread_mutex_lock(&resource2);\n    printf(\"Process %d: Acquired resource2\\n\", process_id);\n    \n    // Critical section\n    printf(\"Process %d: Using both resources\\n\", process_id);\n    usleep(200000);\n    \n    // Release in reverse order (not strictly necessary but good practice)\n    pthread_mutex_unlock(&resource2);\n    pthread_mutex_unlock(&resource1);\n    \n    printf(\"Process %d: Released all resources\\n\", process_id);\n    return NULL;\n}\n\nvoid demonstrate_resource_ordering() {\n    pthread_t thread1, thread2;\n    int id1 = 1, id2 = 2;\n    \n    printf(\"Deadlock Prevention by Resource Ordering:\\n\\n\");\n    printf(\"Resource ordering: resource1 < resource2\\n\");\n    printf(\"All processes must request resources in this order\\n\\n\");\n    \n    pthread_create(&thread1, NULL, process_with_ordering, &id1);\n    pthread_create(&thread2, NULL, process_with_ordering, &id2);\n    \n    pthread_join(thread1, NULL);\n    pthread_join(thread2, NULL);\n    \n    printf(\"\\nBoth processes completed successfully!\\n\");\n    printf(\"Circular wait prevented by enforcing resource ordering.\\n\");\n}\n\n// Example 2 - Deadlock prevention by no hold and wait\n#include <stdio.h>\n#include <pthread.h>\n\npthread_mutex_t global_lock = PTHREAD_MUTEX_INITIALIZER;\n\nvoid *process_no_hold_wait(void *arg) {\n    int process_id = *(int*)arg;\n    \n    printf(\"Process %d: Requesting all resources at once\\n\", process_id);\n    \n    // Acquire global lock before requesting any resources\n    pthread_mutex_lock(&global_lock);\n    \n    // Now acquire all needed resources\n    pthread_mutex_lock(&resource1);\n    pthread_mutex_lock(&resource2);\n    \n    printf(\"Process %d: Acquired all resources\\n\", process_id);\n    \n    // Release global lock - other processes can now see we have all resources\n    pthread_mutex_unlock(&global_lock);\n    \n    // Critical section\n    printf(\"Process %d: Using resources\\n\", process_id);\n    usleep(200000);\n    \n    // Release resources\n    pthread_mutex_unlock(&resource2);\n    pthread_mutex_unlock(&resource1);\n    \n    printf(\"Process %d: Released all resources\\n\", process_id);\n    return NULL;\n}\n\nvoid demonstrate_no_hold_wait() {\n    pthread_t thread1, thread2;\n    int id1 = 1, id2 = 2;\n    \n    printf(\"\\nDeadlock Prevention by No Hold and Wait:\\n\\n\");\n    printf(\"Processes must request all resources at once\\n\");\n    printf(\"Using a global lock to ensure atomic resource acquisition\\n\\n\");\n    \n    pthread_create(&thread1, NULL, process_no_hold_wait, &id1);\n    pthread_create(&thread2, NULL, process_no_hold_wait, &id2);\n    \n    pthread_join(thread1, NULL);\n    pthread_join(thread2, NULL);\n    \n    printf(\"\\nBoth processes completed successfully!\\n\");\n    printf(\"Hold and wait prevented by atomic resource acquisition.\\n\");\n}\n\nint main() {\n    demonstrate_resource_ordering();\n    demonstrate_no_hold_wait();\n    \n    // Cleanup\n    pthread_mutex_destroy(&resource1);\n    pthread_mutex_destroy(&resource2);\n    pthread_mutex_destroy(&global_lock);\n    \n    return 0;\n}"
          },
          {
            "id": "t37-avoidance",
            "title": "Deadlock Avoidance",
            "desc": "Dynamically avoiding deadlock during resource allocation",
            "note": "Deadlock avoidance involves dynamically checking whether resource allocation requests could lead to a deadlock and only granting requests that maintain a safe state. Unlike prevention which designs constraints into the system, avoidance makes decisions at runtime based on the current system state. The main deadlock avoidance algorithm is the Banker's Algorithm, which requires that processes declare their maximum resource needs in advance. The algorithm maintains information about available resources, allocated resources, and maximum demands. Before granting a resource request, the algorithm checks if the resulting state would be safe - meaning there exists a sequence (safe sequence) in which all processes can complete without deadlock. A state is safe if the system can allocate resources to each process in some order and still avoid deadlock. The Banker's Algorithm has some limitations: it requires knowledge of maximum resource needs in advance, it can be computationally expensive for large systems, and it assumes a fixed number of resources. Other avoidance techniques include resource allocation graphs with claim edges, which work well for systems with single instances of each resource type. Deadlock avoidance provides better resource utilization than prevention but requires more runtime overhead and advance knowledge of process behavior.",
            "code": "// Example 1 - Banker's Algorithm implementation\n#include <stdio.h>\n#include <stdbool.h>\n\n#define NUM_PROCESSES 5\n#define NUM_RESOURCES 3\n\n// Available resources\nint available[NUM_RESOURCES] = {3, 3, 2};\n\n// Maximum demand of each process\nint max[NUM_PROCESSES][NUM_RESOURCES] = {\n    {7, 5, 3},\n    {3, 2, 2},\n    {9, 0, 2},\n    {2, 2, 2},\n    {4, 3, 3}\n};\n\n// Resources currently allocated to each process\nint allocation[NUM_PROCESSES][NUM_RESOURCES] = {\n    {0, 1, 0},\n    {2, 0, 0},\n    {3, 0, 2},\n    {2, 1, 1},\n    {0, 0, 2}\n};\n\n// Need of each process (max - allocation)\nint need[NUM_PROCESSES][NUM_RESOURCES];\n\nvoid calculate_need() {\n    for (int i = 0; i < NUM_PROCESSES; i++) {\n        for (int j = 0; j < NUM_RESOURCES; j++) {\n            need[i][j] = max[i][j] - allocation[i][j];\n        }\n    }\n}\n\n// Check if the system is in a safe state\nbool is_safe_state() {\n    int work[NUM_RESOURCES];\n    bool finish[NUM_PROCESSES] = {false};\n    int safe_sequence[NUM_PROCESSES];\n    int count = 0;\n    \n    // Initialize work array\n    for (int i = 0; i < NUM_RESOURCES; i++) {\n        work[i] = available[i];\n    }\n    \n    // Find a process that can finish\n    while (count < NUM_PROCESSES) {\n        bool found = false;\n        \n        for (int i = 0; i < NUM_PROCESSES; i++) {\n            if (!finish[i]) {\n                bool can_allocate = true;\n                \n                // Check if process i's need can be satisfied\n                for (int j = 0; j < NUM_RESOURCES; j++) {\n                    if (need[i][j] > work[j]) {\n                        can_allocate = false;\n                        break;\n                    }\n                }\n                \n                if (can_allocate) {\n                    // This process can complete\n                    for (int j = 0; j < NUM_RESOURCES; j++) {\n                        work[j] += allocation[i][j];\n                    }\n                    \n                    safe_sequence[count++] = i;\n                    finish[i] = true;\n                    found = true;\n                }\n            }\n        }\n        \n        // If no process found, system is not in safe state\n        if (!found) {\n            return false;\n        }\n    }\n    \n    // Print safe sequence\n    printf(\"Safe sequence: \");\n    for (int i = 0; i < NUM_PROCESSES; i++) {\n        printf(\"P%d \", safe_sequence[i]);\n    }\n    printf(\"\\n\");\n    \n    return true;\n}\n\n// Request resources for a process\nbool request_resources(int process_id, int request[]) {\n    printf(\"Process P%d requesting resources: \", process_id);\n    for (int i = 0; i < NUM_RESOURCES; i++) {\n        printf(\"%d \", request[i]);\n    }\n    printf(\"\\n\");\n    \n    // Check if request exceeds need\n    for (int i = 0; i < NUM_RESOURCES; i++) {\n        if (request[i] > need[process_id][i]) {\n            printf(\"Error: Request exceeds maximum need\\n\");\n            return false;\n        }\n    }\n    \n    // Check if request exceeds available resources\n    for (int i = 0; i < NUM_RESOURCES; i++) {\n        if (request[i] > available[i]) {\n            printf(\"Process must wait: Not enough resources available\\n\");\n            return false;\n        }\n    }\n    \n    // Try to allocate resources temporarily\n    for (int i = 0; i < NUM_RESOURCES; i++) {\n        available[i] -= request[i];\n        allocation[process_id][i] += request[i];\n        need[process_id][i] -= request[i];\n    }\n    \n    // Check if the resulting state is safe\n    if (is_safe_state()) {\n        printf(\"Request granted: System remains in safe state\\n\");\n        return true;\n    } else {\n        // Revert the allocation\n        printf(\"Request denied: Would lead to unsafe state\\n\");\n        for (int i = 0; i < NUM_RESOURCES; i++) {\n            available[i] += request[i];\n            allocation[process_id][i] -= request[i];\n            need[process_id][i] += request[i];\n        }\n        return false;\n    }\n}\n\nvoid demonstrate_bankers_algorithm() {\n    printf(\"Banker's Algorithm for Deadlock Avoidance:\\n\\n\");\n    \n    calculate_need();\n    \n    printf(\"Initial state:\\n\");\n    printf(\"Available resources: \");\n    for (int i = 0; i < NUM_RESOURCES; i++) {\n        printf(\"%d \", available[i]);\n    }\n    printf(\"\\n\");\n    \n    // Check if initial state is safe\n    if (is_safe_state()) {\n        printf(\"System is in a safe state\\n\\n\");\n    } else {\n        printf(\"System is not in a safe state\\n\\n\");\n        return;\n    }\n    \n    // Test some resource requests\n    int request1[NUM_RESOURCES] = {1, 0, 2}; // P1 request\n    request_resources(1, request1);\n    \n    printf(\"\\n\");\n    \n    int request2[NUM_RESOURCES] = {3, 3, 0}; // P4 request (should be denied)\n    request_resources(4, request2);\n}\n\n// Example 2 - Resource allocation graph for deadlock avoidance\nvoid demonstrate_resource_allocation_graph() {\n    printf(\"\\nResource Allocation Graph for Deadlock Avoidance:\\n\\n\");\n    \n    printf(\"For single instance resources, we can use resource allocation graphs\\n\");\n    printf(\"with claim edges to avoid deadlocks.\\n\\n\");\n    \n    printf(\"Steps:\\n\");\n    printf(\"1. Processes declare their maximum resource requirements\\n\");\n    printf(\"2. System maintains a resource allocation graph with claim edges\\n\");\n    printf(\"3. Before granting a request, check if it would create a cycle\\n\");\n    printf(\"4. If cycle would be created, deny the request\\n\\n\");\n    \n    printf(\"Advantages:\\n\");\n    printf(\" - Works well for single instance resources\\n\");\n    printf(\" - Less computational overhead than Banker's Algorithm\\n\\n\");\n    \n    printf(\"Limitations:\\n\");\n    printf(\" - Only works for single instance resources\\n\");\n    printf(\" - Still requires advance knowledge of maximum needs\\n\");\n}\n\nint main() {\n    demonstrate_bankers_algorithm();\n    demonstrate_resource_allocation_graph();\n    return 0;\n}"
          },
          {
            "id": "t38-detection",
            "title": "Deadlock Detection",
            "desc": "Identifying deadlocks in system state",
            "note": "Deadlock detection involves periodically examining the system state to determine whether a deadlock has occurred. This approach doesn't try to prevent deadlocks but instead detects them after they happen and then takes recovery actions. Detection algorithms maintain a resource allocation graph or wait-for graph that represents processes and resources and their relationships. For systems with single instances of each resource type, deadlock can be detected by looking for cycles in the wait-for graph. For systems with multiple instances of resource types, detection algorithms similar to the Banker's Algorithm are used but without the safe state concept - instead they look for processes that cannot complete given current resource availability. The detection algorithm must be run periodically, and the frequency involves a trade-off between detection latency and computational overhead. Once a deadlock is detected, the system can employ recovery strategies such as process termination or resource preemption. Deadlock detection is suitable for systems where deadlocks are rare or where prevention/avoidance techniques are too restrictive. It provides better resource utilization than prevention but requires recovery mechanisms and periodic overhead for running detection algorithms.",
            "code": "// Example 1 - Wait-for graph cycle detection\n#include <stdio.h>\n#include <stdbool.h>\n\n#define NUM_PROCESSES 5\n\n// Wait-for graph: graph[i][j] = true if process i is waiting for process j\nbool wait_for_graph[NUM_PROCESSES][NUM_PROCESSES] = {\n    {false, true, false, false, false},  // P0 waits for P1\n    {false, false, true, false, false},  // P1 waits for P2\n    {false, false, false, true, false},  // P2 waits for P3\n    {true, false, false, false, false},  // P3 waits for P0\n    {false, false, false, false, false}   // P4 not waiting\n};\n\n// Depth-first search for cycle detection\nbool dfs(int node, bool visited[], bool rec_stack[]) {\n    if (!visited[node]) {\n        visited[node] = true;\n        rec_stack[node] = true;\n        \n        for (int i = 0; i < NUM_PROCESSES; i++) {\n            if (wait_for_graph[node][i]) {\n                if (!visited[i] && dfs(i, visited, rec_stack)) {\n                    return true;\n                } else if (rec_stack[i]) {\n                    return true;\n                }\n            }\n        }\n    }\n    \n    rec_stack[node] = false;\n    return false;\n}\n\nbool detect_deadlock() {\n    bool visited[NUM_PROCESSES] = {false};\n    bool rec_stack[NUM_PROCESSES] = {false};\n    \n    for (int i = 0; i < NUM_PROCESSES; i++) {\n        if (!visited[i] && dfs(i, visited, rec_stack)) {\n            return true;\n        }\n    }\n    \n    return false;\n}\n\nvoid demonstrate_wait_for_graph() {\n    printf(\"Wait-for Graph Deadlock Detection:\\n\\n\");\n    \n    printf(\"Wait-for graph (P0->P1->P2->P3->P0):\\n\");\n    for (int i = 0; i < NUM_PROCESSES; i++) {\n        printf(\"P%d waits for: \", i);\n        for (int j = 0; j < NUM_PROCESSES; j++) {\n            if (wait_for_graph[i][j]) {\n                printf(\"P%d \", j);\n            }\n        }\n        printf(\"\\n\");\n    }\n    \n    if (detect_deadlock()) {\n        printf(\"\\nDeadlock detected! Cycle exists in wait-for graph.\\n\");\n    } else {\n        printf(\"\\nNo deadlock detected.\\n\");\n    }\n}\n\n// Example 2 - Deadlock detection for multiple resource instances\n#include <stdio.h>\n#include <stdbool.h>\n\n#define NUM_PROCESSES 5\n#define NUM_RESOURCES 3\n\nint available[NUM_RESOURCES] = {0, 0, 0}; // No available resources\nint allocation[NUM_PROCESSES][NUM_RESOURCES] = {\n    {0, 1, 0},\n    {2, 0, 0},\n    {3, 0, 3},\n    {2, 1, 1},\n    {0, 0, 2}\n};\n\nint request[NUM_PROCESSES][NUM_RESOURCES] = {\n    {0, 0, 0},\n    {2, 0, 2},\n    {0, 0, 0},\n    {1, 0, 0},\n    {0, 0, 2}\n};\n\nbool detect_deadlock_multiple() {\n    int work[NUM_RESOURCES];\n    bool finish[NUM_PROCESSES] = {false};\n    \n    // Initialize work array\n    for (int i = 0; i < NUM_RESOURCES; i++) {\n        work[i] = available[i];\n    }\n    \n    // Find processes that can finish\n    bool changed;\n    do {\n        changed = false;\n        \n        for (int i = 0; i < NUM_PROCESSES; i++) {\n            if (!finish[i]) {\n                bool can_finish = true;\n                \n                // Check if all requests can be satisfied\n                for (int j = 0; j < NUM_RESOURCES; j++) {\n                    if (request[i][j] > work[j]) {\n                        can_finish = false;\n                        break;\n                    }\n                }\n                \n                if (can_finish) {\n                    // This process can finish\n                    for (int j = 0; j < NUM_RESOURCES; j++) {\n                        work[j] += allocation[i][j];\n                    }\n                    finish[i] = true;\n                    changed = true;\n                }\n            }\n        }\n    } while (changed);\n    \n    // Check for deadlock\n    for (int i = 0; i < NUM_PROCESSES; i++) {\n        if (!finish[i]) {\n            printf(\"Process P%d is deadlocked\\n\", i);\n            return true;\n        }\n    }\n    \n    return false;\n}\n\nvoid demonstrate_multiple_resource_detection() {\n    printf(\"\\nDeadlock Detection for Multiple Resource Instances:\\n\\n\");\n    \n    printf(\"Available resources: \");\n    for (int i = 0; i < NUM_RESOURCES; i++) {\n        printf(\"%d \", available[i]);\n    }\n    printf(\"\\n\");\n    \n    printf(\"Allocation matrix:\\n\");\n    for (int i = 0; i < NUM_PROCESSES; i++) {\n        printf(\"P%d: \", i);\n        for (int j = 0; j < NUM_RESOURCES; j++) {\n            printf(\"%d \", allocation[i][j]);\n        }\n        printf(\"\\n\");\n    }\n    \n    printf(\"Request matrix:\\n\");\n    for (int i = 0; i < NUM_PROCESSES; i++) {\n        printf(\"P%d: \", i);\n        for (int j = 0; j < NUM_RESOURCES; j++) {\n            printf(\"%d \", request[i][j]);\n        }\n        printf(\"\\n\");\n    }\n    \n    if (detect_deadlock_multiple()) {\n        printf(\"\\nDeadlock detected in the system!\\n\");\n    } else {\n        printf(\"\\nNo deadlock detected.\\n\");\n    }\n}\n\nint main() {\n    demonstrate_wait_for_graph();\n    demonstrate_multiple_resource_detection();\n    return 0;\n}"
          },
          {
            "id": "t39-recovery",
            "title": "Deadlock Recovery",
            "desc": "Strategies for recovering from deadlocks",
            "note": "Deadlock recovery involves taking action to break a deadlock after it has been detected. Recovery strategies can be classified into process termination and resource preemption. Process termination approaches include: 1) Abort all deadlocked processes - simple but drastic, may cause significant work loss. 2) Abort processes one by one - more graceful but requires repeated deadlock detection. The choice of which process to terminate can be based on priority, computation time, resources held, or other factors. Resource preemption involves selecting a victim process and forcibly taking resources from it to break the deadlock. This requires: 1) Selecting a victim - based on cost factors like priority, execution time, or resources held. 2) Rollback - either complete rollback (restart process) or partial rollback (roll back to safe state). 3) Starvation prevention - ensuring the same process isn't always chosen as victim. Recovery strategies must consider the cost of recovery, including lost work, overhead, and potential starvation. The choice between termination and preemption depends on system requirements, process criticality, and the nature of the resources involved. Some systems use a combination of approaches, applying different recovery strategies to different types of processes or resources.",
            "code": "// Example 1 - Process termination for deadlock recovery\n#include <stdio.h>\n#include <stdbool.h>\n#include <stdlib.h>\n\n#define NUM_PROCESSES 4\n\n// Process structure\ntypedef struct {\n    int pid;\n    int priority;\n    int execution_time;\n    int resources_held;\n    bool deadlocked;\n} process_t;\n\nprocess_t processes[NUM_PROCESSES] = {\n    {0, 2, 100, 3, true},\n    {1, 1, 200, 2, true},\n    {2, 3, 50, 1, true},\n    {3, 2, 150, 4, true}\n};\n\n// Select victim process for termination\nint select_victim() {\n    int victim = -1;\n    int min_priority = 1000;\n    \n    // Select process with lowest priority\n    for (int i = 0; i < NUM_PROCESSES; i++) {\n        if (processes[i].deadlocked && processes[i].priority < min_priority) {\n            min_priority = processes[i].priority;\n            victim = i;\n        }\n    }\n    \n    return victim;\n}\n\n// Terminate a process and release its resources\nvoid terminate_process(int victim) {\n    printf(\"Terminating process P%d (priority: %d, execution time: %d, resources: %d)\\n\",\n           processes[victim].pid, processes[victim].priority,\n           processes[victim].execution_time, processes[victim].resources_held);\n    \n    processes[victim].deadlocked = false;\n    \n    printf(\"Released %d resources from process P%d\\n\", \n           processes[victim].resources_held, processes[victim].pid);\n}\n\n// Check if deadlock still exists\nbool deadlock_exists() {\n    for (int i = 0; i < NUM_PROCESSES; i++) {\n        if (processes[i].deadlocked) {\n            return true;\n        }\n    }\n    return false;\n}\n\nvoid demonstrate_process_termination() {\n    printf(\"Deadlock Recovery by Process Termination:\\n\\n\");\n    \n    printf(\"Deadlocked processes:\\n\");\n    for (int i = 0; i < NUM_PROCESSES; i++) {\n        if (processes[i].deadlocked) {\n            printf(\"P%d (priority: %d, time: %d, resources: %d)\\n\",\n                   processes[i].pid, processes[i].priority,\n                   processes[i].execution_time, processes[i].resources_held);\n        }\n    }\n    \n    printf(\"\\nRecovery process:\\n\");\n    \n    while (deadlock_exists()) {\n        int victim = select_victim();\n        if (victim == -1) {\n            printf(\"No more processes to terminate\\n\");\n            break;\n        }\n        \n        terminate_process(victim);\n        \n        // In a real system, we would check if deadlock is resolved\n        // after each termination\n        printf(\"Checking if deadlock is resolved...\\n\");\n    }\n    \n    printf(\"\\nDeadlock recovered! All processes terminated or deadlock resolved.\\n\");\n}\n\n// Example 2 - Resource preemption for deadlock recovery\n#include <stdio.h>\n#include <stdbool.h>\n\n#define NUM_PROCESSES 3\n#define NUM_RESOURCES 2\n\nint allocation[NUM_PROCESSES][NUM_RESOURCES] = {\n    {2, 0},\n    {0, 1},\n    {1, 1}\n};\n\nint request[NUM_PROCESSES][NUM_RESOURCES] = {\n    {0, 1},\n    {2, 0},\n    {0, 0}\n};\n\nint available[NUM_RESOURCES] = {0, 0};\n\n// Select victim for resource preemption\nint select_preemption_victim() {\n    // Simple strategy: select process with most resources\n    int max_resources = -1;\n    int victim = -1;\n    \n    for (int i = 0; i < NUM_PROCESSES; i++) {\n        int total_resources = 0;\n        for (int j = 0; j < NUM_RESOURCES; j++) {\n            total_resources += allocation[i][j];\n        }\n        \n        if (total_resources > max_resources) {\n            max_resources = total_resources;\n            victim = i;\n        }\n    }\n    \n    return victim;\n}\n\n// Preempt resources from a process\nvoid preempt_resources(int victim) {\n    printf(\"Preempting resources from process P%d\\n\", victim);\n    printf(\"Resources held: \");\n    for (int j = 0; j < NUM_RESOURCES; j++) {\n        printf(\"%d \", allocation[victim][j]);\n        available[j] += allocation[victim][j];\n        allocation[victim][j] = 0;\n    }\n    printf(\"\\n\");\n    \n    printf(\"New available resources: \");\n    for (int j = 0; j < NUM_RESOURCES; j++) {\n        printf(\"%d \", available[j]);\n    }\n    printf(\"\\n\");\n}\n\n// Check if process can complete with current resources\nbool can_complete(int process) {\n    for (int j = 0; j < NUM_RESOURCES; j++) {\n        if (request[process][j] > available[j]) {\n            return false;\n        }\n    }\n    return true;\n}\n\nvoid demonstrate_resource_preemption() {\n    printf(\"\\nDeadlock Recovery by Resource Preemption:\\n\\n\");\n    \n    printf(\"Initial state:\\n\");\n    printf(\"Available resources: \");\n    for (int j = 0; j < NUM_RESOURCES; j++) {\n        printf(\"%d \", available[j]);\n    }\n    printf(\"\\n\");\n    \n    printf(\"Deadlock detected!\\n\");\n    \n    // Preempt resources from victim\n    int victim = select_preemption_victim();\n    preempt_resources(victim);\n    \n    // Check if other processes can now complete\n    printf(\"\\nChecking if processes can complete:\\n\");\n    for (int i = 0; i < NUM_PROCESSES; i++) {\n        if (i != victim && can_complete(i)) {\n            printf(\"Process P%d can now complete\\n\", i);\n            // Process would complete and release resources\n            for (int j = 0; j < NUM_RESOURCES; j++) {\n                available[j] += allocation[i][j];\n                allocation[i][j] = 0;\n            }\n        }\n    }\n    \n    printf(\"\\nFinal available resources: \");\n    for (int j = 0; j < NUM_RESOURCES; j++) {\n        printf(\"%d \", available[j]);\n    }\n    printf(\"\\n\");\n    \n    printf(\"Deadlock recovered through resource preemption!\\n\");\n}\n\nint main() {\n    demonstrate_process_termination();\n    demonstrate_resource_preemption();\n    return 0;\n}"
          }
        ]
      },
      {
        "id": "c10-security",
        "title": "Security & Protection",
        "desc": "OS security mechanisms and access control",
        "notes": "Operating system security and protection mechanisms are essential for ensuring the confidentiality, integrity, and availability of system resources and user data. Security involves protecting the system from external threats like malware and unauthorized access, while protection focuses on controlling access to resources by processes and users within the system. Key security concepts include authentication (verifying user identity), authorization (determining access rights), encryption (protecting data confidentiality), and auditing (logging security-relevant events). Protection mechanisms include access control lists (ACLs), capabilities, security domains, and reference monitors. Modern operating systems implement various security features like user account control, file permissions, network security, and malware protection. Understanding OS security is crucial for system administrators, security professionals, and developers to create and maintain secure computing environments.",
        "code": "",
        "duration": "Week 1",
        "topics": [
          {
            "id": "t40-access-control",
            "title": "Access Control Mechanisms",
            "desc": "Controlling resource access through permissions and policies",
            "note": "Access control mechanisms are fundamental to operating system security, determining which users or processes can access specific resources and what operations they can perform. The main access control models are: 1) Discretionary Access Control (DAC) - Resource owners control access permissions (e.g., Unix file permissions). 2) Mandatory Access Control (MAC) - System-wide policies enforce access based on security labels (e.g., SELinux, Windows Mandatory Integrity Control). 3) Role-Based Access Control (RBAC) - Access is based on user roles rather than individual identities. Access control is typically implemented using access control lists (ACLs) that specify permissions for each user/group on each resource, or capabilities that represent unforgeable tokens granting specific access rights. Operating systems also use protection domains to isolate processes and prevent unauthorized access to kernel resources. Modern systems often combine multiple access control models to provide defense in depth. Understanding access control mechanisms is essential for system administrators to configure secure systems and for developers to implement security-aware applications.",
            "code": "// Example 1 - Unix-style file permission simulation\n#include <stdio.h>\n#include <sys/stat.h>\n#include <stdbool.h>\n\n// File permission structure\ntypedef struct {\n    char owner[32];\n    char group[32];\n    mode_t mode; // Permission bits\n} file_perms_t;\n\n// User information\ntypedef struct {\n    char username[32];\n    char group[32];\n    uid_t uid;\n    gid_t gid;\n} user_info_t;\n\n// Check if access is allowed\nbool check_access(file_perms_t perms, user_info_t user, int access_type) {\n    // Check owner permissions\n    if (strcmp(user.username, perms.owner) == 0) {\n        if (access_type == 'r' && (perms.mode & S_IRUSR)) return true;\n        if (access_type == 'w' && (perms.mode & S_IWUSR)) return true;\n        if (access_type == 'x' && (perms.mode & S_IXUSR)) return true;\n    }\n    \n    // Check group permissions\n    if (strcmp(user.group, perms.group) == 0) {\n        if (access_type == 'r' && (perms.mode & S_IRGRP)) return true;\n        if (access_type == 'w' && (perms.mode & S_IWGRP)) return true;\n        if (access_type == 'x' && (perms.mode & S_IXGRP)) return true;\n    }\n    \n    // Check other permissions\n    if (access_type == 'r' && (perms.mode & S_IROTH)) return true;\n    if (access_type == 'w' && (perms.mode & S_IWOTH)) return true;\n    if (access_type == 'x' && (perms.mode & S_IXOTH)) return true;\n    \n    return false;\n}\n\nvoid demonstrate_unix_permissions() {\n    printf(\"Unix-style File Permission Simulation:\\n\\n\");\n    \n    // Create a file with specific permissions\n    file_perms_t file = {\n        .owner = \"alice\",\n        .group = \"users\",\n        .mode = S_IRUSR | S_IWUSR | S_IRGRP | S_IROTH // rw-r--r--\n    };\n    \n    // Create different users\n    user_info_t alice = {\"alice\", \"users\", 1000, 100};\n    user_info_t bob = {\"bob\", \"users\", 1001, 100};\n    user_info_t eve = {\"eve\", \"others\", 1002, 101};\n    \n    printf(\"File permissions: %o (rw-r--r--)\\n\", file.mode);\n    printf(\"Owner: %s, Group: %s\\n\\n\", file.owner, file.group);\n    \n    // Test access for different users\n    printf(\"Access checks:\\n\");\n    printf(\"Alice (owner) read access: %s\\n\", \n           check_access(file, alice, 'r') ? \"GRANTED\" : \"DENIED\");\n    printf(\"Alice (owner) write access: %s\\n\", \n           check_access(file, alice, 'w') ? \"GRANTED\" : \"DENIED\");\n    printf(\"Bob (group) read access: %s\\n\", \n           check_access(file, bob, 'r') ? \"GRANTED\" : \"DENIED\");\n    printf(\"Bob (group) write access: %s\\n\", \n           check_access(file, bob, 'w') ? \"GRANTED\" : \"DENIED\");\n    printf(\"Eve (other) read access: %s\\n\", \n           check_access(file, eve, 'r') ? \"GRANTED\" : \"DENIED\");\n    printf(\"Eve (other) write access: %s\\n\", \n           check_access(file, eve, 'w') ? \"GRANTED\" : \"DENIED\");\n}\n\n// Example 2 - Access Control List (ACL) simulation\n#include <stdio.h>\n#include <stdbool.h>\n\n#define MAX_ACL_ENTRIES 10\n\ntypedef struct {\n    char principal[32]; // User or group\n    char permissions[10]; // e.g., \"rwx\", \"r--\", etc.\n} acl_entry_t;\n\ntypedef struct {\n    acl_entry_t entries[MAX_ACL_ENTRIES];\n    int count;\n} acl_t;\n\n// Check ACL access\nbool check_acl_access(acl_t acl, const char *user, const char *group, char access_type) {\n    for (int i = 0; i < acl.count; i++) {\n        if (strcmp(acl.entries[i].principal, user) == 0 ||\n            strcmp(acl.entries[i].principal, group) == 0) {\n            \n            // Check if the requested access is allowed\n            const char *perms = acl.entries[i].permissions;\n            \n            if (access_type == 'r' && perms[0] == 'r') return true;\n            if (access_type == 'w' && perms[1] == 'w') return true;\n            if (access_type == 'x' && perms[2] == 'x') return true;\n        }\n    }\n    \n    return false;\n}\n\nvoid demonstrate_acl() {\n    printf(\"\\nAccess Control List (ACL) Simulation:\\n\\n\");\n    \n    // Create an ACL\n    acl_t acl = {\n        .entries = {\n            {\"alice\", \"rwx\"},\n            {\"users\", \"r-x\"},\n            {\"backup\", \"r--\"}\n        },\n        .count = 3\n    };\n    \n    printf(\"ACL Entries:\\n\");\n    for (int i = 0; i < acl.count; i++) {\n        printf(\"  %s: %s\\n\", acl.entries[i].principal, acl.entries[i].permissions);\n    }\n    printf(\"\\n\");\n    \n    // Test access\n    printf(\"Access checks:\\n\");\n    printf(\"Alice read access: %s\\n\", \n           check_acl_access(acl, \"alice\", \"\", 'r') ? \"GRANTED\" : \"DENIED\");\n    printf(\"Alice write access: %s\\n\", \n           check_acl_access(acl, \"alice\", \"\", 'w') ? \"GRANTED\" : \"DENIED\");\n    printf(\"Bob (users group) read access: %s\\n\", \n           check_acl_access(acl, \"bob\", \"users\", 'r') ? \"GRANTED\" : \"DENIED\");\n    printf(\"Bob (users group) write access: %s\\n\", \n           check_acl_access(acl, \"bob\", \"users\", 'w') ? \"GRANTED\" : \"DENIED\");\n    printf(\"Backup service read access: %s\\n\", \n           check_acl_access(acl, \"backup\", \"\", 'r') ? \"GRANTED\" : \"DENIED\");\n}\n\nint main() {\n    demonstrate_unix_permissions();\n    demonstrate_acl();\n    return 0;\n}"
          },
          {
            "id": "t41-authentication",
            "title": "Authentication Systems",
            "desc": "Verifying user identity and credentials",
            "note": "Authentication is the process of verifying the identity of users or entities attempting to access a system. Operating systems employ various authentication mechanisms to ensure that only authorized users can access resources. Common authentication methods include: 1) Password-based authentication - Users provide a secret known only to them. 2) Token-based authentication - Users possess a physical or digital token (e.g., smart cards, RSA tokens). 3) Biometric authentication - Users provide biological characteristics (e.g., fingerprints, facial recognition). 4) Multi-factor authentication - Combining multiple methods for enhanced security. Operating systems store user credentials securely using techniques like hashing and salting passwords. Authentication systems also handle account lockout policies, password expiration, and session management. Modern systems often integrate with enterprise authentication services like LDAP, Active Directory, or Kerberos for centralized identity management. Understanding authentication mechanisms is crucial for system administrators to configure secure access controls and for developers to implement proper authentication in applications.",
            "code": "// Example 1 - Password authentication simulation\n#include <stdio.h>\n#include <string.h>\n#include <openssl/sha.h>\n#include <openssl/rand.h>\n\n// User credential structure\ntypedef struct {\n    char username[32];\n    unsigned char password_hash[SHA256_DIGEST_LENGTH];\n    unsigned char salt[16];\n} user_credential_t;\n\n// Hash password with salt\nvoid hash_password(const char *password, const unsigned char *salt, unsigned char *hash) {\n    SHA256_CTX sha256;\n    SHA256_Init(&sha256);\n    SHA256_Update(&sha256, salt, 16);\n    SHA256_Update(&sha256, password, strlen(password));\n    SHA256_Final(hash, &sha256);\n}\n\n// Create new user credential\nvoid create_user(user_credential_t *user, const char *username, const char *password) {\n    strcpy(user->username, username);\n    \n    // Generate random salt\n    RAND_bytes(user->salt, 16);\n    \n    // Hash password with salt\n    hash_password(password, user->salt, user->password_hash);\n}\n\n// Verify password\nbool verify_password(user_credential_t *user, const char *password) {\n    unsigned char test_hash[SHA256_DIGEST_LENGTH];\n    hash_password(password, user->salt, test_hash);\n    \n    return memcmp(user->password_hash, test_hash, SHA256_DIGEST_LENGTH) == 0;\n}\n\nvoid demonstrate_password_auth() {\n    printf(\"Password Authentication Simulation:\\n\\n\");\n    \n    // Create a user\n    user_credential_t user;\n    create_user(&user, \"alice\", \"SecurePassword123\");\n    \n    printf(\"User: %s\\n\", user.username);\n    printf(\"Salt: \");\n    for (int i = 0; i < 16; i++) printf(\"%02x\", user.salt[i]);\n    printf(\"\\n\");\n    printf(\"Password hash: \");\n    for (int i = 0; i < SHA256_DIGEST_LENGTH; i++) printf(\"%02x\", user.password_hash[i]);\n    printf(\"\\n\\n\");\n    \n    // Test authentication\n    printf(\"Authentication tests:\\n\");\n    printf(\"Correct password: %s\\n\", \n           verify_password(&user, \"SecurePassword123\") ? \"SUCCESS\" : \"FAILURE\");\n    printf(\"Wrong password: %s\\n\", \n           verify_password(&user, \"WrongPassword\") ? \"SUCCESS\" : \"FAILURE\");\n    printf(\"Empty password: %s\\n\", \n           verify_password(&user, \"\") ? \"SUCCESS\" : \"FAILURE\");\n}\n\n// Example 2 - Multi-factor authentication simulation\n#include <stdio.h>\n#include <time.h>\n#include <stdlib.h>\n\n// Multi-factor authentication structure\ntypedef struct {\n    char username[32];\n    char password_hash[32];\n    char secret_key[16]; // For TOTP\n} mfa_user_t;\n\n// Generate Time-based One-Time Password (TOTP)\nint generate_totp(const char *secret, time_t time_val) {\n    // Simple simulation - real TOTP uses HMAC-SHA1\n    int time_step = time_val / 30; // 30-second steps\n    \n    // Use secret and time step to generate code\n    int code = 0;\n    for (int i = 0; i < 8 && secret[i] != '\\0'; i++) {\n        code = (code * 31 + secret[i]) % 1000000;\n    }\n    \n    code = (code + time_step) % 1000000;\n    return code;\n}\n\n// Simulate multi-factor authentication\nbool authenticate_mfa(mfa_user_t *user, const char *password, int totp_code) {\n    // Check password (simplified)\n    if (strcmp(password, \"correct_password\") != 0) {\n        return false;\n    }\n    \n    // Check TOTP code\n    time_t current_time = time(NULL);\n    int expected_code = generate_totp(user->secret_key, current_time);\n    \n    return totp_code == expected_code;\n}\n\nvoid demonstrate_mfa() {\n    printf(\"\\nMulti-Factor Authentication Simulation:\\n\\n\");\n    \n    mfa_user_t user = {\n        .username = \"alice\",\n        .secret_key = \"SECRET123\"\n    };\n    \n    time_t current_time = time(NULL);\n    int correct_totp = generate_totp(user.secret_key, current_time);\n    \n    printf(\"User: %s\\n\", user.username);\n    printf(\"Current TOTP code: %06d\\n\", correct_totp);\n    printf(\"\\n\");\n    \n    // Test authentication\n    printf(\"Authentication with correct password and correct TOTP: %s\\n\",\n           authenticate_mfa(&user, \"correct_password\", correct_totp) ? \"SUCCESS\" : \"FAILURE\");\n    \n    printf(\"Authentication with correct password and wrong TOTP: %s\\n\",\n           authenticate_mfa(&user, \"correct_password\", 123456) ? \"SUCCESS\" : \"FAILURE\");\n    \n    printf(\"Authentication with wrong password and correct TOTP: %s\\n\",\n           authenticate_mfa(&user, \"wrong_password\", correct_totp) ? \"SUCCESS\" : \"FAILURE\");\n}\n\nint main() {\n    demonstrate_password_auth();\n    demonstrate_mfa();\n    return 0;\n}"
          },
          {
            "id": "t42-encryption",
            "title": "Encryption Basics",
            "desc": "Protecting data confidentiality through encryption",
            "note": "Encryption is the process of converting plaintext data into ciphertext to protect its confidentiality. Operating systems use encryption to secure data at rest (on storage devices) and data in transit (over networks). Basic encryption concepts include: 1) Symmetric encryption - Uses the same key for encryption and decryption (e.g., AES, DES). 2) Asymmetric encryption - Uses public/private key pairs (e.g., RSA, ECC). 3) Hash functions - One-way functions that produce fixed-size outputs (e.g., SHA-256). Operating systems employ encryption in various areas: file system encryption (e.g., BitLocker, FileVault), secure communication (SSL/TLS), password storage, and digital signatures. Modern systems also use techniques like full disk encryption, file-level encryption, and encrypted swap spaces to protect sensitive data. Understanding encryption basics is essential for system administrators to configure secure systems and for developers to implement proper data protection in applications.",
            "code": "// Example 1 - Basic encryption simulation\n#include <stdio.h>\n#include <string.h>\n#include <openssl/aes.h>\n\n// Simple XOR encryption (for demonstration only - not secure)\nvoid xor_encrypt(const char *input, char *output, const char *key, size_t len) {\n    for (size_t i = 0; i < len; i++) {\n        output[i] = input[i] ^ key[i % strlen(key)];\n    }\n}\n\nvoid demonstrate_basic_encryption() {\n    printf(\"Basic Encryption Simulation:\\n\\n\");\n    \n    char plaintext[] = \"Hello, Secret Message!\";\n    char key[] = \"MySecretKey\";\n    char ciphertext[256];\n    char decrypted[256];\n    \n    printf(\"Plaintext: %s\\n\", plaintext);\n    printf(\"Key: %s\\n\", key);\n    \n    // Encrypt\n    xor_encrypt(plaintext, ciphertext, key, strlen(plaintext));\n    ciphertext[strlen(plaintext)] = '\\0';\n    \n    printf(\"Ciphertext (hex): \");\n    for (size_t i = 0; i < strlen(plaintext); i++) {\n        printf(\"%02x\", (unsigned char)ciphertext[i]);\n    }\n    printf(\"\\n\");\n    \n    // Decrypt\n    xor_encrypt(ciphertext, decrypted, key, strlen(plaintext));\n    decrypted[strlen(plaintext)] = '\\0';\n    \n    printf(\"Decrypted: %s\\n\", decrypted);\n}\n\n// Example 2 - AES encryption simulation using OpenSSL\n#include <stdio.h>\n#include <string.h>\n#include <openssl/aes.h>\n\nvoid demonstrate_aes_encryption() {\n    printf(\"\\nAES Encryption Simulation:\\n\\n\");\n    \n    // AES key (128-bit)\n    unsigned char aes_key[16] = {\n        0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07,\n        0x08, 0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f\n    };\n    \n    // Input data (must be multiple of 16 bytes for AES)\n    unsigned char plaintext[16] = \"Hello AES 123!\";\n    unsigned char ciphertext[16];\n    unsigned char decrypted[16];\n    \n    printf(\"Plaintext: %s\\n\", plaintext);\n    printf(\"Key: \");\n    for (int i = 0; i < 16; i++) printf(\"%02x\", aes_key[i]);\n    printf(\"\\n\");\n    \n    // AES encryption\n    AES_KEY enc_key;\n    AES_set_encrypt_key(aes_key, 128, &enc_key);\n    AES_encrypt(plaintext, ciphertext, &enc_key);\n    \n    printf(\"Ciphertext: \");\n    for (int i = 0; i < 16; i++) printf(\"%02x\", ciphertext[i]);\n    printf(\"\\n\");\n    \n    // AES decryption\n    AES_KEY dec_key;\n    AES_set_decrypt_key(aes_key, 128, &dec_key);\n    AES_decrypt(ciphertext, decrypted, &dec_key);\n    \n    printf(\"Decrypted: %s\\n\", decrypted);\n}\n\nint main() {\n    demonstrate_basic_encryption();\n    demonstrate_aes_encryption();\n    return 0;\n}"
          }
        ]
      },
      {
        "id": "c11-virtualization",
        "title": "Virtualization & Cloud OS",
        "desc": "Virtual machines, containers, and cloud operating systems",
        "notes": "Virtualization and cloud operating systems represent the evolution of operating systems toward more flexible, scalable, and efficient resource utilization. Virtualization allows multiple operating systems to run concurrently on a single physical machine through virtual machines (VMs) or containers. Cloud operating systems extend this concept to distributed environments, providing resources as services over networks. Key virtualization technologies include: 1) Hypervisors - Software that creates and runs VMs (Type 1: bare-metal, Type 2: hosted). 2) Containers - Lightweight virtualization using OS-level isolation (e.g., Docker, Kubernetes). 3) Paravirtualization - Modified guest OS for better performance. Cloud OS concepts include: 1) Infrastructure as a Service (IaaS) - Virtualized computing resources. 2) Platform as a Service (PaaS) - Development and deployment platforms. 3) Software as a Service (SaaS) - Applications delivered as services. Understanding virtualization and cloud OS is essential for cloud architects, DevOps engineers, and system administrators working with modern distributed systems.",
        "code": "",
        "duration": "Week 1",
        "topics": [
          {
            "id": "t43-vms",
            "title": "Virtual Machines",
            "desc": "Hardware virtualization using hypervisors",
            "note": "Virtual machines (VMs) are software emulations of physical computers that run operating systems and applications. VMs are created and managed by hypervisors (virtual machine monitors) that abstract physical hardware and provide virtualized resources to guest operating systems. There are two types of hypervisors: Type 1 (bare-metal) runs directly on hardware (e.g., VMware ESXi, Microsoft Hyper-V, Xen), and Type 2 (hosted) runs on top of a host operating system (e.g., VMware Workstation, VirtualBox). VMs provide strong isolation between guest systems, allowing different operating systems to run simultaneously on the same physical hardware. Key VM concepts include virtual hardware (virtual CPUs, memory, storage, network interfaces), snapshots (point-in-time copies of VM state), migration (moving VMs between physical hosts), and resource allocation (CPU, memory, I/O limits). VMs are widely used for server consolidation, development and testing, legacy application support, and cloud computing infrastructure. Understanding VM technology is essential for system administrators, cloud engineers, and anyone working with modern data center environments.",
            "code": "// Example 1 - Basic VM structure simulation\n#include <stdio.h>\n#include <stdbool.h>\n\n// Virtual hardware components\ntypedef struct {\n    int vcpus;\n    size_t memory_mb;\n    size_t storage_gb;\n    char network_interfaces;\n} virtual_hardware_t;\n\n// VM state\ntypedef struct {\n    char name[32];\n    virtual_hardware_t hardware;\n    char os_type[32];\n    bool is_running;\n    int cpu_usage;\n    int memory_usage;\n} virtual_machine_t;\n\n// Hypervisor functions\nvoid start_vm(virtual_machine_t *vm) {\n    if (!vm->is_running) {\n        vm->is_running = true;\n        printf(\"Starting VM %s\\n\", vm->name);\n    } else {\n        printf(\"VM %s is already running\\n\", vm->name);\n    }\n}\n\nvoid stop_vm(virtual_machine_t *vm) {\n    if (vm->is_running) {\n        vm->is_running = false;\n        printf(\"Stopping VM %s\\n\", vm->name);\n    } else {\n        printf(\"VM %s is not running\\n\", vm->name);\n    }\n}\n\nvoid migrate_vm(virtual_machine_t *vm, const char *destination) {\n    if (vm->is_running) {\n        printf(\"Migrating VM %s to %s\\n\", vm->name, destination);\n        // Simulate migration process\n        printf(\"1. Pre-copy memory pages\\n\");\n        printf(\"2. Suspend VM\\n\");\n        printf(\"3. Transfer remaining state\\n\");\n        printf(\"4. Resume VM on destination\\n\");\n        printf(\"Migration completed\\n\");\n    } else {\n        printf(\"Cannot migrate stopped VM %s\\n\", vm->name);\n    }\n}\n\nvoid demonstrate_vm_operations() {\n    printf(\"Virtual Machine Operations Simulation:\\n\\n\");\n    \n    // Create a VM\n    virtual_machine_t vm = {\n        .name = \"WebServer-VM\",\n        .hardware = {4, 4096, 100, 2},\n        .os_type = \"Ubuntu Linux\",\n        .is_running = false,\n        .cpu_usage = 0,\n        .memory_usage = 0\n    };\n    \n    printf(\"VM Configuration:\\n\");\n    printf(\"Name: %s\\n\", vm.name);\n    printf(\"OS: %s\\n\", vm.os_type);\n    printf(\"vCPUs: %d\\n\", vm.hardware.vcpus);\n    printf(\"Memory: %zu MB\\n\", vm.hardware.memory_mb);\n    printf(\"Storage: %zu GB\\n\", vm.hardware.storage_gb);\n    printf(\"Network Interfaces: %d\\n\", vm.hardware.network_interfaces);\n    printf(\"\\n\");\n    \n    // Perform operations\n    start_vm(&vm);\n    printf(\"VM running: %s\\n\", vm.is_running ? \"Yes\" : \"No\");\n    \n    migrate_vm(&vm, \"Host02\");\n    \n    stop_vm(&vm);\n    printf(\"VM running: %s\\n\", vm.is_running ? \"Yes\" : \"No\");\n}\n\n// Example 2 - Hypervisor type comparison\nvoid demonstrate_hypervisor_types() {\n    printf(\"\\nHypervisor Types Comparison:\\n\\n\");\n    \n    printf(\"Type 1 (Bare-metal) Hypervisors:\\n\");\n    printf(\"  - Run directly on physical hardware\\n\");\n    printf(\"  - Examples: VMware ESXi, Microsoft Hyper-V, Xen, KVM\\n\");\n    printf(\"  - Advantages: Better performance, more secure\\n\");\n    printf(\"  - Use cases: Data centers, cloud infrastructure\\n\\n\");\n    \n    printf(\"Type 2 (Hosted) Hypervisors:\\n\");\n    printf(\"  - Run on top of a host operating system\\n\");\n    printf(\"  - Examples: VMware Workstation, VirtualBox, Parallels\\n\");\n    printf(\"  - Advantages: Easier to install and use\\n\");\n    printf(\"  - Disadvantages: Lower performance\\n\");\n    printf(\"  - Use cases: Development, testing, personal use\\n\\n\");\n    \n    printf(\"Container-based Virtualization:\\n\");\n    printf(\"  - OS-level virtualization, not hardware virtualization\\n\");\n    printf(\"  - Examples: Docker, Kubernetes, LXC\\n\");\n    printf(\"  - Advantages: Lightweight, fast startup, high density\\n\");\n    printf(\"  - Disadvantages: Less isolation than VMs\\n\");\n    printf(\"  - Use cases: Microservices, cloud-native applications\\n\");\n}\n\nint main() {\n    demonstrate_vm_operations();\n    demonstrate_hypervisor_types();\n    return 0;\n}"
          },
          {
            "id": "t44-hypervisors",
            "title": "Hypervisors",
            "desc": "Virtual machine monitors and management",
            "note": "Hypervisors, also known as Virtual Machine Monitors (VMMs), are software that creates and runs virtual machines. They abstract physical hardware and provide virtualized resources to guest operating systems. Hypervisors handle critical functions including: 1) CPU virtualization - Using techniques like binary translation, paravirtualization, or hardware-assisted virtualization (Intel VT-x, AMD-V). 2) Memory virtualization - Managing physical memory allocation and providing virtual memory spaces for guests. 3) I/O virtualization - Emulating virtual devices and managing access to physical devices. 4) Resource scheduling - Allocating CPU time, memory, and I/O bandwidth among VMs. 5) Live migration - Moving running VMs between physical hosts without downtime. Hypervisors also provide management interfaces for creating, configuring, and monitoring VMs. Modern hypervisors include advanced features like snapshots, cloning, high availability, and distributed resource scheduling. Understanding hypervisor technology is essential for virtualization administrators, cloud engineers, and data center operators.",
            "code": "// Example 1 - Hypervisor resource management simulation\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n\n#define MAX_VMS 10\n#define TOTAL_CPU 16\n#define TOTAL_MEMORY 32768 // 32GB\n#define TOTAL_STORAGE 1000 // 1TB\n\ntypedef struct {\n    int vm_id;\n    char name[32];\n    int allocated_cpu;\n    int allocated_memory;\n    int allocated_storage;\n    int cpu_usage;\n    int memory_usage;\n    bool is_running;\n} vm_t;\n\ntypedef struct {\n    vm_t vms[MAX_VMS];\n    int vm_count;\n    int available_cpu;\n    int available_memory;\n    int available_storage;\n} hypervisor_t;\n\nvoid hypervisor_init(hypervisor_t *hv) {\n    hv->vm_count = 0;\n    hv->available_cpu = TOTAL_CPU;\n    hv->available_memory = TOTAL_MEMORY;\n    hv->available_storage = TOTAL_STORAGE;\n}\n\nbool create_vm(hypervisor_t *hv, const char *name, int cpu, int memory, int storage) {\n    if (hv->vm_count >= MAX_VMS) {\n        printf(\"Cannot create VM: Maximum VM count reached\\n\");\n        return false;\n    }\n    \n    if (cpu > hv->available_cpu || memory > hv->available_memory || storage > hv->available_storage) {\n        printf(\"Cannot create VM: Not enough resources\\n\");\n        return false;\n    }\n    \n    vm_t *vm = &hv->vms[hv->vm_count++];\n    vm->vm_id = hv->vm_count;\n    strcpy(vm->name, name);\n    vm->allocated_cpu = cpu;\n    vm->allocated_memory = memory;\n    vm->allocated_storage = storage;\n    vm->cpu_usage = 0;\n    vm->memory_usage = 0;\n    vm->is_running = false;\n    \n    hv->available_cpu -= cpu;\n    hv->available_memory -= memory;\n    hv->available_storage -= storage;\n    \n    printf(\"Created VM %s (ID: %d) with %d CPU, %d MB memory, %d GB storage\\n\",\n           name, vm->vm_id, cpu, memory, storage);\n    \n    return true;\n}\n\nvoid start_vm(hypervisor_t *hv, int vm_id) {\n    if (vm_id < 1 || vm_id > hv->vm_count) {\n        printf(\"Invalid VM ID\\n\");\n        return;\n    }\n    \n    vm_t *vm = &hv->vms[vm_id - 1];\n    if (!vm->is_running) {\n        vm->is_running = true;\n        printf(\"Started VM %s\\n\", vm->name);\n    } else {\n        printf(\"VM %s is already running\\n\", vm->name);\n    }\n}\n\nvoid simulate_resource_usage(hypervisor_t *hv) {\n    srand(time(NULL));\n    \n    for (int i = 0; i < hv->vm_count; i++) {\n        if (hv->vms[i].is_running) {\n            hv->vms[i].cpu_usage = rand() % 101; // 0-100%\n            hv->vms[i].memory_usage = (rand() % (hv->vms[i].allocated_memory / 2)) + \n                                     (hv->vms[i].allocated_memory / 2);\n        }\n    }\n}\n\nvoid display_resource_usage(hypervisor_t *hv) {\n    printf(\"\\nHypervisor Resource Usage:\\n\");\n    printf(\"Total CPU: %d, Available: %d\\n\", TOTAL_CPU, hv->available_cpu);\n    printf(\"Total Memory: %d MB, Available: %d MB\\n\", TOTAL_MEMORY, hv->available_memory);\n    printf(\"Total Storage: %d GB, Available: %d GB\\n\", TOTAL_STORAGE, hv->available_storage);\n    \n    printf(\"\\nVM Resource Usage:\\n\");\n    printf(\"ID\\tName\\t\\tCPU\\tMem\\tStorage\\tCPU%%\\tMem Used\\n\");\n    \n    for (int i = 0; i < hv->vm_count; i++) {\n        vm_t *vm = &hv->vms[i];\n        printf(\"%d\\t%-12s\\t%d\\t%d\\t%d\\t%d%%\\t%d MB\\n\",\n               vm->vm_id, vm->name, vm->allocated_cpu, vm->allocated_memory,\n               vm->allocated_storage, vm->cpu_usage, vm->memory_usage);\n    }\n}\n\nvoid demonstrate_hypervisor_management() {\n    printf(\"Hypervisor Resource Management Simulation:\\n\\n\");\n    \n    hypervisor_t hv;\n    hypervisor_init(&hv);\n    \n    // Create some VMs\n    create_vm(&hv, \"WebServer\", 2, 2048, 50);\n    create_vm(&hv, \"DBServer\", 4, 4096, 100);\n    create_vm(&hv, \"AppServer\", 2, 1024, 30);\n    \n    // Start VMs\n    start_vm(&hv, 1);\n    start_vm(&hv, 2);\n    \n    // Simulate resource usage\n    simulate_resource_usage(&hv);\n    \n    // Display usage\n    display_resource_usage(&hv);\n}\n\n// Example 2 - Hardware-assisted virtualization\nvoid demonstrate_hardware_virtualization() {\n    printf(\"\\nHardware-assisted Virtualization:\\n\\n\");\n    \n    printf(\"CPU Virtualization Extensions:\\n\");\n    printf(\"  - Intel VT-x: Virtualization Technology\\n\");\n    printf(\"  - AMD-V: AMD Virtualization\\n\");\n    printf(\"  - Provides hardware support for virtualization\\n\");\n    printf(\"  - Reduces performance overhead\\n\");\n    printf(\"  - Enables running unmodified guest OS\\n\\n\");\n    \n    printf(\"Memory Virtualization:\\n\");\n    printf(\"  - Extended Page Tables (EPT) - Intel\\n\");\n    printf(\"  - Rapid Virtualization Indexing (RVI) - AMD\\n\");\n    printf(\"  - Hardware support for memory address translation\\n\");\n    printf(\"  - Reduces memory virtualization overhead\\n\\n\");\n    \n    printf(\"I/O Virtualization:\\n\");\n    printf(\"  - Intel VT-d: Directed I/O\\n\");\n    printf(\"  - AMD-Vi: I/O Memory Management Unit\\n\");\n    printf(\"  - SR-IOV: Single Root I/O Virtualization\\n\");\n    printf(\"  - Allows direct device assignment to VMs\\n\");\n    printf(\"  - Improves I/O performance\\n\");\n}\n\nint main() {\n    demonstrate_hypervisor_management();\n    demonstrate_hardware_virtualization();\n    return 0;\n}"
          },
          {
            "id": "t45-containers",
            "title": "Container Technology",
            "desc": "Lightweight virtualization using OS-level isolation",
            "note": "Containers are a lightweight form of virtualization that provides operating system-level isolation rather than hardware virtualization. Unlike virtual machines that emulate complete hardware environments, containers share the host operating system kernel while providing isolated user spaces. Key container technologies include: 1) Namespaces - Isolate processes, network, filesystem, and other resources. 2) Cgroups - Control and limit resource usage (CPU, memory, I/O). 3) Union filesystems - Allow efficient image layering and sharing. Popular container platforms include Docker (container runtime and packaging), Kubernetes (container orchestration), and containerd (industry-standard container runtime). Containers offer advantages over VMs including faster startup times, higher density, smaller footprint, and easier application packaging. However, they provide less isolation than VMs since all containers share the same host kernel. Container technology is fundamental to modern cloud-native application development, microservices architectures, and DevOps practices. Understanding containers is essential for developers, DevOps engineers, and cloud architects working with modern application deployment and orchestration.",
            "code": "// Example 1 - Container isolation simulation\n#include <stdio.h>\n#include <unistd.h>\n#include <sys/types.h>\n#include <sys/wait.h>\n\nvoid demonstrate_namespace_isolation() {\n    printf(\"Container Namespace Isolation Simulation:\\n\\n\");\n    \n    printf(\"Host PID: %d\\n\", getpid());\n    printf(\"Host PPID: %d\\n\", getppid());\n    \n    // Simulate PID namespace isolation\n    printf(\"\\nCreating child process (simulated container)...\\n\");\n    \n    pid_t child_pid = fork();\n    \n    if (child_pid == 0) {\n        // Child process (simulated container)\n        printf(\"Container PID: %d\\n\", getpid());\n        printf(\"Container PPID: %d\\n\", getppid());\n        printf(\"Inside container namespace - isolated from host\\n\");\n        \n        // Simulate containerized application\n        sleep(2);\n        \n        printf(\"Container exiting...\\n\");\n        _exit(0);\n    } else {\n        // Parent process (host)\n        printf(\"Host waiting for container to exit...\\n\");\n        waitpid(child_pid, NULL, 0);\n        printf(\"Container exited\\n\");\n    }\n}\n\n// Example 2 - Resource limits simulation (cgroups)\n#include <stdio.h>\n#include <stdlib.h>\n\nvoid demonstrate_resource_limits() {\n    printf(\"\\nContainer Resource Limits (cgroups) Simulation:\\n\\n\");\n    \n    // Simulate CPU limits\n    printf(\"CPU Limits:\\n\");\n    printf(\"  - CPU shares: Relative CPU allocation\\n\");\n    printf(\"  - CPU quota: Maximum CPU time per period\\n\");\n    printf(\"  - CPU set: Specific CPU cores allowed\\n\\n\");\n    \n    // Simulate memory limits\n    printf(\"Memory Limits:\\n\");\n    printf(\"  - Memory limit: Maximum RAM usage\\n\");\n    printf(\"  - Memory swap: Swap space limit\\n\");\n    printf(\"  - OOM killer: Kills container if over limit\\n\\n\");\n    \n    // Simulate I/O limits\n    printf(\"I/O Limits:\\n\");\n    printf(\"  - Read/Write IOPS: I/O operations per second\\n\");\n    printf(\"  - Read/Write bandwidth: Bytes per second\\n\");\n    printf(\"  - Block device access control\\n\\n\");\n    \n    printf(\"Example: Container with limits:\\n\");\n    printf(\"  CPU: 2 cores, 50% quota\\n\");\n    printf(\"  Memory: 512MB limit, 1GB swap\\n\");\n    printf(\"  I/O: 1000 IOPS read, 500 IOPS write\\n\");\n}\n\n// Example 3 - Container image layers simulation\nvoid demonstrate_image_layers() {\n    printf(\"\\nContainer Image Layers (Union Filesystem):\\n\\n\");\n    \n    printf(\"Base Image Layers:\\n\");\n    printf(\"  Layer 1: Base OS (Ubuntu)\\n\");\n    printf(\"  Layer 2: Runtime dependencies\\n\");\n    printf(\"  Layer 3: Application code\\n\");\n    printf(\"  Layer 4: Configuration files\\n\\n\");\n    \n    printf(\"How layers work:\\n\");\n    printf(\"  - Each layer is read-only\\n\");\n    printf(\"  - Changes create new writable layer\\n\");\n    printf(\"  - Layers are shared between containers\\n\");\n    printf(\"  - Efficient storage and transfer\\n\\n\");\n    \n    printf(\"Example: Dockerfile layers:\\n\");\n    printf(\"  FROM ubuntu:20.04\\n\");\n    printf(\"  RUN apt-get update\\n\");\n    printf(\"  COPY app.py /app/\\n\");\n    printf(\"  CMD [\\\"python\\\", \\\"/app/app.py\\\"]\\n\");\n}\n\nint main() {\n    demonstrate_namespace_isolation();\n    demonstrate_resource_limits();\n    demonstrate_image_layers();\n    return 0;\n}"
          },
          {
            "id": "t46-cloud-os",
            "title": "Cloud OS Concepts",
            "desc": "Operating systems for cloud computing environments",
            "note": "Cloud operating systems extend traditional OS concepts to distributed cloud environments, providing resources as services over networks. Cloud OS platforms manage vast distributed infrastructure and provide abstraction layers for applications. Key cloud OS concepts include: 1) Service Models - IaaS (Infrastructure as a Service), PaaS (Platform as a Service), SaaS (Software as a Service). 2) Deployment Models - Public cloud, private cloud, hybrid cloud, multi-cloud. 3) Cloud Native Principles - Microservices, containers, DevOps, continuous delivery. 4) Orchestration - Automated deployment, scaling, and management of containerized applications (e.g., Kubernetes). 5) Serverless Computing - Event-driven execution without managing servers. Cloud OS platforms provide features like auto-scaling, load balancing, distributed storage, and managed services. Understanding cloud OS concepts is essential for cloud architects, DevOps engineers, and developers building and deploying applications in cloud environments.",
            "code": "// Example 1 - Cloud service models simulation\n#include <stdio.h>\n\nvoid demonstrate_cloud_models() {\n    printf(\"Cloud Service Models Simulation:\\n\\n\");\n    \n    printf(\"Infrastructure as a Service (IaaS):\\n\");\n    printf(\"  - Provides virtualized computing resources\\n\");\n    printf(\"  - Examples: AWS EC2, Azure VMs, Google Compute Engine\\n\");\n    printf(\"  - User manages: OS, applications, data\\n\");\n    printf(\"  - Provider manages: Hardware, virtualization, networking\\n\\n\");\n    \n    printf(\"Platform as a Service (PaaS):\\n\");\n    printf(\"  - Provides development and deployment platform\\n\");\n    printf(\"  - Examples: Heroku, Google App Engine, Azure App Service\\n\");\n    printf(\"  - User manages: Applications, data\\n\");\n    printf(\"  - Provider manages: Runtime, OS, infrastructure\\n\\n\");\n    \n    printf(\"Software as a Service (SaaS):\\n\");\n    printf(\"  - Provides complete software applications\\n\");\n    printf(\"  - Examples: Gmail, Salesforce, Office 365\\n\");\n    printf(\"  - User manages: Data (sometimes)\\n\");\n    printf(\"  - Provider manages: Everything else\\n\\n\");\n}\n\n// Example 2 - Auto-scaling simulation\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n\nvoid demonstrate_auto_scaling() {\n    printf(\"Cloud Auto-scaling Simulation:\\n\\n\");\n    \n    srand(time(NULL));\n    \n    int current_instances = 2;\n    int min_instances = 2;\n    int max_instances = 10;\n    int cpu_threshold = 70; // Scale out if CPU > 70%\n    int scale_out_step = 2;\n    int scale_in_step = 1;\n    \n    printf(\"Initial instances: %d\\n\", current_instances);\n    printf(\"Auto-scaling parameters:\\n\");\n    printf(\"  Min instances: %d\\n\", min_instances);\n    printf(\"  Max instances: %d\\n\", max_instances);\n    printf(\"  CPU threshold: %d%%\\n\", cpu_threshold);\n    printf(\"  Scale out step: %d\\n\", scale_out_step);\n    printf(\"  Scale in step: %d\\n\\n\", scale_in_step);\n    \n    // Simulate load changes and auto-scaling\n    for (int minute = 1; minute <= 10; minute++) {\n        int cpu_usage = rand() % 101; // Random CPU usage 0-100%\n        \n        printf(\"Minute %d: CPU usage = %d%%, Instances = %d\", \n               minute, cpu_usage, current_instances);\n        \n        // Scale out if CPU usage is high\n        if (cpu_usage > cpu_threshold && current_instances < max_instances) {\n            int new_instances = current_instances + scale_out_step;\n            if (new_instances > max_instances) new_instances = max_instances;\n            printf(\" -> Scaling out to %d instances\", new_instances);\n            current_instances = new_instances;\n        }\n        // Scale in if CPU usage is low\n        else if (cpu_usage < cpu_threshold / 2 && current_instances > min_instances) {\n            int new_instances = current_instances - scale_in_step;\n            if (new_instances < min_instances) new_instances = min_instances;\n            printf(\" -> Scaling in to %d instances\", new_instances);\n            current_instances = new_instances;\n        }\n        \n        printf(\"\\n\");\n    }\n}\n\n// Example 3 - Kubernetes concepts simulation\nvoid demonstrate_kubernetes() {\n    printf(\"\\nKubernetes Concepts Simulation:\\n\\n\");\n    \n    printf(\"Kubernetes Components:\\n\");\n    printf(\"  Pods: Smallest deployable units (one or more containers)\\n\");\n    printf(\"  Deployments: Manage pod replicas and updates\\n\");\n    printf(\"  Services: Network access to pods\\n\");\n    printf(\"  Ingress: External access to services\\n\");\n    printf(\"  ConfigMaps: Configuration data\\n\");\n    printf(\"  Secrets: Sensitive data\\n\\n\");\n    \n    printf(\"Example Deployment:\\n\");\n    printf(\"apiVersion: apps/v1\\n\");\n    printf(\"kind: Deployment\\n\");\n    printf(\"metadata:\\n\");\n    printf(\"  name: webapp-deployment\\n\");\n    printf(\"spec:\\n\");\n    printf(\"  replicas: 3\\n\");\n    printf(\"  template:\\n\");\n    printf(\"    spec:\\n\");\n    printf(\"      containers:\\n\");\n    printf(\"      - name: webapp\\n\");\n    printf(\"        image: nginx:1.20\\n\");\n    printf(\"        ports:\\n\");\n    printf(\"        - containerPort: 80\\n\");\n}\n\nint main() {\n    demonstrate_cloud_models();\n    demonstrate_auto_scaling();\n    demonstrate_kubernetes();\n    return 0;\n}"
          }
        ]
      },
      {
        "id": "c12-case-studies",
        "title": "Case Studies & Advanced Topics",
        "desc": "Real-world OS implementations and advanced concepts",
        "notes": "Case studies of real-world operating systems provide valuable insights into how theoretical concepts are implemented in practice. Examining different OS architectures helps understand design trade-offs, performance considerations, and implementation challenges. Advanced topics in operating systems include real-time systems, distributed OS, embedded systems, security enhancements, and emerging technologies. Studying these areas provides a comprehensive understanding of modern OS development and future directions. Case studies typically cover major operating systems like Linux, Windows, macOS, and Android, as well as specialized systems for embedded, real-time, and distributed environments.",
        "code": "",
        "duration": "Week 1",
        "topics": [
          {
            "id": "t47-linux-internals",
            "title": "Linux Kernel Internals",
            "desc": "Deep dive into Linux kernel architecture and implementation",
            "note": "The Linux kernel is a monolithic, modular operating system kernel that serves as the foundation for numerous operating systems. Its architecture includes several key components: 1) Process management - Uses task_struct for process control, supports cloning via fork() and copy-on-write. 2) Memory management - Implements virtual memory with paging, uses buddy system for physical memory allocation. 3) Virtual File System (VFS) - Provides abstraction layer for multiple filesystem types. 4) Network stack - Implements TCP/IP protocol suite with socket interface. 5) Device drivers - Loadable kernel modules for hardware support. 6) Interrupt handling - Bottom-half/top-half model for efficient interrupt processing. Linux uses a symmetric multiprocessing (SMP) model and supports numerous architectures. The kernel is highly configurable with thousands of compile-time options. Understanding Linux internals is essential for system programmers, kernel developers, and performance engineers working with Linux-based systems.",
            "code": "// Example 1 - Linux kernel module simulation\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\n// Simulated kernel data structures\ntypedef struct {\n    int pid;\n    char comm[16];\n    long state;\n    int priority;\n} task_struct_t;\n\n// Simulated kernel functions\nvoid simulate_kernel_module() {\n    printf(\"Linux Kernel Module Simulation:\\n\\n\");\n    \n    // Simulate process list traversal\n    task_struct_t tasks[] = {\n        {1, \"init\", 0, 120},\n        {2, \"kthreadd\", 0, 98},\n        {3, \"sshd\", 1, 100},\n        {4, \"bash\", 1, 120},\n        {5, \"vim\", 1, 120}\n    };\n    \n    int num_tasks = sizeof(tasks) / sizeof(tasks[0]);\n    \n    printf(\"Process list traversal (like ps command):\\n\");\n    printf(\"PID\\tCOMMAND\\t\\tSTATE\\tPRIO\\n\");\n    \n    for (int i = 0; i < num_tasks; i++) {\n        printf(\"%d\\t%-12s\\t%ld\\t%d\\n\",\n               tasks[i].pid, tasks[i].comm, tasks[i].state, tasks[i].priority);\n    }\n}\n\n// Example 2 - Linux VFS simulation\n#include <stdio.h>\n#include <stdbool.h>\n\n// Simulated VFS structures\ntypedef struct {\n    const char *name;\n    int (*open)(const char *path, int flags);\n    int (*read)(int fd, void *buf, size_t count);\n    int (*write)(int fd, const void *buf, size_t count);\n    int (*close)(int fd);\n} file_operations_t;\n\ntypedef struct {\n    const char *name;\n    const file_operations_t *fops;\n} file_system_type_t;\n\n// Simulated filesystem operations\nint ext4_open(const char *path, int flags) {\n    printf(\"ext4_open(%s, %d)\\n\", path, flags);\n    return 0; // Return file descriptor\n}\n\nint ext4_read(int fd, void *buf, size_t count) {\n    printf(\"ext4_read(%d, %p, %zu)\\n\", fd, buf, count);\n    return count;\n}\n\nint ext4_write(int fd, const void *buf, size_t count) {\n    printf(\"ext4_write(%d, %p, %zu)\\n\", fd, buf, count);\n    return count;\n}\n\nint ext4_close(int fd) {\n    printf(\"ext4_close(%d)\\n\", fd);\n    return 0;\n}\n\n// ext4 filesystem operations\nconst file_operations_t ext4_fops = {\n    .name = \"ext4\",\n    .open = ext4_open,\n    .read = ext4_read,\n    .write = ext4_write,\n    .close = ext4_close\n};\n\n// Simulated VFS layer\nint vfs_open(const char *path, int flags, const file_system_type_t *fs) {\n    printf(\"VFS: Opening %s on %s filesystem\\n\", path, fs->name);\n    return fs->fops->open(path, flags);\n}\n\nvoid demonstrate_vfs() {\n    printf(\"\\nLinux Virtual File System (VFS) Simulation:\\n\\n\");\n    \n    file_system_type_t ext4_fs = {\n        .name = \"ext4\",\n        .fops = &ext4_fops\n    };\n    \n    // Simulate file operations through VFS\n    int fd = vfs_open(\"/home/user/file.txt\", 0, &ext4_fs);\n    \n    char buffer[100];\n    ext4_fops.read(fd, buffer, sizeof(buffer));\n    \n    ext4_fops.write(fd, \"Hello VFS!\", 10);\n    \n    ext4_fops.close(fd);\n}\n\nint main() {\n    simulate_kernel_module();\n    demonstrate_vfs();\n    return 0;\n}"
          },
          {
            "id": "t48-windows-architecture",
            "title": "Windows Architecture",
            "desc": "Windows NT kernel architecture and components",
            "note": "The Windows NT architecture is a hybrid kernel design that combines elements of monolithic and microkernel architectures. Key components include: 1) Executive - Core OS services (object manager, process manager, memory manager, I/O manager, security reference monitor). 2) Kernel - Low-level OS functions (scheduling, interrupt handling, synchronization). 3) Hardware Abstraction Layer (HAL) - Abstracts hardware differences. 4) Subsystems - Environment subsystems (Win32, POSIX) and integral subsystems. Windows uses a modular design with well-defined interfaces between components. The architecture emphasizes security, reliability, and extensibility. Key features include object-based design, symmetric multiprocessing, virtual memory management, and advanced security model. Understanding Windows architecture is essential for system programmers, driver developers, and security professionals working with Windows systems.",
            "code": "// Example 1 - Windows object manager simulation\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\n// Simulated object types\ntypedef enum {\n    ObjectTypeProcess,\n    ObjectTypeThread,\n    ObjectTypeFile,\n    ObjectTypeEvent,\n    ObjectTypeMutex\n} object_type_t;\n\n// Simulated object header\ntypedef struct {\n    object_type_t type;\n    char name[64];\n    int reference_count;\n    void *body;\n} object_header_t;\n\n// Simulated object manager\n#define MAX_OBJECTS 100\nobject_header_t *object_table[MAX_OBJECTS];\nint object_count = 0;\n\n// Create an object\nobject_header_t *create_object(object_type_t type, const char *name) {\n    if (object_count >= MAX_OBJECTS) {\n        return NULL;\n    }\n    \n    object_header_t *obj = malloc(sizeof(object_header_t));\n    obj->type = type;\n    strncpy(obj->name, name, sizeof(obj->name) - 1);\n    obj->reference_count = 1;\n    obj->body = NULL;\n    \n    object_table[object_count++] = obj;\n    \n    printf(\"Created object: %s (type: %d)\\n\", name, type);\n    return obj;\n}\n\n// Reference an object\nvoid reference_object(object_header_t *obj) {\n    if (obj) {\n        obj->reference_count++;\n        printf(\"Referenced object %s, count: %d\\n\", obj->name, obj->reference_count);\n    }\n}\n\n// Dereference an object\nvoid dereference_object(object_header_t *obj) {\n    if (obj) {\n        obj->reference_count--;\n        printf(\"Dereferenced object %s, count: %d\\n\", obj->name, obj->reference_count);\n        \n        if (obj->reference_count == 0) {\n            printf(\"Destroying object %s\\n\", obj->name);\n            free(obj);\n        }\n    }\n}\n\nvoid demonstrate_object_manager() {\n    printf(\"Windows Object Manager Simulation:\\n\\n\");\n    \n    // Create some objects\n    object_header_t *process = create_object(ObjectTypeProcess, \"Process1\");\n    object_header_t *file = create_object(ObjectTypeFile, \"File1.txt\");\n    object_header_t *event = create_object(ObjectTypeEvent, \"Event1\");\n    \n    printf(\"\\n\");\n    \n    // Reference and dereference objects\n    reference_object(process);\n    reference_object(file);\n    \n    dereference_object(process);\n    dereference_object(file);\n    dereference_object(event);\n    \n    // Cleanup remaining objects\n    for (int i = 0; i < object_count; i++) {\n        if (object_table[i]) {\n            free(object_table[i]);\n        }\n    }\n}\n\n// Example 2 - Windows registry simulation\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\ntypedef enum {\n    RegTypeString,\n    RegTypeDword,\n    RegTypeBinary\n} registry_value_type_t;\n\ntypedef struct {\n    char name[64];\n    registry_value_type_t type;\n    void *data;\n    size_t data_size;\n} registry_value_t;\n\ntypedef struct {\n    char path[256];\n    registry_value_t *values;\n    int value_count;\n} registry_key_t;\n\nvoid demonstrate_registry() {\n    printf(\"\\nWindows Registry Simulation:\\n\\n\");\n    \n    // Simulate registry keys and values\n    registry_key_t hklm = {\n        .path = \"HKEY_LOCAL_MACHINE\\\\Software\\\\MyApp\",\n        .value_count = 3\n    };\n    \n    registry_value_t values[3];\n    \n    // String value\n    strcpy(values[0].name, \"InstallPath\");\n    values[0].type = RegTypeString;\n    values[0].data = strdup(\"C:\\\\Program Files\\\\MyApp\");\n    values[0].data_size = strlen(values[0].data) + 1;\n    \n    // DWORD value\n    strcpy(values[1].name, \"Version\");\n    values[1].type = RegTypeDword;\n    int version = 2;\n    values[1].data = malloc(sizeof(int));\n    memcpy(values[1].data, &version, sizeof(int));\n    values[1].data_size = sizeof(int);\n    \n    // Binary value\n    strcpy(values[2].name, \"Config\");\n    values[2].type = RegTypeBinary;\n    unsigned char config[] = {0x01, 0x02, 0x03, 0x04};\n    values[2].data = malloc(sizeof(config));\n    memcpy(values[2].data, config, sizeof(config));\n    values[2].data_size = sizeof(config);\n    \n    hklm.values = values;\n    \n    // Display registry contents\n    printf(\"Registry Key: %s\\n\", hklm.path);\n    printf(\"Values:\\n\");\n    \n    for (int i = 0; i < hklm.value_count; i++) {\n        printf(\"  %s: \", values[i].name);\n        \n        switch (values[i].type) {\n            case RegTypeString:\n                printf(\"REG_SZ = %s\\n\", (char*)values[i].data);\n                break;\n            case RegTypeDword:\n                printf(\"REG_DWORD = %d\\n\", *(int*)values[i].data);\n                break;\n            case RegTypeBinary:\n                printf(\"REG_BINARY = \");\n                for (size_t j = 0; j < values[i].data_size; j++) {\n                    printf(\"%02X \", ((unsigned char*)values[i].data)[j]);\n                }\n                printf(\"\\n\");\n                break;\n        }\n    }\n    \n    // Cleanup\n    for (int i = 0; i < hklm.value_count; i++) {\n        free(values[i].data);\n    }\n}\n\nint main() {\n    demonstrate_object_manager();\n    demonstrate_registry();\n    return 0;\n}"
          },
          {
            "id": "t49-android-os",
            "title": "Android OS Overview",
            "desc": "Android architecture and mobile OS features",
            "note": "Android is a Linux-based open-source operating system designed primarily for mobile devices. Its architecture consists of several layers: 1) Linux kernel - Provides hardware abstraction, security, and core OS services. 2) Hardware Abstraction Layer (HAL) - Standard interfaces for hardware vendors. 3) Android Runtime (ART) - Executes and manages application code. 4) Native C/C++ libraries - For performance-critical components. 5) Java API framework - Provides APIs for app development. 6) System apps - Core applications like phone, contacts, browser. Android uses a unique security model based on Linux permissions and application sandboxing. Each app runs in its own Dalvik VM instance with limited permissions. Key Android features include activity-based application model, intent system for inter-app communication, content providers for data sharing, and services for background operations. Understanding Android architecture is essential for mobile app developers, embedded system engineers, and security researchers working with mobile platforms.",
            "code": "// Example 1 - Android activity lifecycle simulation\n#include <stdio.h>\n\n// Android activity states\ntypedef enum {\n    ACTIVITY_CREATED,\n    ACTIVITY_STARTED,\n    ACTIVITY_RESUMED,\n    ACTIVITY_PAUSED,\n    ACTIVITY_STOPPED,\n    ACTIVITY_DESTROYED\n} activity_state_t;\n\nconst char *state_names[] = {\n    \"CREATED\", \"STARTED\", \"RESUMED\", \"PAUSED\", \"STOPPED\", \"DESTROYED\"\n};\n\n// Simulate activity lifecycle\nvoid activity_lifecycle() {\n    printf(\"Android Activity Lifecycle Simulation:\\n\\n\");\n    \n    activity_state_t current_state = ACTIVITY_CREATED;\n    printf(\"Activity state: %s\\n\", state_names[current_state]);\n    \n    // Simulate lifecycle transitions\n    current_state = ACTIVITY_STARTED;\n    printf(\"Activity state: %s\\n\", state_names[current_state]);\n    \n    current_state = ACTIVITY_RESUMED;\n    printf(\"Activity state: %s (visible and interactive)\\n\", state_names[current_state]);\n    \n    // Simulate user navigating away\n    current_state = ACTIVITY_PAUSED;\n    printf(\"Activity state: %s (partially visible)\\n\", state_names[current_state]);\n    \n    current_state = ACTIVITY_STOPPED;\n    printf(\"Activity state: %s (not visible)\\n\", state_names[current_state]);\n    \n    // Simulate activity being destroyed\n    current_state = ACTIVITY_DESTROYED;\n    printf(\"Activity state: %s\\n\", state_names[current_state]);\n}\n\n// Example 2 - Android intent system simulation\n#include <stdio.h>\n#include <string.h>\n\n// Intent structure\ntypedef struct {\n    char action[64];\n    char category[64];\n    char data[128];\n    char type[64];\n    int flags;\n} intent_t;\n\n// Simulate sending an intent\nvoid send_intent(const intent_t *intent) {\n    printf(\"Sending Intent:\\n\");\n    printf(\"  Action: %s\\n\", intent->action);\n    printf(\"  Category: %s\\n\", intent->category);\n    printf(\"  Data: %s\\n\", intent->data);\n    printf(\"  Type: %s\\n\", intent->type);\n    printf(\"  Flags: %d\\n\", intent->flags);\n    printf(\"\\n\");\n}\n\n// Simulate intent filters\nbool intent_matches_filter(const intent_t *intent, const char *action, const char *category) {\n    if (strcmp(intent->action, action) != 0) {\n        return false;\n    }\n    \n    if (category && strcmp(intent->category, category) != 0) {\n        return false;\n    }\n    \n    return true;\n}\n\nvoid demonstrate_intent_system() {\n    printf(\"Android Intent System Simulation:\\n\\n\");\n    \n    // Create some intents\n    intent_t view_intent = {\n        .action = \"android.intent.action.VIEW\",\n        .category = \"android.intent.category.DEFAULT\",\n        .data = \"https://www.example.com\",\n        .type = \"text/html\",\n        .flags = 0\n    };\n    \n    intent_t dial_intent = {\n        .action = \"android.intent.action.DIAL\",\n        .category = \"android.intent.category.DEFAULT\",\n        .data = \"tel:+1234567890\",\n        .type = \"\",\n        .flags = 0\n    };\n    \n    // Send intents\n    send_intent(&view_intent);\n    send_intent(&dial_intent);\n    \n    // Check intent filters\n    printf(\"Intent matching:\\n\");\n    printf(\"VIEW intent matches browser: %s\\n\",\n           intent_matches_filter(&view_intent, \"android.intent.action.VIEW\", \n                                \"android.intent.category.BROWSABLE\") ? \"YES\" : \"NO\");\n    \n    printf(\"DIAL intent matches phone: %s\\n\",\n           intent_matches_filter(&dial_intent, \"android.intent.action.DIAL\", \n                                \"android.intent.category.DEFAULT\") ? \"YES\" : \"NO\");\n}\n\nint main() {\n    activity_lifecycle();\n    printf(\"\\n\");\n    demonstrate_intent_system();\n    return 0;\n}"
          }
        ]
      }
    ]
  }
]